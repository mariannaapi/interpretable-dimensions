{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92f0488-7456-497b-9084-46dd56c8aecf",
   "metadata": {},
   "source": [
    "# Experiments on the data of Grand et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da1dfe0-29ac-4db1-ac31-0eb90506ea8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kee252/Library/Python/3.9/lib/python/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import math\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "glove_path = \"glove/glove.42B.300d.zip\"\n",
    "glove_file = \"glove.42B.300d.txt\"\n",
    "\n",
    "feature_dim = 300\n",
    "\n",
    "word_vectors = { }\n",
    "\n",
    "with zipfile.ZipFile(glove_path) as azip:\n",
    "    with azip.open(glove_file) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0].decode()\n",
    "            vector = np.array(values[1:], dtype=np.float32)\n",
    "            word_vectors[word] = vector\n",
    "\n",
    "grandratings_dir = \"Grand_etal_csv/\"\n",
    "grandfeatures_path = \"/Users/kee252/Data/grand_directions_in_space/features.xlsx\"\n",
    "\n",
    "grandfeatures_df = pd.read_excel(grandfeatures_path)\n",
    "\n",
    "# reading in Grand data\n",
    "def read_grand_data(filename, grandratings_dir, grandfeatures_df):\n",
    "    # extract category and feature\n",
    "    grandcategory, grandfeature = filename[:-4].split(\"_\")\n",
    "        \n",
    "    # read human ratings, make gold column\n",
    "    df = pd.read_csv(grandratings_dir + filename)\n",
    "    nspeakers = len(df.columns) -1\n",
    "    df[\"Average\"] = [row.iloc[1:26].sum() / nspeakers for _, row in df.iterrows()]\n",
    "    # z-scores of average ratings\n",
    "    df[\"Gold\"] = (df[\"Average\"] - df[\"Average\"].mean()) / df[\"Average\"].std()\n",
    "        \n",
    "    # obtain seed words from excel file\n",
    "    relevant_row = grandfeatures_df[grandfeatures_df.Dimension == grandfeature]\n",
    "    seedwords = relevant_row.iloc[:, 1:].values.flatten().tolist()\n",
    "    pos_seedwords = seedwords[:3]\n",
    "    neg_seedwords = seedwords[3:]\n",
    "    \n",
    "    return (grandcategory, grandfeature, pos_seedwords, neg_seedwords, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090dda3f-040d-4141-9f95-dd983be77e1e",
   "metadata": {},
   "source": [
    "## Reproducing their results\n",
    "\n",
    "We reproduce their results from the Nature paper almost perfectly, on both Pearson's r correlation and pairwise order evaluation OC_P. X percent of category/feature pairs show a significant correlation, and average OC_P is Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2945e83-e61a-483f-b5f1-94d34f867a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script for running on data\n",
    "def each_grandcondition(grandratings_dir, grandfeatures_df):\n",
    "    for filename in os.listdir(grandratings_dir): \n",
    "        if not filename.endswith(\"csv\"):\n",
    "            continue\n",
    "\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, \n",
    "                                                                    grandratings_dir, \n",
    "                                                                    grandfeatures_df)\n",
    "\n",
    "        # storage for word vectors and gold values for this dataset\n",
    "        data_vectors = []\n",
    "\n",
    "        # collect word vectors and gold ratings\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            data_vectors.append( word_vectors[ row.Row ])\n",
    "            \n",
    "        yield (grandcategory, grandfeature, pos_seedwords, neg_seedwords, df, data_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8637842-e4aa-42f3-bf45-db25445ff1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import compute_dim\n",
    "import eval_dim\n",
    "from scipy import stats\n",
    "\n",
    "results = [ ]\n",
    "\n",
    "for grandcategory, grandfeature, pos_seedwords, neg_seedwords, df, data_vectors in each_grandcondition(grandratings_dir, grandfeatures_df):\n",
    "    \n",
    "    dimension = compute_dim.dimension_seedbased(pos_seedwords, neg_seedwords, word_vectors)\n",
    "    \n",
    "    df[\"Pred\"]  = compute_dim.predict_scalarproj(data_vectors, dimension)\n",
    "    \n",
    "    ocp = eval_dim.pairwise_order_consistency(df[\"Gold\"], df[\"Pred\"])\n",
    "    result_obj = stats.pearsonr(df[\"Gold\"], df[\"Pred\"])\n",
    "    \n",
    "    results.append({\"category\": grandcategory,\n",
    "                    \"feature\" : grandfeature,\n",
    "                    \"ocp\" : ocp,\n",
    "                    \"pearsonr\" : result_obj.statistic,\n",
    "                    \"pvalue\" : result_obj.pvalue } )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8efba4d-c057-4484-8b6f-b028ff4e31b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothing age r 0.561 p= 0.0 ocp 0.709   *\n",
      "names age r 0.616 p= 0.0 ocp 0.723   *\n",
      "professions age r 0.238 p= 0.1 ocp 0.568   \n",
      "cities arousal r 0.001 p= 0.996 ocp 0.522   \n",
      "clothing arousal r 0.185 p= 0.199 ocp 0.562   \n",
      "professions arousal r 0.523 p= 0.0 ocp 0.658   *\n",
      "sports arousal r 0.279 p= 0.05 ocp 0.597   *\n",
      "cities cost r -0.136 p= 0.346 ocp 0.47   \n",
      "clothing cost r -0.087 p= 0.549 ocp 0.471   \n",
      "states cost r -0.006 p= 0.968 ocp 0.54   \n",
      "animals danger r 0.599 p= 0.0 ocp 0.695   *\n",
      "cities danger r 0.715 p= 0.0 ocp 0.774   *\n",
      "myth danger r 0.723 p= 0.0 ocp 0.779   *\n",
      "professions danger r 0.446 p= 0.001 ocp 0.641   *\n",
      "sports danger r 0.379 p= 0.007 ocp 0.633   *\n",
      "weather danger r 0.79 p= 0.0 ocp 0.797   *\n",
      "animals gender r 0.7 p= 0.0 ocp 0.731   *\n",
      "clothing gender r 0.818 p= 0.0 ocp 0.811   *\n",
      "myth gender r 0.817 p= 0.0 ocp 0.744   *\n",
      "names gender r 0.94 p= 0.0 ocp 0.873   *\n",
      "professions gender r 0.916 p= 0.0 ocp 0.839   *\n",
      "sports gender r 0.854 p= 0.0 ocp 0.817   *\n",
      "animals intelligence r 0.08 p= 0.652 ocp 0.547   \n",
      "cities intelligence r 0.161 p= 0.265 ocp 0.579   \n",
      "names intelligence r 0.651 p= 0.0 ocp 0.737   *\n",
      "professions intelligence r 0.468 p= 0.001 ocp 0.625   *\n",
      "sports intelligence r 0.613 p= 0.0 ocp 0.686   *\n",
      "states intelligence r 0.107 p= 0.46 ocp 0.586   \n",
      "clothing location r 0.323 p= 0.022 ocp 0.584   *\n",
      "professions location r -0.127 p= 0.386 ocp 0.449   \n",
      "sports location r 0.649 p= 0.0 ocp 0.77   *\n",
      "animals loudness r -0.081 p= 0.647 ocp 0.478   \n",
      "states political r 0.399 p= 0.004 ocp 0.651   *\n",
      "cities religiosity r 0.459 p= 0.001 ocp 0.584   *\n",
      "states religiosity r -0.063 p= 0.666 ocp 0.46   \n",
      "animals size r 0.668 p= 0.0 ocp 0.736   *\n",
      "cities size r 0.162 p= 0.26 ocp 0.563   \n",
      "clothing size r 0.097 p= 0.503 ocp 0.53   \n",
      "myth size r 0.704 p= 0.0 ocp 0.762   *\n",
      "states size r 0.331 p= 0.019 ocp 0.576   *\n",
      "animals speed r 0.358 p= 0.037 ocp 0.624   *\n",
      "sports speed r 0.029 p= 0.843 ocp 0.518   \n",
      "cities temperature r -0.086 p= 0.553 ocp 0.469   \n",
      "states temperature r 0.611 p= 0.0 ocp 0.741   *\n",
      "weather temperature r 0.47 p= 0.003 ocp 0.661   *\n",
      "myth valence r 0.643 p= 0.0 ocp 0.732   *\n",
      "professions valence r 0.381 p= 0.007 ocp 0.585   *\n",
      "cities wealth r 0.128 p= 0.377 ocp 0.549   \n",
      "clothing wealth r 0.369 p= 0.008 ocp 0.624   *\n",
      "names wealth r 0.533 p= 0.0 ocp 0.655   *\n",
      "professions wealth r 0.533 p= 0.0 ocp 0.668   *\n",
      "sports wealth r 0.435 p= 0.002 ocp 0.622   *\n",
      "states wealth r 0.47 p= 0.001 ocp 0.622   *\n",
      "animals weight r 0.065 p= 0.714 ocp 0.51   \n",
      "animals wetness r 0.794 p= 0.0 ocp 0.761   *\n",
      "weather wetness r 0.508 p= 0.001 ocp 0.682   *\n"
     ]
    }
   ],
   "source": [
    "# arranging the data in the same order as in the Grand et al paper so we can compare numbers\n",
    "\n",
    "for r in sorted(results, key = lambda r:(r[\"feature\"], r[\"category\"])):\n",
    "    starred = \"*\" if r[\"pearsonr\"] > 0 and r[\"pvalue\"] < 0.05 else \"\"\n",
    "    print(r[\"category\"], r[\"feature\"], \n",
    "          \"r\", round(r[\"pearsonr\"], 3), \"p=\", round(r[\"pvalue\"],3), \n",
    "          \"ocp\", round(r[\"ocp\"], 3), \" \", starred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af2d19-30e9-4223-ad76-5235822767dc",
   "metadata": {},
   "source": [
    "## Fitted dimensions\n",
    "\n",
    "Schockaert and colleagues have a series of papers in which they consider interpretable dimensions in space from a knowledge base point of view. Their methods are completely different from the seed-based approach popular in NLP. We adapt an idea of Jameel and Schockaert to fit a dimension in space to best match human ratings.\n",
    "\n",
    "For every category/feature pair from Grand et al, we obtain a dimension that is a perfect fit to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5f871d-986e-450c-8022-0d9c1672da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [ ]\n",
    "\n",
    "for grandcategory, grandfeature, pos_seedwords, neg_seedwords, df, data_vectors in each_grandcondition(grandratings_dir, grandfeatures_df):\n",
    "    \n",
    "    dimension = compute_dim.dimension_seedbased(pos_seedwords, neg_seedwords, word_vectors)\n",
    "    \n",
    "    # seed-based dimension\n",
    "    df[\"SPred\"]  = compute_dim.predict_scalarproj(data_vectors, dimension)\n",
    "    sresult_obj = stats.pearsonr(df[\"Gold\"], df[\"SPred\"])\n",
    "    \n",
    "    # fitted dimension\n",
    "    dimension, weight, bias = compute_dim.dimension_fitted_fromratings(data_vectors, df[\"Gold\"], feature_dim)\n",
    "    df[\"FPred\"] = compute_dim.predict_coord_fromline(data_vectors, dimension, weight, bias)\n",
    "    fresult_obj = stats.pearsonr(df[\"Gold\"], df[\"FPred\"])\n",
    "    \n",
    "    results.append({\"category\": grandcategory,\n",
    "                    \"feature\" : grandfeature,\n",
    "                    \"s_pearsonr\" : sresult_obj.statistic,\n",
    "                    \"s_pvalue\" : sresult_obj.pvalue,\n",
    "                    \"f_pearsonr\" : fresult_obj.statistic,\n",
    "                    \"f_pvalue\" : fresult_obj.pvalue } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d176a874-d234-4ddb-b551-d45ee454359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of conditions with significant correlations:\n",
      "Seed-based: 0.679\n",
      "Fitted: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of conditions with significant correlations:\")\n",
    "print(\"Seed-based:\", round(len([ r for r in results if r[\"s_pearsonr\"] > 0 and r[\"s_pvalue\"] < 0.05]) / len(results), 3))\n",
    "print(\"Fitted:\", round(len([ r for r in results if r[\"f_pearsonr\"] > 0 and r[\"f_pvalue\"] < 0.05]) / len(results), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5113a5d5-2b38-440b-a8b4-204bc0801b3c",
   "metadata": {},
   "source": [
    "### Underdetermined dimensions\n",
    "\n",
    "However, the embeddings give us too much leeway to fit dimensions in space. Even when we scramble the ratings, the model mostly still manages to fit a dimension perfectly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7aba488-8824-4aa4-83d9-bfb73b5df6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "results = [ ]\n",
    "\n",
    "for grandcategory, grandfeature, pos_seedwords, neg_seedwords, df, data_vectors in each_grandcondition(grandratings_dir, grandfeatures_df):\n",
    "    \n",
    "    data_gold = [row.Gold for row in df.itertuples()]\n",
    "    random.shuffle(data_gold)\n",
    "    \n",
    "    # fitted dimension\n",
    "    dimension, weight, bias = compute_dim.dimension_fitted_fromratings(data_vectors, data_gold, feature_dim)\n",
    "    df[\"Pred\"] = compute_dim.predict_coord_fromline(data_vectors, dimension, weight, bias)\n",
    "    result_obj = stats.pearsonr(data_gold, df[\"Pred\"])\n",
    "    \n",
    "    results.append({\"category\": grandcategory,\n",
    "                    \"feature\" : grandfeature,\n",
    "                    \"pearsonr\" : result_obj.statistic,\n",
    "                    \"pvalue\" : result_obj.pvalue } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da253742-eeef-4d96-b850-e00c38341663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrambled ratings: percentage of dimensions that could be fitted successfully\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Scrambled ratings: percentage of dimensions that could be fitted successfully\")\n",
    "print(round(len([ r for r in results if r[\"pearsonr\"] > 0 and r[\"pvalue\"] < 0.05]) / len(results), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17f8e9-221d-4aa6-963c-b47ee45bd6fe",
   "metadata": {},
   "source": [
    "That also means that the model overfits to the given data, and doesn't generalize well to new datapoints, as we will show below.\n",
    "\n",
    "To mitigate this problem, we combine the fitted model with seed property words, and we will be able to show that this leads to improved dimensions in space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9375c66-1c5a-49d8-93d6-0b16c47224a0",
   "metadata": {},
   "source": [
    "# Variants of the fitted model\n",
    "\n",
    "Seeds as words, match to seed-based dimensions as part of the loss, and both of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce8735-678c-4b14-ab8d-c7442ea3fe10",
   "metadata": {},
   "source": [
    "# Evaluating on unseen data\n",
    "\n",
    "We introduce a train/test split, or rather crossvalidation, to test how well different models do on unseen data.  But when we do that, we cannot use Pearson's r anymore: When there are few datapoints in the dataset, significance computation becomes unreliable.\n",
    "\n",
    "Instead, we will focus on (a variant of) OC_P, and we add mean square error to the picture. OC_P is highly correlated with Pearson's r; MSE less so:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43966ba0-00d5-400e-985d-33bb9a0e379c",
   "metadata": {},
   "source": [
    "The variant of OC_P that we use doesn't just compare pairwise orderings of the datapoints in the test set, but also pairwise orderings of test datapoints compared to training datapoints: Do the test datapoints get inserted at the right point in the overall ordering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d7858-c9cc-44c9-be5b-880ad0c10e2d",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "We make a development set, and use it to set the hyperparameters: offset and jitter for the seeds-as-words, alpha and averaging for seeds-as-dimensions, all of the above for the joint model, alpha for the seed-dimension-attention model. \n",
    "\n",
    "See other notebook. We use:\n",
    "\n",
    "* Fitted model with seed words: offset of 1.3, with jitter.  (which got OC_P of 0.61 with MSE = 13.6)\n",
    "* Fitted model with seed dimensions: alpha = 0.01, with averaging. (which got OC_P of 0.69 with MSE = 2.0)\n",
    "* Fitted model with seed words and seed dimensions: alpha = 0.055, with averaging, jitter, offset of 1.3. (Only alpha was re-fitted.) (this got an OC_P of 0.83 with MSE = 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89756d23-fad5-419a-b5be-b3dcc8aa0b52",
   "metadata": {},
   "source": [
    "## Crossvalidation on all data except the development data\n",
    "\n",
    "See other notebook. We obtain:\n",
    "\n",
    "```Seed-based method: OC_P mean 0.636 (0.12) MSE median 220.202 MSE mean 1177228.385 (12986411.98)```\n",
    "\n",
    "```Fitted method: OC_P mean 0.543 (0.11) MSE median 88.377 MSE mean 20095.844 (255193.91)```\n",
    "\n",
    "```Fitted method with seed words: OC_P mean 0.534 (0.11) MSE median 147.199 MSE mean 16850.911 (227645.29)```\n",
    "\n",
    "```Fitted method with seed dim.s: OC_P mean 0.655 (0.13) MSE median 6.174 MSE mean 1998.254 (27162.71)```\n",
    "\n",
    "```Fitted method, seed words and dim.s: OC_P mean 0.79 (0.08) MSE median 0.624 MSE mean 0.74 (0.5)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d651cf-738e-47c1-bc29-c61080536d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
