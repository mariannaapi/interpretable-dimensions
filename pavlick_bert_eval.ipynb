{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03097e0e-fb41-429e-86e8-6db459e0eac4",
   "metadata": {},
   "source": [
    "# Evaluating on the Pavlick and Nenkova style data, using BERT embeddings\n",
    "\n",
    "# Global settings\n",
    "\n",
    "Expected locations of data:\n",
    "* Pavlick/Nenkova data: \"style-data-Pavlick-Nenkova_2015\", subdirectory of current directory\n",
    "* BERT, RoBERTa: \"emb\", subdirectory of current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab7bcdb-5af0-4f52-846b-20b0d18aa81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pavlick_path = \"./style-data-Pavlick-Nenkova_2015/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35f7a6d-3eed-45de-bbb7-d4c9790e6b07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import math\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efbeba0f-52f3-48e2-909d-382fd298c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_randseeds = 3\n",
    "feature_dim = 1024\n",
    "numfolds = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5f1a9e-6e89-42f9-bc5b-74ec173c5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT variants and hyperparameters\n",
    "\n",
    "bert_dirs = { \"complexity\" : \"emb\" , \"formality\" : \"emb\"}\n",
    "\n",
    "berts = { \"ltop4\" : {\n",
    "              \"path\" : {\"complexity\" : \"bert-large-uncased.complexity.top4layers.pkl\",\n",
    "                        \"formality\" : \"bert-large-uncased.formality.top4layers.pkl\"},\n",
    "              \"offset\" : 1.0,\n",
    "              \"jitter\" : False,\n",
    "              \"alpha1\" : 0.001,\n",
    "              \"average\" : True,\n",
    "              \"alpha2\" : 0.02},\n",
    "         \"robltop4\" : {\n",
    "              \"path\" : {\"complexity\" : \"roberta-large.complexity.top4layers.pkl\",\n",
    "                        \"formality\" : \"roberta-large.formality.top4layers.pkl\"},\n",
    "              \"offset\" : 1.0,\n",
    "              \"jitter\" : False,\n",
    "              \"alpha1\" : 0.001,\n",
    "              \"average\" : True,\n",
    "              \"alpha2\" : 0.02}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba99cb05-1379-41d3-86e4-c51c695ec4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "thisbert = \"robltop4\"\n",
    "thisdataset = \"formality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef50ce94-9ee9-48d1-89fe-88738bb7924d",
   "metadata": {},
   "source": [
    "# Reading the data\n",
    "\n",
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48868c39-ca3d-4a76-a0bf-05fa4dda2ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BERT robltop4 ./roberta-large.formality.top4layers.pkl\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(bert_dirs[thisdataset], berts[thisbert][\"path\"][thisdataset])\n",
    "\n",
    "print(\"Using BERT\", thisbert, filename)\n",
    "\n",
    "with open(filename, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "word_vectors = dict([(w, v.numpy()) for w, v in data.items()])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64d447-7b67-4fba-a1ee-f73599c1f1b0",
   "metadata": {},
   "source": [
    "## Pavlick and Nenkova data\n",
    "\n",
    "There are 1,160 complexity scores and 1,274 formality scores.\n",
    "\n",
    "For each of the two datasets, we z-score the ratings so they will be on a similar scale as the Grand et al ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "678dad11-c493-47e3-9d68-5ee87bc0c149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_filtered_name = { \"complexity\" : \"complexity/human/filtered_complexity_human_scores.txt\",\n",
    "                       \"formality\" : \"formality/human/filtered_formality_human_scores.txt\" }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e09dc377-23e1-41e8-b2e6-b2e2c0bdf511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.428571</td>\n",
       "      <td>someplace</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>chow</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>yeah</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.714286</td>\n",
       "      <td>dressing</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.571429</td>\n",
       "      <td>grandma</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>scrutiny</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>97.285714</td>\n",
       "      <td>endorsement</td>\n",
       "      <td>5.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>97.857143</td>\n",
       "      <td>inequality</td>\n",
       "      <td>5.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>98.142857</td>\n",
       "      <td>exchange</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1274 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating         word    sd\n",
       "0      1.428571    someplace  3.78\n",
       "1      1.571429         chow  3.36\n",
       "2      1.571429         yeah  2.15\n",
       "3      1.714286     dressing  2.93\n",
       "4      2.571429      grandma  4.43\n",
       "...         ...          ...   ...\n",
       "1269  97.000000     scrutiny  4.55\n",
       "1270  97.285714  endorsement  5.31\n",
       "1271  97.857143   inequality  5.67\n",
       "1272  98.000000      adapted  5.29\n",
       "1273  98.142857     exchange  3.76\n",
       "\n",
       "[1274 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_df = pd.read_csv(pavlick_path + human_filtered_name[thisdataset], sep = \"\\s+\", header = None)\n",
    "data_df.columns = [\"rating\", \"word\", \"sd\"]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71357f74-b4eb-4619-847f-bf506e00848e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word</th>\n",
       "      <th>sd</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.428571</td>\n",
       "      <td>someplace</td>\n",
       "      <td>3.78</td>\n",
       "      <td>-1.694189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>chow</td>\n",
       "      <td>3.36</td>\n",
       "      <td>-1.689661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>yeah</td>\n",
       "      <td>2.15</td>\n",
       "      <td>-1.689661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.714286</td>\n",
       "      <td>dressing</td>\n",
       "      <td>2.93</td>\n",
       "      <td>-1.685134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.571429</td>\n",
       "      <td>grandma</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-1.657968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>scrutiny</td>\n",
       "      <td>4.55</td>\n",
       "      <td>1.334787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>97.285714</td>\n",
       "      <td>endorsement</td>\n",
       "      <td>5.31</td>\n",
       "      <td>1.343842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>97.857143</td>\n",
       "      <td>inequality</td>\n",
       "      <td>5.67</td>\n",
       "      <td>1.361953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>5.29</td>\n",
       "      <td>1.366481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>98.142857</td>\n",
       "      <td>exchange</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.371008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1274 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating         word    sd         z\n",
       "0      1.428571    someplace  3.78 -1.694189\n",
       "1      1.571429         chow  3.36 -1.689661\n",
       "2      1.571429         yeah  2.15 -1.689661\n",
       "3      1.714286     dressing  2.93 -1.685134\n",
       "4      2.571429      grandma  4.43 -1.657968\n",
       "...         ...          ...   ...       ...\n",
       "1269  97.000000     scrutiny  4.55  1.334787\n",
       "1270  97.285714  endorsement  5.31  1.343842\n",
       "1271  97.857143   inequality  5.67  1.361953\n",
       "1272  98.000000      adapted  5.29  1.366481\n",
       "1273  98.142857     exchange  3.76  1.371008\n",
       "\n",
       "[1274 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"z\"] = (data_df.rating - data_df.rating.mean()) / data_df.rating.std()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bbc80-e9c9-4e02-9cef-984ebc714c2d",
   "metadata": {},
   "source": [
    "# Seeds\n",
    "\n",
    "Here the seeds come in pairs. Marianna extracted them frmo the Pavlick/Nenkova \"pairs\" data by using the top rated pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bedb2613-585f-49ff-864a-10207e502bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('winner', 'recipient'),\n",
       " ('terrible', 'disastrous'),\n",
       " ('membership', 'affiliation'),\n",
       " ('highest', 'paramount'),\n",
       " ('test', 'verify')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds_str = { \"complexity\" : \"\"\"work - employment\n",
    "further - subsequently\n",
    "strong - powerful\n",
    "train - railway\n",
    "shown - indicated\"\"\",\n",
    "             \"formality\" : \"\"\"winner - recipient\n",
    "terrible - disastrous\n",
    "membership - affiliation\n",
    "highest - paramount\n",
    "test - verify\"\"\"}\n",
    "\n",
    "data_seeds = [ ]\n",
    "for pairstr in seeds_str[thisdataset].split(\"\\n\"):\n",
    "    pair = [s.strip() for s in pairstr.split(\"-\")]\n",
    "    data_seeds.append(tuple(pair))\n",
    "    \n",
    "data_seeds\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ffc051-294c-420d-8243-0f658dd35ac1",
   "metadata": {},
   "source": [
    "## Function for running crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a4f96ee-78eb-4c16-bf36-2c68475d68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_dim\n",
    "import compute_dim\n",
    "import statistics\n",
    "\n",
    "def crossvalidation(method, word_vectors, df, seedpairs, random_seed = 123):\n",
    "    \n",
    "    neg_seedwords = [n for n, _ in seedpairs]\n",
    "    pos_seedwords = [p for _, p in seedpairs]\n",
    "                     \n",
    "    all_vectors = [ word_vectors[w] for w in df.word]\n",
    "    \n",
    "    # crossvalidation setup: give indices to datapoints\n",
    "    rng = np.random.default_rng(seed = 3)\n",
    "    fold = rng.integers(low = 0, high = method[\"numfolds\"], size = len(df.word))\n",
    "\n",
    "    # store the evaluation results from the different test folds\n",
    "    all_evals = [ ]\n",
    "\n",
    "    # iterate over folds, evaluate for each of them\n",
    "    for testfold in range(method[\"numfolds\"]):\n",
    "        # compute training and test data for this fold\n",
    "        test_indices =  [i for i in range(len(df.z)) if fold[i] == testfold]\n",
    "        train_indices = [i for i in range(len(df.z)) if fold[i] != testfold]\n",
    "\n",
    "        gold_test =  [ell[\"z\"] for _, ell in df.iloc[ test_indices ].iterrows()]\n",
    "        gold_train = [ ell[\"z\"] for _, ell in df.iloc[ train_indices ].iterrows()]\n",
    "        words_test =  [ell[\"word\"] for _, ell in df.iloc[ test_indices].iterrows()]\n",
    "        words_train = [ell[\"word\"] for _, ell in df.iloc[ train_indices].iterrows()]\n",
    "        vec_test =  [word_vectors[ w ] for w in words_test]\n",
    "        vec_train = [word_vectors[ w ] for w in words_train ]\n",
    "\n",
    "\n",
    "        # compute seed-based dimension, and its predictions\n",
    "        if method[\"method\"] == \"seedbased\":\n",
    "            dimension = compute_dim.dimension_seedbased(pos_seedwords, neg_seedwords, word_vectors, paired = True)\n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromtrain(vec_train, gold_train, dimension, all_vectors)\n",
    "\n",
    "        elif method[\"method\"] == \"fitted\":\n",
    "            dimension, weight, bias = compute_dim.dimension_fitted_fromratings(vec_train, gold_train, \n",
    "                                                                               method[\"feature_dim\"],\n",
    "                                                                               random_seed = random_seed)\n",
    "\n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromline(all_vectors, dimension, weight, bias)\n",
    "\n",
    "        elif method[\"method\"] == \"fitted_seedwords\":\n",
    "            dimension, weight, bias = compute_dim.dimension_fitted_fromratings_seedwords(vec_train, gold_train, \n",
    "                                                            method[\"feature_dim\"], \n",
    "                                                            pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                            offset = method[\"offset\"], jitter = method[\"jitter\"],\n",
    "                                                            random_seed = random_seed)\n",
    "                                                            \n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromline(all_vectors, dimension, weight, bias)\n",
    "\n",
    "        elif method[\"method\"] == \"fitted_seeddims\":\n",
    "            dimension, weight, bias = compute_dim.dimension_fitted_fromratings_seeddims(vec_train, gold_train, \n",
    "                                                            method[\"feature_dim\"], \n",
    "                                                            pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                            do_average = method[\"do_average\"], \n",
    "                                                            alpha = method[\"alpha\"],\n",
    "                                                            random_seed = random_seed,\n",
    "                                                            paired = True)\n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromline(all_vectors, dimension, weight, bias)\n",
    "\n",
    "        elif method[\"method\"] == \"combined\":\n",
    "            dimension, weight, bias = compute_dim.dimension_fitted_fromratings_combined(vec_train, gold_train,\n",
    "                                                            method[\"feature_dim\"],\n",
    "                                                            pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                            offset = method[\"offset\"], jitter = method[\"jitter\"],\n",
    "                                                            do_average = method[\"do_average\"], \n",
    "                                                            alpha = method[\"alpha\"],\n",
    "                                                            random_seed = random_seed,\n",
    "                                                            paired = True)\n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromline(all_vectors, dimension, weight, bias)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"shouldn't be here\")\n",
    "\n",
    "        # order consistency pairwise: test values tested for their ordering wrt. all values, training and test\n",
    "        # MSE: evaluate on test only\n",
    "        e = { \"ocp\" : eval_dim.pairwise_order_consistency_wrt(df[\"z\"], df[\"Pred\"], test_indices),\n",
    "              \"mse\" : eval_dim.mean_squared_error(gold_test, [p for i, p in enumerate(df[\"Pred\"]) if i in test_indices]) }\n",
    "\n",
    "        all_evals.append(e)\n",
    "\n",
    "        \n",
    "    return all_evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56562490-3542-4384-8709-9ae8b5adfc59",
   "metadata": {},
   "source": [
    "## Aggregating results\n",
    "\n",
    "This is yet different from Grand et al because there are no sub-conditions, just a single dataset.\n",
    "We directly aggregate over all results in the list of results dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a089795d-2ef3-453a-b5a6-c5b816f59f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "# given a list of results dictionaries,\n",
    "# compute mean, median and standard deviation over values for a particular key\n",
    "def eval_summary_by(evals, keylabel):\n",
    "    vals = [e[keylabel] for e in evals if e[keylabel] is not None]\n",
    "    \n",
    "    return (statistics.mean(vals), statistics.median(vals), statistics.stdev(vals))\n",
    "\n",
    "# given a dictionary of results (parameters -> result dictionary list),\n",
    "# all for the same dataset but from different crossvalidatin runs\n",
    "# and runs with different random seeds \n",
    "def eval_eval(results):\n",
    "    ocp_mean, _, _ = eval_summary_by(results, \"ocp\")\n",
    "    mse_mean, mse_med, _ = eval_summary_by(results, \"mse\")\n",
    "    \n",
    "    return ocp_mean, mse_mean, mse_med\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402d22a-ccd2-4d48-99ec-2ea4bef8e70b",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d886147f-eeff-42a9-88f6-24daf097821f",
   "metadata": {},
   "source": [
    "## Seed-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e14a32-90ce-45ba-b6c8-ee273387ac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-based method, data formality\n",
      "OC_P mean 0.674 MSE mean 213.606 MSE median 223.004\n"
     ]
    }
   ],
   "source": [
    "method = { \"method\": \"seedbased\",\n",
    "          \"numfolds\" : numfolds}\n",
    "\n",
    "print(\"Seed-based method, data\", thisdataset)\n",
    "\n",
    "\n",
    "\n",
    "results = crossvalidation(method, word_vectors, data_df, data_seeds)\n",
    "\n",
    "ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "print(f\"OC_P mean {ocp_mean:.3f}\", \n",
    "      f\"MSE mean {mse_mean:.3f}\",\n",
    "      f\"MSE median {mse_med:.3f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b12a6-89d8-4d26-b411-5e797f242936",
   "metadata": {},
   "source": [
    "# Fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c90b464c-8aa8-4bee-b43e-cfb88471e766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted method, data formality\n",
      "OC_P mean 0.529 MSE mean 2957.067 MSE median 324.998\n"
     ]
    }
   ],
   "source": [
    "method = {\"method\": \"fitted\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "print(\"Fitted method, data\", thisdataset)\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "\n",
    "\n",
    "results = [ ]\n",
    "for rval in randoms:\n",
    "    theseresults = crossvalidation(method, word_vectors, data_df,data_seeds,\n",
    "                                   random_seed = rval)\n",
    "    results += theseresults\n",
    "\n",
    "\n",
    "ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "print(f\"OC_P mean {ocp_mean:.3f}\", \n",
    "      f\"MSE mean {mse_mean:.3f}\",\n",
    "      f\"MSE median {mse_med:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad583c-87aa-4301-91f8-ef20c8d6b1d4",
   "metadata": {},
   "source": [
    "# Fitted, with seeds as words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b66072d-8d54-4846-aebb-82dd15edb150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted method with seed words, data formality\n",
      "OC_P mean 0.525 MSE mean 2152.185 MSE median 778.103\n"
     ]
    }
   ],
   "source": [
    "method = { \"method\": \"fitted_seedwords\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"offset\" : 2.0,\n",
    "          \"jitter\" : True,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "print(\"Fitted method with seed words, data\", thisdataset)\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "\n",
    "\n",
    "results = [ ]\n",
    "for rval in randoms:\n",
    "    theseresults = crossvalidation(method, word_vectors, data_df,data_seeds,\n",
    "                                   random_seed = rval)\n",
    "    results += theseresults\n",
    "\n",
    "\n",
    "ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "print(f\"OC_P mean {ocp_mean:.3f}\", \n",
    "      f\"MSE mean {mse_mean:.3f}\",\n",
    "      f\"MSE median {mse_med:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ea81a-e842-4b98-b55a-70f1546574b0",
   "metadata": {},
   "source": [
    "# Fitted, with seed dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "031300f0-6ea8-4236-97cd-ec8a3c34ddbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted method with seed dimensions, data formality\n",
      "OC_P mean 0.656 MSE mean 7.742 MSE median 7.286\n"
     ]
    }
   ],
   "source": [
    "method = { \"method\": \"fitted_seeddims\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"alpha\" : 0.02,\n",
    "          \"do_average\" : True,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "print(\"Fitted method with seed dimensions, data\", thisdataset)\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "\n",
    "results = [ ]\n",
    "for rval in randoms:\n",
    "    theseresults = crossvalidation(method, word_vectors, data_df,data_seeds,\n",
    "                                   random_seed = rval)\n",
    "    results += theseresults\n",
    "\n",
    "\n",
    "ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "print(f\"OC_P mean {ocp_mean:.3f}\", \n",
    "      f\"MSE mean {mse_mean:.3f}\",\n",
    "      f\"MSE median {mse_med:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48623e4-353f-4a1a-87a7-afee68ffad3b",
   "metadata": {},
   "source": [
    "# Fitted, with seeds as words and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "100943aa-d365-42e9-82f1-281f9a1a0381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted method with seeds as words and dim.s, data formality\n",
      "OC_P mean 0.710 MSE mean 2.404 MSE median 2.372\n"
     ]
    }
   ],
   "source": [
    "method = {\"method\": \"combined\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"alpha\" : 0.05,\n",
    "          \"do_average\" : True,\n",
    "          \"offset\" : 2,\n",
    "          \"jitter\" : True,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "print(\"Fitted method with seeds as words and dim.s, data\", thisdataset)\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "\n",
    "\n",
    "results = [ ]\n",
    "for rval in randoms:\n",
    "    theseresults = crossvalidation(method, word_vectors, data_df,data_seeds,\n",
    "                                   random_seed = rval)\n",
    "    results += theseresults\n",
    "\n",
    "\n",
    "ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "print(f\"OC_P mean {ocp_mean:.3f}\", \n",
    "      f\"MSE mean {mse_mean:.3f}\",\n",
    "      f\"MSE median {mse_med:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc6b68-3c91-4e3c-926f-7d0470e6d931",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
