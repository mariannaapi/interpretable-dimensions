{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03097e0e-fb41-429e-86e8-6db459e0eac4",
   "metadata": {},
   "source": [
    "# Evaluating on the Pavlick and Nenkova style data, using word type embeddings\n",
    "\n",
    "# Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35f7a6d-3eed-45de-bbb7-d4c9790e6b07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import math\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbeba0f-52f3-48e2-909d-382fd298c4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n"
     ]
    }
   ],
   "source": [
    "num_randseeds = 3\n",
    "featuredim = 300\n",
    "numfolds = 5\n",
    "\n",
    "param_offset = 1.0\n",
    "param_jitter = False\n",
    "param_average = True\n",
    "param_alpha = 0.02\n",
    "param_alpha_comb = 0.05\n",
    "\n",
    "print(param_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea13fa6d-e771-4c8d-bb6b-8d07e9d11a2b",
   "metadata": {},
   "source": [
    "# Reading in the data.\n",
    "\n",
    "## GLoVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13300f26-03cd-4a57-b54a-7311b3bfe8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../glove/glove.42B.300d.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m feature_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[1;32m      6\u001b[0m word_vectors \u001b[38;5;241m=\u001b[39m { }\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglove_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m azip:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m azip\u001b[38;5;241m.\u001b[39mopen(glove_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/zipfile.py:1284\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../glove/glove.42B.300d.zip'"
     ]
    }
   ],
   "source": [
    "glove_path = \"../glove/glove.42B.300d.zip\"\n",
    "glove_file = \"glove.42B.300d.txt\"\n",
    "\n",
    "feature_dim = 300\n",
    "\n",
    "word_vectors = { }\n",
    "\n",
    "with zipfile.ZipFile(glove_path) as azip:\n",
    "    with azip.open(glove_file) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0].decode()\n",
    "            vector = np.array(values[1:], dtype=np.float32)\n",
    "            word_vectors[word] = vector\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64d447-7b67-4fba-a1ee-f73599c1f1b0",
   "metadata": {},
   "source": [
    "## Pavlick and Nenkova data\n",
    "\n",
    "There are 1,160 complexity scores and 1,274 formality scores.\n",
    "\n",
    "For each of the two datasets, we z-score the ratings so they will be on a similar scale as the Grand et al ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "678dad11-c493-47e3-9d68-5ee87bc0c149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complexity/human/filtered_complexity_human_scores.txt\n"
     ]
    }
   ],
   "source": [
    "# pavlick_path = \"/Users/kee252/Projects/Marianna/interpretable-dimensions/style-data-Pavlick-Nenkova_2015/\"\n",
    "pavlick_path = \"../../github-dimensions/interpretable-dimensions/style-data-Pavlick-Nenkova_2015/\"\n",
    "formality_human_filtered_name = \"formality/human/filtered_formality_human_scores.txt\"\n",
    "complexity_human_filtered_name = \"complexity/human/filtered_complexity_human_scores.txt\"\n",
    "\n",
    "formality_frequency_file = \"/Users/marianna/Documents/NSF-Katrin/jupyter-notebooks/freq_ranking_style/freq_ranking.unsorted.formality\"\n",
    "complexity_frequency_file = \"/Users/marianna/Documents/NSF-Katrin/jupyter-notebooks/freq_ranking_style/freq_ranking.unsorted.complexity\"\n",
    "\n",
    "print(complexity_human_filtered_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e09dc377-23e1-41e8-b2e6-b2e2c0bdf511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.428571</td>\n",
       "      <td>someplace</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>chow</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>yeah</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.714286</td>\n",
       "      <td>dressing</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.571429</td>\n",
       "      <td>grandma</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>scrutiny</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>97.285714</td>\n",
       "      <td>endorsement</td>\n",
       "      <td>5.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>97.857143</td>\n",
       "      <td>inequality</td>\n",
       "      <td>5.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>98.142857</td>\n",
       "      <td>exchange</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1274 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating         word    sd\n",
       "0      1.428571    someplace  3.78\n",
       "1      1.571429         chow  3.36\n",
       "2      1.571429         yeah  2.15\n",
       "3      1.714286     dressing  2.93\n",
       "4      2.571429      grandma  4.43\n",
       "...         ...          ...   ...\n",
       "1269  97.000000     scrutiny  4.55\n",
       "1270  97.285714  endorsement  5.31\n",
       "1271  97.857143   inequality  5.67\n",
       "1272  98.000000      adapted  5.29\n",
       "1273  98.142857     exchange  3.76\n",
       "\n",
       "[1274 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formality_df = pd.read_csv(pavlick_path + formality_human_filtered_name, sep = \"\\s+\", header = None)\n",
    "formality_df.columns = [\"rating\", \"word\", \"sd\"]\n",
    "formality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a74b443-1b3e-4c6e-9b7a-aff177361beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -1.694189\n",
       "1      -1.689661\n",
       "2      -1.689661\n",
       "3      -1.685134\n",
       "4      -1.657968\n",
       "          ...   \n",
       "1269    1.334787\n",
       "1270    1.343842\n",
       "1271    1.361953\n",
       "1272    1.366481\n",
       "1273    1.371008\n",
       "Name: rating, Length: 1274, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(formality_df.rating - formality_df.rating.mean()) / formality_df.rating.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71357f74-b4eb-4619-847f-bf506e00848e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word</th>\n",
       "      <th>sd</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.428571</td>\n",
       "      <td>someplace</td>\n",
       "      <td>3.78</td>\n",
       "      <td>-1.694189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>chow</td>\n",
       "      <td>3.36</td>\n",
       "      <td>-1.689661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>yeah</td>\n",
       "      <td>2.15</td>\n",
       "      <td>-1.689661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.714286</td>\n",
       "      <td>dressing</td>\n",
       "      <td>2.93</td>\n",
       "      <td>-1.685134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.571429</td>\n",
       "      <td>grandma</td>\n",
       "      <td>4.43</td>\n",
       "      <td>-1.657968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>scrutiny</td>\n",
       "      <td>4.55</td>\n",
       "      <td>1.334787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>97.285714</td>\n",
       "      <td>endorsement</td>\n",
       "      <td>5.31</td>\n",
       "      <td>1.343842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>97.857143</td>\n",
       "      <td>inequality</td>\n",
       "      <td>5.67</td>\n",
       "      <td>1.361953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>adapted</td>\n",
       "      <td>5.29</td>\n",
       "      <td>1.366481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>98.142857</td>\n",
       "      <td>exchange</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.371008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1274 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating         word    sd         z\n",
       "0      1.428571    someplace  3.78 -1.694189\n",
       "1      1.571429         chow  3.36 -1.689661\n",
       "2      1.571429         yeah  2.15 -1.689661\n",
       "3      1.714286     dressing  2.93 -1.685134\n",
       "4      2.571429      grandma  4.43 -1.657968\n",
       "...         ...          ...   ...       ...\n",
       "1269  97.000000     scrutiny  4.55  1.334787\n",
       "1270  97.285714  endorsement  5.31  1.343842\n",
       "1271  97.857143   inequality  5.67  1.361953\n",
       "1272  98.000000      adapted  5.29  1.366481\n",
       "1273  98.142857     exchange  3.76  1.371008\n",
       "\n",
       "[1274 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formality_df[\"z\"] = (formality_df.rating - formality_df.rating.mean()) / formality_df.rating.std()\n",
    "formality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8115e4c-4a4b-4a54-aa54-afc148f28bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.285714</td>\n",
       "      <td>walk</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>tells</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.857143</td>\n",
       "      <td>last</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.857143</td>\n",
       "      <td>next</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>94.428571</td>\n",
       "      <td>systematic</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>95.428571</td>\n",
       "      <td>diplomatic</td>\n",
       "      <td>6.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>96.285714</td>\n",
       "      <td>referendum</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>96.714286</td>\n",
       "      <td>archaeological</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>registered</td>\n",
       "      <td>6.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating            word    sd\n",
       "0      0.428571           woman  0.79\n",
       "1      1.285714            walk  2.21\n",
       "2      1.571429           tells  3.31\n",
       "3      1.857143            last  4.10\n",
       "4      1.857143            next  4.49\n",
       "...         ...             ...   ...\n",
       "1155  94.428571      systematic  6.70\n",
       "1156  95.428571      diplomatic  6.43\n",
       "1157  96.285714      referendum  5.25\n",
       "1158  96.714286  archaeological  5.68\n",
       "1159  97.000000      registered  6.35\n",
       "\n",
       "[1160 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity_df = pd.read_csv(pavlick_path + complexity_human_filtered_name, sep = \"\\s+\", header = None)\n",
    "complexity_df.columns = [\"rating\", \"word\", \"sd\"]\n",
    "complexity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81517e99-d5bf-42f4-9d67-a8544c122847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>word</th>\n",
       "      <th>sd</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-1.492158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.285714</td>\n",
       "      <td>walk</td>\n",
       "      <td>2.21</td>\n",
       "      <td>-1.465328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.571429</td>\n",
       "      <td>tells</td>\n",
       "      <td>3.31</td>\n",
       "      <td>-1.456384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.857143</td>\n",
       "      <td>last</td>\n",
       "      <td>4.10</td>\n",
       "      <td>-1.447441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.857143</td>\n",
       "      <td>next</td>\n",
       "      <td>4.49</td>\n",
       "      <td>-1.447441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>94.428571</td>\n",
       "      <td>systematic</td>\n",
       "      <td>6.70</td>\n",
       "      <td>1.450255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>95.428571</td>\n",
       "      <td>diplomatic</td>\n",
       "      <td>6.43</td>\n",
       "      <td>1.481557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>96.285714</td>\n",
       "      <td>referendum</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.508388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>96.714286</td>\n",
       "      <td>archaeological</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.521803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>registered</td>\n",
       "      <td>6.35</td>\n",
       "      <td>1.530747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating            word    sd         z\n",
       "0      0.428571           woman  0.79 -1.492158\n",
       "1      1.285714            walk  2.21 -1.465328\n",
       "2      1.571429           tells  3.31 -1.456384\n",
       "3      1.857143            last  4.10 -1.447441\n",
       "4      1.857143            next  4.49 -1.447441\n",
       "...         ...             ...   ...       ...\n",
       "1155  94.428571      systematic  6.70  1.450255\n",
       "1156  95.428571      diplomatic  6.43  1.481557\n",
       "1157  96.285714      referendum  5.25  1.508388\n",
       "1158  96.714286  archaeological  5.68  1.521803\n",
       "1159  97.000000      registered  6.35  1.530747\n",
       "\n",
       "[1160 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity_df[\"z\"] = (complexity_df.rating - complexity_df.rating.mean()) / complexity_df.rating.std()\n",
    "complexity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88e3458e-aa05-4f05-9206-d53f71897cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             word  frequency  log_frequency\n",
      "0       someplace     533015      13.186305\n",
      "1            chow     369072      12.818747\n",
      "2            yeah   11643327      16.270244\n",
      "3        dressing    3817659      15.155148\n",
      "4         grandma    1134937      13.942088\n",
      "...           ...        ...            ...\n",
      "1269     scrutiny    2737436      14.822532\n",
      "1270  endorsement    4669066      15.356470\n",
      "1271   inequality    2893527      14.877987\n",
      "1272      adapted    5603112      15.538833\n",
      "1273     exchange   38565747      17.467875\n",
      "\n",
      "[1274 rows x 3 columns]\n",
      "                word  frequency  log_frequency\n",
      "0              woman   51276703      17.752747\n",
      "1               walk   27633191      17.134528\n",
      "2              tells   14620721      16.497950\n",
      "3               last  241219808      19.301219\n",
      "4               next  183243510      19.026326\n",
      "...              ...        ...            ...\n",
      "1155      systematic    5141697      15.452894\n",
      "1156      diplomatic    2659134      14.793511\n",
      "1157      referendum    2257890      14.629941\n",
      "1158  archaeological    1825802      14.417530\n",
      "1159      registered   53583190      17.796746\n",
      "\n",
      "[1160 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "frequency_df_formality = pd.read_csv(formality_frequency_file, sep = \"\\s+\", header = None)\n",
    "frequency_df_formality.columns = [\"word\", \"frequency\"]\n",
    "frequency_df_formality[\"log_frequency\"] = np.log(frequency_df_formality[\"frequency\"])\n",
    "\n",
    "frequency_df_complexity = pd.read_csv(complexity_frequency_file, sep = \"\\s+\", header = None)\n",
    "frequency_df_complexity.columns = [\"word\", \"frequency\"]\n",
    "frequency_df_complexity[\"log_frequency\"] = np.log(frequency_df_complexity[\"frequency\"])\n",
    "\n",
    "print(frequency_df_formality)\n",
    "print(frequency_df_complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bbc80-e9c9-4e02-9cef-984ebc714c2d",
   "metadata": {},
   "source": [
    "# Seeds\n",
    "\n",
    "Here the seeds come in pairs. Marianna extracted them frmo the Pavlick/Nenkova \"pairs\" data by using the top rated pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bedb2613-585f-49ff-864a-10207e502bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('work', 'employment'),\n",
       " ('further', 'subsequently'),\n",
       " ('strong', 'powerful'),\n",
       " ('train', 'railway'),\n",
       " ('shown', 'indicated')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity_seeds_str = \"\"\"work - employment\n",
    "further - subsequently\n",
    "strong - powerful\n",
    "train - railway\n",
    "shown - indicated\"\"\"\n",
    "complexity_seeds = [ ]\n",
    "for pairstr in complexity_seeds_str.split(\"\\n\"):\n",
    "    pair = [s.strip() for s in pairstr.split(\"-\")]\n",
    "    complexity_seeds.append(tuple(pair))\n",
    "    \n",
    "complexity_seeds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78ab5260-b597-40bc-bc5d-7e3b6e27f7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('winner', 'recipient'),\n",
       " ('terrible', 'disastrous'),\n",
       " ('membership', 'affiliation'),\n",
       " ('highest', 'paramount'),\n",
       " ('test', 'verify')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formality_seeds_str = \"\"\"winner - recipient\n",
    "terrible - disastrous\n",
    "membership - affiliation\n",
    "highest - paramount\n",
    "test - verify\"\"\"\n",
    "formality_seeds = [ ]\n",
    "for pairstr in formality_seeds_str.split(\"\\n\"):\n",
    "    pair = [s.strip() for s in pairstr.split(\"-\")]\n",
    "    formality_seeds.append(tuple(pair))\n",
    "    \n",
    "formality_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ffc051-294c-420d-8243-0f658dd35ac1",
   "metadata": {},
   "source": [
    "## Function for running crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4a4f96ee-78eb-4c16-bf36-2c68475d68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_dim\n",
    "import compute_dim\n",
    "import statistics\n",
    "\n",
    "def crossvalidation(method, word_vectors, df, seedpairs, random_seed = 123):\n",
    "    \n",
    "    neg_seedwords = [n for n, _ in seedpairs]\n",
    "    pos_seedwords = [p for _, p in seedpairs]\n",
    "                     \n",
    "    all_vectors = [ word_vectors[w] for w in df.word]\n",
    "    \n",
    "    # crossvalidation setup: give indices to datapoints\n",
    "    rng = np.random.default_rng(seed = 3)\n",
    "    fold = rng.integers(low = 0, high = method[\"numfolds\"], size = len(df.word))\n",
    "\n",
    "    # store the evaluation results from the different test folds\n",
    "    all_evals = [ ]\n",
    "\n",
    "    # iterate over folds, evaluate for each of them\n",
    "    for testfold in range(method[\"numfolds\"]):\n",
    "        # compute training and test data for this fold\n",
    "        test_indices =  [i for i in range(len(df.z)) if fold[i] == testfold]\n",
    "        train_indices = [i for i in range(len(df.z)) if fold[i] != testfold]\n",
    "        \n",
    "        gold_test =  [ell[\"z\"] for _, ell in df.iloc[ test_indices ].iterrows()]\n",
    "        gold_train = [ell[\"z\"] for _, ell in df.iloc[ train_indices ].iterrows()]\n",
    "        \n",
    "        words_test =  [ell[\"word\"] for _, ell in df.iloc[ test_indices].iterrows()]\n",
    "        words_train = [ell[\"word\"] for _, ell in df.iloc[ train_indices].iterrows()]\n",
    "        \n",
    "        vec_test =  [word_vectors[ w ] for w in words_test]\n",
    "        vec_train = [word_vectors[ w ] for w in words_train ]\n",
    "\n",
    "\n",
    "        # compute seed-based dimension, and its predictions\n",
    "        if method[\"method\"] == \"seedbased\":\n",
    "            dimension = compute_dim.dimension_seedbased(pos_seedwords, neg_seedwords, word_vectors, paired = True)\n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromtrain(vec_train, gold_train, dimension, all_vectors)\n",
    "            predictions = df[\"Pred\"]\n",
    "            print('PREDICTIONS ====>','\\n')\n",
    "            print(predictions)\n",
    "\n",
    "        elif method[\"method\"] == \"fitted\":\n",
    "            dimension, weight, bias = compute_dim.dimension_fitted_fromratings(vec_train, gold_train, \n",
    "                                                                               method[\"feature_dim\"],\n",
    "                                                                               random_seed = random_seed)\n",
    "\n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromline(all_vectors, dimension, weight, bias)\n",
    "\n",
    "        elif method[\"method\"] == \"fitted_seedwords\":\n",
    "            dimension, weight, bias = compute_dim.dimension_fitted_fromratings_seedwords(vec_train, gold_train, \n",
    "                                                            method[\"feature_dim\"], \n",
    "                                                            pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                            offset = method[\"offset\"], jitter = method[\"jitter\"],\n",
    "                                                            random_seed = random_seed)\n",
    "                                                            \n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromline(all_vectors, dimension, weight, bias)\n",
    "\n",
    "        elif method[\"method\"] == \"fitted_seeddims\":\n",
    "            dimension, weight, bias = compute_dim.dimension_fitted_fromratings_seeddims(vec_train, gold_train, \n",
    "                                                            method[\"feature_dim\"], \n",
    "                                                            pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                            do_average = method[\"do_average\"], \n",
    "                                                            alpha = method[\"alpha\"],\n",
    "                                                            random_seed = random_seed,\n",
    "                                                            paired = True)\n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromline(all_vectors, dimension, weight, bias)\n",
    "\n",
    "        elif method[\"method\"] == \"combined\":\n",
    "            dimension, weight, bias = compute_dim.dimension_fitted_fromratings_combined(vec_train, gold_train,\n",
    "                                                            method[\"feature_dim\"],\n",
    "                                                            pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                            offset = method[\"offset\"], jitter = method[\"jitter\"],\n",
    "                                                            do_average = method[\"do_average\"], \n",
    "                                                            alpha = method[\"alpha\"],\n",
    "                                                            random_seed = random_seed,\n",
    "                                                            paired = True)\n",
    "            df[\"Pred\"] = compute_dim.predict_coord_fromline(all_vectors, dimension, weight, bias)\n",
    "\n",
    "        elif method[\"method\"] == \"frequency\":\n",
    "            if df is formality_df:\n",
    "                df[\"Pred\"] = frequency_df_formality[\"log_frequency\"]\n",
    "            elif df is complexity_df:\n",
    "                df[\"Pred\"] = frequency_df_complexity[\"log_frequency\"]\n",
    "\n",
    "            # weight, bias = compute_dim.fit_dimension_coef(df[\"z\"], df[\"Pred\"])\n",
    "            \n",
    "            pred_train = [ell[\"Pred\"] for _, ell in df.iloc[ train_indices ].iterrows()]\n",
    "            weight, bias = compute_dim.fit_dimension_coef(gold_train, pred_train)\n",
    "            print('weight : ', weight, 'bias : ', bias)\n",
    "            updated_model_predictions = [(v - bias) / weight for v in df[\"Pred\"]]\n",
    "            df[\"Pred\"] = updated_model_predictions\n",
    "            \n",
    "        elif method[\"method\"] == \"random\":\n",
    "            np.random.seed(8)\n",
    "            df[\"Pred\"] = np.random.uniform(-3, 3, size=len(df))\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"shouldn't be here\")\n",
    "\n",
    "        # weight, bias = compute_dim.fit_dimension_coef(gold_ratings, model_predictions)\n",
    "        # updated_model_predictions = [(v - bias) / weight for v in model_predictions]\n",
    "        \n",
    "\n",
    "        \n",
    "        # for ind in test_indices:\n",
    "            # gold_scores = df[\"z\"]\n",
    "            # frequencies = df[\"Pred\"]\n",
    "            # words = frequency_df_formality[\"word\"]\n",
    "            \n",
    "            # gold_df_row = df.iloc[ind]\n",
    "            # if df is formality_df:\n",
    "            #     freq_df_row = frequency_df_formality.iloc[ind]\n",
    "            # elif df is complexity_df:\n",
    "            #     freq_df_row = frequency_df_complexity.iloc[ind]\n",
    "               \n",
    "            # if freq_df_row['word'] == gold_df_row['word']:\n",
    "            #     print('yes',freq_df_row['word'], gold_df_row['word'] )\n",
    "            # else:\n",
    "            #     print('no', freq_df_row['word'], gold_df_row['word'] )\n",
    "            \n",
    "                       \n",
    "        # order consistency pairwise: test values tested for their ordering wrt. all values, training and test\n",
    "        # MSE: evaluate on test only\n",
    "        e = { \"ocp\" : eval_dim.pairwise_order_consistency_wrt(df[\"z\"], df[\"Pred\"], test_indices),\n",
    "              \"mse\" : eval_dim.mean_squared_error(gold_test, [p for i, p in enumerate(df[\"Pred\"]) if i in test_indices]) }\n",
    "        \n",
    "        \n",
    "        all_evals.append(e)\n",
    "\n",
    "        \n",
    "    return all_evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56562490-3542-4384-8709-9ae8b5adfc59",
   "metadata": {},
   "source": [
    "## Aggregating results\n",
    "\n",
    "This is yet different from Grand et al because there are no sub-conditions, just a single dataset.\n",
    "We directly aggregate over all results in the list of results dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a089795d-2ef3-453a-b5a6-c5b816f59f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "# given a list of results dictionaries,\n",
    "# compute mean, median and standard deviation over values for a particular key\n",
    "def eval_summary_by(evals, keylabel):\n",
    "    vals = [e[keylabel] for e in evals if e[keylabel] is not None]\n",
    "    \n",
    "    return (statistics.mean(vals), statistics.median(vals), statistics.stdev(vals))\n",
    "\n",
    "# given a dictionary of results (parameters -> result dictionary list),\n",
    "# all for the same dataset but from different crossvalidatin runs\n",
    "# and runs with different random seeds \n",
    "def eval_eval(results):\n",
    "    ocp_mean, _, _ = eval_summary_by(results, \"ocp\")\n",
    "    mse_mean, mse_med, _ = eval_summary_by(results, \"mse\")\n",
    "    \n",
    "    return ocp_mean, mse_mean, mse_med\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402d22a-ccd2-4d48-99ec-2ea4bef8e70b",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7bd392-394e-4434-a1f7-641130389ab8",
   "metadata": {},
   "source": [
    "## Frequency baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f699ab88-82f2-4fb6-be21-94593519f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency baseline\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "weight :  -0.6040857055504381 bias :  16.24218282729719\n",
      "weight : Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      " -0.6375991695149622 bias :  16.243017910732004\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "weight :  -0.6043147085429749 bias :  16.207235857737775\n",
      "weight : Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      " -0.5915526080360562 bias :  16.17362259596061\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "weight :  -0.6197853745973927 bias :  16.205389904037133\n",
      "\t Formality dataset OC_P mean 0.628 MSE mean 5.597 MSE median 5.661\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "weight :  -0.5697591003174673 bias :  16.704869171874066\n",
      "weight : Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      " -0.591029221365656 bias :  16.696095732365826\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "weight :  -0.6432730861942514 bias :  16.733279779585843\n",
      "weight : Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      " -0.6642054036207731 bias :  16.681237057260443\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "weight :  -0.6444458498738662 bias :  16.704219345014856\n",
      "\t Complexity dataset OC_P mean 0.646 MSE mean 4.552 MSE median 4.561\n"
     ]
    }
   ],
   "source": [
    "method = {\"method\": \"frequency\",\n",
    "          \"numfolds\" : numfolds}\n",
    "\n",
    "print(\"Frequency baseline\")\n",
    "\n",
    "for data_label, data_df, data_seeds in [ (\"Formality\", formality_df, formality_seeds), \n",
    "                                         (\"Complexity\", complexity_df, complexity_seeds) ]:\n",
    "\n",
    "    # frequency_df_formality, frequency_df_complexity\n",
    "    results = crossvalidation(method, word_vectors, data_df, data_seeds)\n",
    "\n",
    "    ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "    print(\"\\t\", data_label, \"dataset\", \n",
    "          f\"OC_P mean {ocp_mean:.3f}\", \n",
    "          f\"MSE mean {mse_mean:.3f}\", \n",
    "          f\"MSE median {mse_med:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd5c1b-e8ba-4641-99c1-7eb35c16b5d1",
   "metadata": {},
   "source": [
    "# Random baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a9ff5e1-c5b4-414e-bfff-020fc3398474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random baseline\n",
      "\t Formality dataset OC_P mean 0.51 MSE mean 3.79 MSE median 3.84\n",
      "\t Complexity dataset OC_P mean 0.50 MSE mean 3.81 MSE median 3.95\n"
     ]
    }
   ],
   "source": [
    "method = {\"method\": \"random\",\n",
    "          \"numfolds\": numfolds}\n",
    "\n",
    "print(\"Random baseline\")\n",
    "\n",
    "for data_label, data_df, data_seeds in [ (\"Formality\", formality_df, formality_seeds), \n",
    "                                         (\"Complexity\", complexity_df, complexity_seeds) ]:\n",
    "    \n",
    "    results = crossvalidation(method, word_vectors, data_df, data_seeds)\n",
    "\n",
    "    ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "    print(\"\\t\", data_label, \"dataset\", \n",
    "          f\"OC_P mean {ocp_mean:.2f}\", \n",
    "          f\"MSE mean {mse_mean:.2f}\", \n",
    "          f\"MSE median {mse_med:.2f}\")\n",
    "\n",
    "# print(\"Random baseline:\", \n",
    "#       f\"OC_P mean {ocp_mean:.2f}\", \n",
    "#       # f\"MSE mean {mse_mean:.3f}\", \n",
    "#       f\"MSE mean {msemean_mean:.3f}\", \n",
    "#       # f\"MSE median {mse_med:.3f}\")\n",
    "#       f\"MSE median {msemed_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d886147f-eeff-42a9-88f6-24daf097821f",
   "metadata": {},
   "source": [
    "## Seed-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e14a32-90ce-45ba-b6c8-ee273387ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = { \"method\": \"seedbased\",\n",
    "          \"numfolds\" : numfolds}\n",
    "\n",
    "print(\"Seed-based method\")\n",
    "\n",
    "for data_label, data_df, data_seeds in [ (\"Formality\", formality_df, formality_seeds), \n",
    "                                         (\"Complexity\", complexity_df, complexity_seeds) ]:\n",
    "\n",
    "    print('formality_df : ')\n",
    "    print(formality_df)\n",
    "    results = crossvalidation(method, word_vectors, data_df, data_seeds)\n",
    "    \n",
    "    ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "    print(\"\\t\", data_label, \"dataset\", \n",
    "          f\"OC_P mean {ocp_mean:.3f}\", \n",
    "          f\"MSE mean {mse_mean:.3f}\",\n",
    "          f\"MSE median {mse_med:.3f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b12a6-89d8-4d26-b411-5e797f242936",
   "metadata": {},
   "source": [
    "# Fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c90b464c-8aa8-4bee-b43e-cfb88471e766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted method\n",
      "testfold\n",
      "testfold\n",
      "testfold\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m [ ]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rval \u001b[38;5;129;01min\u001b[39;00m randoms:\n\u001b[0;32m---> 14\u001b[0m     theseresults \u001b[38;5;241m=\u001b[39m \u001b[43mcrossvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_seeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m theseresults\n\u001b[1;32m     19\u001b[0m ocp_mean, mse_mean, mse_med \u001b[38;5;241m=\u001b[39m eval_eval(results)\n",
      "Cell \u001b[0;32mIn[13], line 42\u001b[0m, in \u001b[0;36mcrossvalidation\u001b[0;34m(method, word_vectors, df, seedpairs, random_seed)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPREDICTIONS ====>\u001b[39m\u001b[38;5;124m'\u001b[39m, predictions)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitted\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m     dimension, weight, bias \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_dim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimension_fitted_fromratings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgold_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeature_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPred\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compute_dim\u001b[38;5;241m.\u001b[39mpredict_coord_fromline(all_vectors, dimension, weight, bias)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitted_seedwords\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/NSF-Katrin/jupyter-notebooks/freq_eval/compute_dim.py:76\u001b[0m, in \u001b[0;36mdimension_fitted_fromratings\u001b[0;34m(word_vectors_list, gold_ratings, feature_dim, random_seed)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Average loss over all words in X_train or in the whole human dic (2,801 annotated single words in total)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# avg_loss = total_loss / len(X_train)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(word_vectors_list)\n\u001b[0;32m---> 76\u001b[0m \u001b[43mavg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Compute the gradient norms and monitor them during training\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# feature_vector_grad_norm = torch.norm(feature_vector.grad)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# print(f\"Step {step+1}, Feature Vector Gradient Norm: {feature_vector_grad_norm.item()}\")\u001b[39;00m\n\u001b[1;32m     83\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_([feature_vector, weight_constant, bias_constant], max_norm)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "method = {\"method\": \"fitted\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "print(\"Fitted method\")\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "\n",
    "for data_label, data_df, data_seeds in [ (\"Formality\", formality_df, formality_seeds), \n",
    "                                         (\"Complexity\", complexity_df, complexity_seeds) ]:\n",
    "    results = [ ]\n",
    "    for rval in randoms:\n",
    "        theseresults = crossvalidation(method, word_vectors, data_df,data_seeds,\n",
    "                                       random_seed = rval)\n",
    "        results += theseresults\n",
    "        \n",
    "    \n",
    "    ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "    print(\"\\t\", data_label, \"dataset\", \n",
    "          f\"OC_P mean {ocp_mean:.3f}\", \n",
    "          f\"MSE mean {mse_mean:.3f}\", \n",
    "          f\"MSE median {mse_med:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad583c-87aa-4301-91f8-ef20c8d6b1d4",
   "metadata": {},
   "source": [
    "# Fitted, with seeds as words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66072d-8d54-4846-aebb-82dd15edb150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "method = { \"method\": \"fitted_seedwords\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"offset\" : 2.0,\n",
    "          \"jitter\" : True,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "print(\"Fitted method with seed words\")\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "\n",
    "for data_label, data_df, data_seeds in [ (\"Formality\", formality_df, formality_seeds), \n",
    "                                         (\"Complexity\", complexity_df, complexity_seeds) ]:\n",
    "    results = [ ]\n",
    "    for rval in randoms:\n",
    "        theseresults = crossvalidation(method, word_vectors, data_df,data_seeds,\n",
    "                                       random_seed = rval)\n",
    "        results += theseresults\n",
    "        \n",
    "    \n",
    "    ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "    print(\"\\t\", data_label, \"dataset\", \n",
    "          f\"OC_P mean {ocp_mean:.3f}\", \n",
    "          f\"MSE mean {mse_mean:.3f}\", \n",
    "          f\"MSE median {mse_med:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ea81a-e842-4b98-b55a-70f1546574b0",
   "metadata": {},
   "source": [
    "# Fitted, with seed dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031300f0-6ea8-4236-97cd-ec8a3c34ddbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "method = { \"method\": \"fitted_seeddims\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"alpha\" : 0.02,\n",
    "          \"do_average\" : True,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "print(\"Fitted method with seed dimensions\")\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "\n",
    "for data_label, data_df, data_seeds in [ (\"Formality\", formality_df, formality_seeds), \n",
    "                                         (\"Complexity\", complexity_df, complexity_seeds) ]:\n",
    "    results = [ ]\n",
    "    for rval in randoms:\n",
    "        theseresults = crossvalidation(method, word_vectors, data_df,data_seeds,\n",
    "                                       random_seed = rval)\n",
    "        results += theseresults\n",
    "        \n",
    "    \n",
    "    ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "    print(\"\\t\", data_label, \"dataset\", \n",
    "          f\"OC_P mean {ocp_mean:.3f}\", \n",
    "          f\"MSE mean {mse_mean:.3f}\",\n",
    "          f\"MSE median {mse_med:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48623e4-353f-4a1a-87a7-afee68ffad3b",
   "metadata": {},
   "source": [
    "# Fitted, with seeds as words and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100943aa-d365-42e9-82f1-281f9a1a0381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "method = {\"method\": \"combined\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"alpha\" : 0.05,\n",
    "          \"do_average\" : True,\n",
    "          \"offset\" : 2,\n",
    "          \"jitter\" : True,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "print(\"Fitted method with seeds as words and dim.s\")\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "\n",
    "for data_label, data_df, data_seeds in [ (\"Formality\", formality_df, formality_seeds), \n",
    "                                         (\"Complexity\", complexity_df, complexity_seeds) ]:\n",
    "    results = [ ]\n",
    "    for rval in randoms:\n",
    "        theseresults = crossvalidation(method, word_vectors, data_df,data_seeds,\n",
    "                                       random_seed = rval)\n",
    "        results += theseresults\n",
    "        \n",
    "    \n",
    "    ocp_mean, mse_mean, mse_med = eval_eval(results)\n",
    "\n",
    "    print(\"\\t\", data_label, \"dataset\", \n",
    "          f\"OC_P mean {ocp_mean:.3f}\", \n",
    "          f\"MSE mean {mse_mean:.3f}\", \n",
    "          f\"MSE median {mse_med:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
