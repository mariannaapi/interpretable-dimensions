{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f0d2475-3fe2-4b3d-bb49-3c727b0413f8",
   "metadata": {},
   "source": [
    "# running through all the datasets in Grand et al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184ac520-a284-411b-a798-1629055cd93d",
   "metadata": {},
   "source": [
    "# Reading the GLoVE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2753dae-bf0e-4721-9974-d2a7ceb5df94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import math\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f63d1a-f009-4093-93db-b0b0f6532e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glove_path = \"glove/glove.42B.300d.zip\"\n",
    "glove_file = \"glove.42B.300d.txt\"\n",
    "\n",
    "feature_dim = 300\n",
    "\n",
    "word_vectors = { }\n",
    "\n",
    "with zipfile.ZipFile(glove_path) as azip:\n",
    "    with azip.open(glove_file) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0].decode()\n",
    "            vector = np.array(values[1:], dtype=np.float32)\n",
    "            word_vectors[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582747bb-3e42-414d-bc99-b4a68f52f148",
   "metadata": {},
   "source": [
    "# Read Grand features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce095bb2-f610-4a31-a720-1a6d51e48173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kee252/Library/Python/3.9/lib/python/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "grandratings_dir = \"Grand_etal_csv/\"\n",
    "grandfeatures_path = \"/Users/kee252/Data/grand_directions_in_space/features.xlsx\"\n",
    "\n",
    "grandfeatures_df = pd.read_excel(grandfeatures_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8f4bf8-5368-4f18-935e-ca2de15668a0",
   "metadata": {},
   "source": [
    "# Relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef1f4ae-2e2d-41cd-b8fb-a50671f0ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging over seed pair vectors\n",
    "def average_dim_vector(seeds_pos, seeds_neg, space):\n",
    "    diffvectors = [ ]\n",
    "    \n",
    "    for negword in seeds_neg:\n",
    "        for posword in seeds_pos:\n",
    "            diffvectors.append(space[posword] - space[negword])\n",
    "\n",
    "    # average\n",
    "    dimvec = np.mean(diffvectors, axis = 0)\n",
    "    return dimvec\n",
    "\n",
    "# scalar projection of a vector along a given direction:\n",
    "# length of the projection vector\n",
    "# (vec * direction) / ||direction||\n",
    "def vector_scalar_projection(vec, direction):\n",
    "    dir_veclen = math.sqrt(np.dot(direction, direction))\n",
    "    return np.dot(vec, direction) / dir_veclen\n",
    "\n",
    "# projection of a vector along a direction,\n",
    "# where we want the actual vector, not its length\n",
    "# (vec * direction1) * direction1\n",
    "def vector_projection(vec, direction):\n",
    "    dir_veclen = math.sqrt(np.dot(direction, direction))\n",
    "    direction1 = direction / dir_veclen\n",
    "    return np.dot(vec, direction1) * direction1\n",
    "\n",
    "# computing a fitted dimension based on a list of word vectors and matching list of gold ratings.\n",
    "# feature_dim is dimensionality of the vectors. \n",
    "# This fits a dimension using an objective function based on the Jameel and Schockaert idea\n",
    "def ideal_dimension(word_vectors_list, gold_ratings, feature_dim, random_seed = 123):\n",
    "    torch.manual_seed(random_seed) \n",
    "\n",
    "    # we compute: a vector of same dimensionality as our embeddings,\n",
    "    # and a weight and a bias constant\n",
    "    feature_vector = torch.randn(feature_dim, requires_grad=True) # dtype=torch.float32)\n",
    "    weight_constant = torch.randn(1, requires_grad=True) \n",
    "    bias_constant = torch.randn(1, requires_grad=True)    \n",
    "\n",
    "    \n",
    "    optimizer = optim.Adam([feature_vector, weight_constant, bias_constant], lr=0.01)\n",
    "    # optimizer = optim.SGD([feature_vector, weight_constant, bias_constant], lr=0.001)\n",
    "\n",
    "    # Number of optimization steps\n",
    "    num_steps = 1000\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    # Gradient clipping threshold\n",
    "    max_norm = 1.0  \n",
    "\n",
    "    for step in range(num_steps):\n",
    "        total_loss = 0\n",
    "\n",
    "        # for i in range(len(X_train)):\n",
    "        # \tword_embedding = torch.tensor(X_train[i]) \n",
    "        # \tgold_rating = y_train[i]\n",
    "\n",
    "        for i in range(len(word_vectors_list)):\n",
    "            word_embedding = torch.tensor(word_vectors_list[i])\n",
    "            gold_rating = gold_ratings[i]\n",
    "\n",
    "            dot_product = torch.dot(word_embedding, feature_vector)\n",
    "            weighted_gold = gold_rating * weight_constant\n",
    "            loss = ((dot_product - weighted_gold - bias_constant) ** 2)\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "        # Average loss over all words in X_train or in the whole human dic (2,801 annotated single words in total)\n",
    "        # avg_loss = total_loss / len(X_train)\n",
    "        avg_loss = total_loss / len(word_vectors_list)\n",
    "\n",
    "        avg_loss.backward()\n",
    "\n",
    "        # Compute the gradient norms and monitor them during training\n",
    "\n",
    "        # feature_vector_grad_norm = torch.norm(feature_vector.grad)\n",
    "        # print(f\"Step {step+1}, Feature Vector Gradient Norm: {feature_vector_grad_norm.item()}\")\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_([feature_vector, weight_constant, bias_constant], max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(avg_loss.item())\n",
    "    \n",
    "    return (feature_vector.detach().numpy(), weight_constant.item(), bias_constant.item())\n",
    "\n",
    "# we have defined our loss to shoot for\n",
    "# (vec * direction) \\approx weight* goldrating + bias\n",
    "# hence the predicted rating is\n",
    "# predictedrating = ((vec * direction) - bias ) / weight\n",
    "def iprediction(vec, direction, weight, bias):\n",
    "    return (np.dot(vec, direction) - bias) / weight\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6ae77b-91f2-4e3a-8b54-7a3d398a30af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading in Grand data\n",
    "def read_grand_data(filename, grandratings_dir, grandfeatures_df):\n",
    "    # extract category and feature\n",
    "    grandcategory, grandfeature = filename[:-4].split(\"_\")\n",
    "        \n",
    "    # read human ratings, make gold column\n",
    "    df = pd.read_csv(grandratings_dir + filename)\n",
    "    df[\"Average\"] = [row.iloc[1:26].sum() / 25 for _, row in df.iterrows()]\n",
    "    # z-scores of average ratings\n",
    "    df[\"Gold\"] = (df[\"Average\"] - df[\"Average\"].mean()) / df[\"Average\"].std()\n",
    "        \n",
    "    # obtain seed words from excel file\n",
    "    relevant_row = grandfeatures_df[grandfeatures_df.Dimension == grandfeature]\n",
    "    seedwords = relevant_row.iloc[:, 1:].values.flatten().tolist()\n",
    "    pos_seedwords = seedwords[:3]\n",
    "    neg_seedwords = seedwords[3:]\n",
    "    \n",
    "    return (grandcategory, grandfeature, pos_seedwords, neg_seedwords, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450cab3e-8665-4ea3-9ddb-f814e9abb40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# fitted dimensions come with a weight and bias for prediction. \n",
    "# we can compute those also for seed-based dimensions\n",
    "# to make predictions on the same order of magnitude as the original ratings.\n",
    "# We need that in order to do a Mean Squared Error (MSE) evaluation.\n",
    "# \n",
    "# This function uses linear regression to compute weight and bias. formula:\n",
    "#\n",
    "# model_rating ~ weight * gold_rating + bias\n",
    "#\n",
    "# formulated this way round to match the formulation in the objective function\n",
    "# of the fitted dimensions model\n",
    "def coef_for_seed_dimension(gold_ratings, model_ratings):\n",
    "    result = stats.linregress(gold_ratings, model_ratings)\n",
    "    \n",
    "    return (result.slope, result.intercept)\n",
    "\n",
    "# given a scalar projection on a seed-based dimension,\n",
    "# along with weight and bias computed by\n",
    "# coef_for_seed_dimension,\n",
    "# compute a predicted rating.\n",
    "def sprediction(sprojection, weight, bias):\n",
    "    return (sprojection - bias) / weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf267b-5e4f-4c5a-b0e6-9de527f50d76",
   "metadata": {},
   "source": [
    "# Correlation with human ratings: seed-based versus fitted dimensions\n",
    "\n",
    "We compute fitted dimensions from the entirety of the human ratings data. We also compute seed-based dimensions.\n",
    "We evaluate both of them using Pearson's r for correlation with human ratings.\n",
    "\n",
    "We find that we can in all cases compute a near-perfect dimension matching the human ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c37e2d-66c8-4137-a9b5-d74e98120d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-based versus fitted dimensions, correlation with human ratings\n",
      "cities      -temperature  Pred r=-0.086 p=0.553 IPred =0.986 p=0.000\n",
      "professions -intelligence Pred r=0.468 p=0.001 IPred =0.999 p=0.000\n",
      "cities      -intelligence Pred r=0.161 p=0.265 IPred =0.997 p=0.000\n",
      "clothing    -location     Pred r=0.323 p=0.022 IPred =0.996 p=0.000\n",
      "cities      -arousal      Pred r=0.001 p=0.996 IPred =0.994 p=0.000\n",
      "clothing    -arousal      Pred r=0.185 p=0.199 IPred =0.987 p=0.000\n",
      "states      -size         Pred r=0.331 p=0.019 IPred =0.992 p=0.000\n",
      "sports      -intelligence Pred r=0.613 p=0.000 IPred =0.998 p=0.000\n",
      "names       -age          Pred r=0.616 p=0.000 IPred =0.999 p=0.000\n",
      "clothing    -wealth       Pred r=0.369 p=0.008 IPred =0.998 p=0.000\n",
      "weather     -danger       Pred r=0.790 p=0.000 IPred =0.996 p=0.000\n",
      "professions -danger       Pred r=0.446 p=0.001 IPred =0.993 p=0.000\n",
      "clothing    -size         Pred r=0.097 p=0.503 IPred =0.993 p=0.000\n",
      "animals     -size         Pred r=0.668 p=0.000 IPred =0.998 p=0.000\n",
      "sports      -wealth       Pred r=0.435 p=0.002 IPred =0.997 p=0.000\n",
      "professions -valence      Pred r=0.381 p=0.007 IPred =0.999 p=0.000\n",
      "names       -wealth       Pred r=0.533 p=0.000 IPred =0.998 p=0.000\n",
      "cities      -cost         Pred r=-0.136 p=0.346 IPred =0.994 p=0.000\n",
      "cities      -wealth       Pred r=0.128 p=0.377 IPred =0.986 p=0.000\n",
      "professions -gender       Pred r=0.916 p=0.000 IPred =0.998 p=0.000\n",
      "states      -religiosity  Pred r=-0.063 p=0.666 IPred =0.991 p=0.000\n",
      "clothing    -age          Pred r=0.561 p=0.000 IPred =0.995 p=0.000\n",
      "weather     -wetness      Pred r=0.508 p=0.001 IPred =0.993 p=0.000\n",
      "professions -wealth       Pred r=0.533 p=0.000 IPred =0.995 p=0.000\n",
      "myth        -valence      Pred r=0.643 p=0.000 IPred =0.997 p=0.000\n",
      "clothing    -cost         Pred r=-0.087 p=0.549 IPred =0.997 p=0.000\n",
      "professions -age          Pred r=0.238 p=0.100 IPred =0.995 p=0.000\n",
      "myth        -size         Pred r=0.704 p=0.000 IPred =0.992 p=0.000\n",
      "sports      -danger       Pred r=0.379 p=0.007 IPred =0.997 p=0.000\n",
      "names       -gender       Pred r=0.940 p=0.000 IPred =1.000 p=0.000\n",
      "cities      -danger       Pred r=0.715 p=0.000 IPred =0.992 p=0.000\n",
      "animals     -weight       Pred r=0.065 p=0.714 IPred =0.992 p=0.000\n",
      "sports      -gender       Pred r=0.854 p=0.000 IPred =0.991 p=0.000\n",
      "professions -location     Pred r=-0.127 p=0.386 IPred =0.995 p=0.000\n",
      "sports      -speed        Pred r=0.029 p=0.843 IPred =0.995 p=0.000\n",
      "states      -temperature  Pred r=0.611 p=0.000 IPred =0.997 p=0.000\n",
      "professions -arousal      Pred r=0.523 p=0.000 IPred =0.992 p=0.000\n",
      "cities      -size         Pred r=0.162 p=0.260 IPred =0.997 p=0.000\n",
      "states      -wealth       Pred r=0.470 p=0.001 IPred =0.998 p=0.000\n",
      "sports      -arousal      Pred r=0.279 p=0.050 IPred =0.997 p=0.000\n",
      "animals     -wetness      Pred r=0.794 p=0.000 IPred =0.998 p=0.000\n",
      "clothing    -gender       Pred r=0.818 p=0.000 IPred =0.996 p=0.000\n",
      "weather     -temperature  Pred r=0.470 p=0.003 IPred =0.992 p=0.000\n",
      "cities      -religiosity  Pred r=0.459 p=0.001 IPred =0.996 p=0.000\n",
      "animals     -intelligence Pred r=0.080 p=0.652 IPred =0.998 p=0.000\n",
      "states      -political    Pred r=0.399 p=0.004 IPred =0.997 p=0.000\n",
      "names       -intelligence Pred r=0.651 p=0.000 IPred =0.998 p=0.000\n",
      "myth        -gender       Pred r=0.817 p=0.000 IPred =0.988 p=0.000\n",
      "animals     -speed        Pred r=0.358 p=0.037 IPred =0.990 p=0.000\n",
      "animals     -gender       Pred r=0.700 p=0.000 IPred =0.995 p=0.000\n",
      "states      -cost         Pred r=-0.006 p=0.968 IPred =0.997 p=0.000\n",
      "myth        -danger       Pred r=0.723 p=0.000 IPred =0.993 p=0.000\n",
      "animals     -danger       Pred r=0.599 p=0.000 IPred =0.998 p=0.000\n",
      "animals     -loudness     Pred r=-0.081 p=0.647 IPred =0.994 p=0.000\n",
      "states      -intelligence Pred r=0.107 p=0.460 IPred =0.988 p=0.000\n",
      "sports      -location     Pred r=0.649 p=0.000 IPred =0.995 p=0.000\n"
     ]
    }
   ],
   "source": [
    "results_fitted = { }\n",
    "\n",
    "print(\"Seed-based versus fitted dimensions, correlation with human ratings\")\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "        \n",
    "        # make average seed-based dimension, use for predictions\n",
    "        dimension_vec = average_dim_vector(pos_seedwords, neg_seedwords, word_vectors)\n",
    "        df[\"Pred\"] = [vector_scalar_projection( word_vectors[w], dimension_vec) for w in df[\"Row\"]]\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        thisdata_vectors = []\n",
    "        thisdata_gold = []\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            thisdata_gold.append( row.Gold)\n",
    "        \n",
    "        ideal_dim, ideal_wt, ideal_bias = ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n",
    "        \n",
    "        df[\"IPred\"] = [iprediction( word_vectors[w], ideal_dim, ideal_wt, ideal_bias) for w in df[\"Row\"]]\n",
    "        \n",
    "        # evaluate\n",
    "        res_s = stats.pearsonr(df[\"Gold\"], df[\"Pred\"])\n",
    "        res_i = stats.pearsonr(df[\"Gold\"], df[\"IPred\"])\n",
    "        \n",
    "        print(f\"{grandcategory:12s}-{grandfeature:12s} Pred r={res_s.statistic:.3f} p={res_s.pvalue:.3f} IPred ={res_i.statistic:.3f} p={res_i.pvalue:.3f}\")\n",
    "        \n",
    "        results_fitted[ ( grandcategory, grandfeature) ] = {\n",
    "            \"grandcategory\" : grandcategory,\n",
    "            \"grandfeature\" : grandfeature,\n",
    "            \"seed_r\" : res_s.statistic,\n",
    "            \"seed_p\" : res_s.pvalue,\n",
    "            \"fitted_r\" : res_i.statistic,\n",
    "            \"fitted_p\" : res_i.pvalue } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfcd9b73-928a-4a2c-a1bd-cc7dfd3c47f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with significant correlations:\n",
      "Seed-based: 0.679\n",
      "Fitted: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage with significant correlations:\")\n",
    "seed_sig = sum([r[\"seed_p\"] <= 0.05 for r in results_fitted.values() if r[\"seed_r\"] > 0])\n",
    "print(\"Seed-based:\", round(seed_sig / len(results_fitted), 3))\n",
    "fitted_sig = sum([r[\"fitted_p\"] <= 0.05 for r in results_fitted.values() if r[\"fitted_r\"] > 0])\n",
    "print(\"Fitted:\", round(fitted_sig / len(results_fitted), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7ebe4-22b7-4eff-b444-8caafb8788c1",
   "metadata": {},
   "source": [
    "# Scrambled ratings\n",
    "\n",
    "The fitted dimensions above work very well, maybe too well. Is it maybe possible to compute a fitted dimension from any arbitrary ratings collection? We test this by scrambling ratings, so that they are arbitrary. Do we still manage to compute meaningful fitted dimensions? We again test using Pearson's r for correlation.\n",
    "\n",
    "The result is that yes, we actually do manage to compute axes on which the words are put in arbitrary bizarre orders, showing that the fitted dimensions have too many degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0be0d23-cc12-45e5-9a14-ee9a9284fc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrambled ratings\n",
      "cities      -temperature  Pred r=-0.030 p=0.835 IPred =0.997 p=0.000\n",
      "professions -intelligence Pred r=-0.275 p=0.056 IPred =0.981 p=0.000\n",
      "cities      -intelligence Pred r=-0.010 p=0.946 IPred =0.997 p=0.000\n",
      "clothing    -location     Pred r=-0.098 p=0.497 IPred =0.993 p=0.000\n",
      "cities      -arousal      Pred r=-0.015 p=0.919 IPred =0.991 p=0.000\n",
      "clothing    -arousal      Pred r=-0.090 p=0.532 IPred =0.992 p=0.000\n",
      "states      -size         Pred r=0.017 p=0.904 IPred =0.996 p=0.000\n",
      "sports      -intelligence Pred r=0.054 p=0.710 IPred =0.995 p=0.000\n",
      "names       -age          Pred r=0.046 p=0.751 IPred =0.994 p=0.000\n",
      "clothing    -wealth       Pred r=-0.323 p=0.022 IPred =0.996 p=0.000\n",
      "weather     -danger       Pred r=-0.097 p=0.567 IPred =0.988 p=0.000\n",
      "professions -danger       Pred r=0.014 p=0.926 IPred =0.998 p=0.000\n",
      "clothing    -size         Pred r=0.110 p=0.448 IPred =0.990 p=0.000\n",
      "animals     -size         Pred r=-0.242 p=0.167 IPred =0.993 p=0.000\n",
      "sports      -wealth       Pred r=-0.047 p=0.746 IPred =0.990 p=0.000\n",
      "professions -valence      Pred r=-0.160 p=0.271 IPred =0.995 p=0.000\n",
      "names       -wealth       Pred r=-0.077 p=0.593 IPred =0.994 p=0.000\n",
      "cities      -cost         Pred r=-0.019 p=0.896 IPred =0.994 p=0.000\n",
      "cities      -wealth       Pred r=-0.019 p=0.894 IPred =0.987 p=0.000\n",
      "professions -gender       Pred r=0.041 p=0.782 IPred =0.990 p=0.000\n",
      "states      -religiosity  Pred r=-0.145 p=0.316 IPred =0.998 p=0.000\n",
      "clothing    -age          Pred r=-0.264 p=0.064 IPred =0.995 p=0.000\n",
      "weather     -wetness      Pred r=-0.136 p=0.421 IPred =0.996 p=0.000\n",
      "professions -wealth       Pred r=0.222 p=0.125 IPred =0.995 p=0.000\n",
      "myth        -valence      Pred r=-0.012 p=0.932 IPred =0.991 p=0.000\n",
      "clothing    -cost         Pred r=-0.018 p=0.900 IPred =0.997 p=0.000\n",
      "professions -age          Pred r=0.246 p=0.089 IPred =0.989 p=0.000\n",
      "myth        -size         Pred r=-0.215 p=0.133 IPred =0.995 p=0.000\n",
      "sports      -danger       Pred r=0.045 p=0.758 IPred =0.992 p=0.000\n",
      "names       -gender       Pred r=-0.119 p=0.411 IPred =0.996 p=0.000\n",
      "cities      -danger       Pred r=-0.036 p=0.806 IPred =0.997 p=0.000\n",
      "animals     -weight       Pred r=0.267 p=0.127 IPred =0.997 p=0.000\n",
      "sports      -gender       Pred r=-0.312 p=0.027 IPred =0.992 p=0.000\n",
      "professions -location     Pred r=0.287 p=0.046 IPred =0.998 p=0.000\n",
      "sports      -speed        Pred r=0.305 p=0.031 IPred =0.981 p=0.000\n",
      "states      -temperature  Pred r=-0.075 p=0.604 IPred =0.990 p=0.000\n",
      "professions -arousal      Pred r=-0.129 p=0.378 IPred =0.988 p=0.000\n",
      "cities      -size         Pred r=-0.039 p=0.789 IPred =0.983 p=0.000\n",
      "states      -wealth       Pred r=0.323 p=0.022 IPred =0.980 p=0.000\n",
      "sports      -arousal      Pred r=0.042 p=0.770 IPred =0.989 p=0.000\n",
      "animals     -wetness      Pred r=0.125 p=0.481 IPred =0.989 p=0.000\n",
      "clothing    -gender       Pred r=-0.096 p=0.506 IPred =0.994 p=0.000\n",
      "weather     -temperature  Pred r=-0.056 p=0.744 IPred =0.997 p=0.000\n",
      "cities      -religiosity  Pred r=-0.137 p=0.344 IPred =0.990 p=0.000\n",
      "animals     -intelligence Pred r=0.151 p=0.393 IPred =0.993 p=0.000\n",
      "states      -political    Pred r=0.003 p=0.983 IPred =0.989 p=0.000\n",
      "names       -intelligence Pred r=0.015 p=0.920 IPred =0.995 p=0.000\n",
      "myth        -gender       Pred r=-0.077 p=0.595 IPred =0.991 p=0.000\n",
      "animals     -speed        Pred r=0.089 p=0.616 IPred =0.997 p=0.000\n",
      "animals     -gender       Pred r=0.130 p=0.464 IPred =0.990 p=0.000\n",
      "states      -cost         Pred r=-0.237 p=0.098 IPred =0.980 p=0.000\n",
      "myth        -danger       Pred r=0.004 p=0.979 IPred =0.994 p=0.000\n",
      "animals     -danger       Pred r=0.184 p=0.296 IPred =0.990 p=0.000\n",
      "animals     -loudness     Pred r=0.331 p=0.056 IPred =0.998 p=0.000\n",
      "states      -intelligence Pred r=0.164 p=0.254 IPred =0.981 p=0.000\n",
      "sports      -location     Pred r=0.060 p=0.681 IPred =0.997 p=0.000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "print(\"Scrambled ratings\")\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "        \n",
    "        # make average seed-based dimension, use for predictions\n",
    "        dimension_vec = average_dim_vector(pos_seedwords, neg_seedwords, word_vectors)\n",
    "        df[\"Pred\"] = [vector_scalar_projection( word_vectors[w], dimension_vec) for w in df[\"Row\"]]\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        thisdata_vectors = []\n",
    "        thisdata_gold = []\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            thisdata_gold.append( row.Gold)\n",
    "      \n",
    "        #SCRAMBLING\n",
    "        random.shuffle(thisdata_gold)\n",
    "        \n",
    "        ideal_dim, ideal_wt, ideal_bias = ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n",
    "        \n",
    "        df[\"IPred\"] = [iprediction( word_vectors[w], ideal_dim, ideal_wt, ideal_bias) for w in df[\"Row\"]]\n",
    "        \n",
    "        # evaluate, again against the scrambled ratings\n",
    "        res_s = stats.pearsonr(thisdata_gold, df[\"Pred\"])\n",
    "        res_i = stats.pearsonr(thisdata_gold, df[\"IPred\"])\n",
    "        \n",
    "        print(f\"{grandcategory:12s}-{grandfeature:12s} Pred r={res_s.statistic:.3f} p={res_s.pvalue:.3f} IPred ={res_i.statistic:.3f} p={res_i.pvalue:.3f}\")\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_scrambled_r\"] = res_i.statistic\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_scrambled_p\"] = res_i.pvalue\n",
    "        results_fitted[(grandcategory, grandfeature)][\"seed_scrambled_r\"] = res_s.statistic\n",
    "        results_fitted[(grandcategory, grandfeature)][\"seed_scrambled_p\"] = res_s.pvalue             \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82a5edb3-d58d-49a3-ba18-f9303600053c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with significant correlations:\n",
      "Fitted dimensions w scrambled ratings: 1.0\n",
      "Seed dimensions w scrambled ratings: 0.054\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage with significant correlations:\")\n",
    "sig = sum([r[\"fitted_scrambled_p\"] <= 0.05 for r in results_fitted.values() if r[\"fitted_scrambled_r\"] > 0])\n",
    "print(\"Fitted dimensions w scrambled ratings:\", round(sig / len(results_fitted), 3))\n",
    "sig = sum([r[\"seed_scrambled_p\"] <= 0.05 for r in results_fitted.values() if r[\"seed_scrambled_r\"] > 0])\n",
    "print(\"Seed dimensions w scrambled ratings:\", round(sig / len(results_fitted), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3119e-3ef6-4afc-806b-4637109f9728",
   "metadata": {},
   "source": [
    "In the above test, the ratings are scrambled, but the words all come from a common category, like \"animals\". What if the words are random too? We run an exacerbated version of this test where we don't just scramble the ratings, we exchange the words by random ones.\n",
    "\n",
    "This time, we mostly do not find any correlation between gold and predicted values. This means that we cannot fit a dimension through arbitrary words, but for words that do belong to the same category, there are too many ways of fitting a dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1288e6bd-4710-4755-a7d5-6144d149170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrambled ratings, arbitrary words\n",
      "cities      -temperature  Pred r=0.150 p=0.298 IPred =-0.033 p=0.821\n",
      "professions -intelligence Pred r=0.095 p=0.514 IPred =0.036 p=0.806\n",
      "cities      -intelligence Pred r=-0.099 p=0.496 IPred =0.074 p=0.612\n",
      "clothing    -location     Pred r=0.025 p=0.864 IPred =0.182 p=0.206\n",
      "cities      -arousal      Pred r=0.065 p=0.652 IPred =-0.098 p=0.500\n",
      "clothing    -arousal      Pred r=0.095 p=0.512 IPred =0.127 p=0.380\n",
      "states      -size         Pred r=-0.081 p=0.576 IPred =-0.162 p=0.261\n",
      "sports      -intelligence Pred r=-0.068 p=0.640 IPred =-0.197 p=0.171\n",
      "names       -age          Pred r=0.148 p=0.305 IPred =-0.059 p=0.683\n",
      "clothing    -wealth       Pred r=0.076 p=0.601 IPred =0.202 p=0.159\n",
      "weather     -danger       Pred r=0.113 p=0.507 IPred =0.088 p=0.604\n",
      "professions -danger       Pred r=0.273 p=0.057 IPred =-0.155 p=0.286\n",
      "clothing    -size         Pred r=-0.259 p=0.070 IPred =-0.358 p=0.011\n",
      "animals     -size         Pred r=0.277 p=0.113 IPred =0.064 p=0.721\n",
      "sports      -wealth       Pred r=-0.127 p=0.380 IPred =-0.107 p=0.460\n",
      "professions -valence      Pred r=0.060 p=0.682 IPred =-0.187 p=0.198\n",
      "names       -wealth       Pred r=-0.070 p=0.630 IPred =-0.064 p=0.658\n",
      "cities      -cost         Pred r=0.035 p=0.809 IPred =-0.011 p=0.940\n",
      "cities      -wealth       Pred r=0.201 p=0.162 IPred =-0.352 p=0.012\n",
      "professions -gender       Pred r=0.191 p=0.190 IPred =0.212 p=0.144\n",
      "states      -religiosity  Pred r=0.087 p=0.549 IPred =-0.100 p=0.492\n",
      "clothing    -age          Pred r=0.017 p=0.906 IPred =-0.221 p=0.123\n",
      "weather     -wetness      Pred r=-0.087 p=0.608 IPred =0.085 p=0.615\n",
      "professions -wealth       Pred r=-0.094 p=0.520 IPred =0.233 p=0.107\n",
      "myth        -valence      Pred r=0.001 p=0.993 IPred =-0.053 p=0.716\n",
      "clothing    -cost         Pred r=-0.136 p=0.347 IPred =-0.052 p=0.717\n",
      "professions -age          Pred r=-0.055 p=0.708 IPred =0.102 p=0.486\n",
      "myth        -size         Pred r=0.328 p=0.020 IPred =0.065 p=0.652\n",
      "sports      -danger       Pred r=-0.085 p=0.559 IPred =0.054 p=0.707\n",
      "names       -gender       Pred r=0.034 p=0.817 IPred =0.177 p=0.218\n",
      "cities      -danger       Pred r=-0.146 p=0.311 IPred =0.132 p=0.360\n",
      "animals     -weight       Pred r=-0.254 p=0.146 IPred =-0.065 p=0.714\n",
      "sports      -gender       Pred r=0.034 p=0.813 IPred =-0.137 p=0.343\n",
      "professions -location     Pred r=0.004 p=0.978 IPred =0.007 p=0.963\n",
      "sports      -speed        Pred r=-0.035 p=0.809 IPred =0.091 p=0.528\n",
      "states      -temperature  Pred r=-0.021 p=0.884 IPred =-0.130 p=0.367\n",
      "professions -arousal      Pred r=0.199 p=0.170 IPred =-0.059 p=0.686\n",
      "cities      -size         Pred r=-0.180 p=0.211 IPred =-0.105 p=0.468\n",
      "states      -wealth       Pred r=0.064 p=0.659 IPred =0.005 p=0.971\n",
      "sports      -arousal      Pred r=-0.174 p=0.228 IPred =0.105 p=0.470\n",
      "animals     -wetness      Pred r=0.204 p=0.246 IPred =0.102 p=0.566\n",
      "clothing    -gender       Pred r=-0.199 p=0.165 IPred =-0.171 p=0.236\n",
      "weather     -temperature  Pred r=-0.352 p=0.032 IPred =-0.041 p=0.811\n",
      "cities      -religiosity  Pred r=0.089 p=0.539 IPred =-0.062 p=0.669\n",
      "animals     -intelligence Pred r=-0.014 p=0.935 IPred =0.297 p=0.088\n",
      "states      -political    Pred r=0.054 p=0.710 IPred =-0.010 p=0.945\n",
      "names       -intelligence Pred r=-0.045 p=0.759 IPred =0.190 p=0.187\n",
      "myth        -gender       Pred r=-0.075 p=0.605 IPred =0.047 p=0.746\n",
      "animals     -speed        Pred r=-0.157 p=0.376 IPred =-0.059 p=0.739\n",
      "animals     -gender       Pred r=0.342 p=0.048 IPred =0.185 p=0.294\n",
      "states      -cost         Pred r=-0.031 p=0.830 IPred =-0.141 p=0.328\n",
      "myth        -danger       Pred r=-0.056 p=0.698 IPred =-0.173 p=0.229\n",
      "animals     -danger       Pred r=0.181 p=0.306 IPred =-0.037 p=0.835\n",
      "animals     -loudness     Pred r=-0.098 p=0.582 IPred =-0.061 p=0.733\n",
      "states      -intelligence Pred r=-0.179 p=0.214 IPred =-0.224 p=0.117\n",
      "sports      -location     Pred r=0.112 p=0.438 IPred =-0.144 p=0.317\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Scrambled ratings, arbitrary words\")\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "        \n",
    "        # make average seed-based dimension, use for predictions\n",
    "        dimension_vec = average_dim_vector(pos_seedwords, neg_seedwords, word_vectors)\n",
    "        df[\"Pred\"] = [vector_scalar_projection( word_vectors[w], dimension_vec) for w in df[\"Row\"]]\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        thisdata_vectors = []\n",
    "        thisdata_gold = []\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            thisdata_gold.append( row.Gold)\n",
    "      \n",
    "        # Scrambling the ratings\n",
    "        random.shuffle(thisdata_gold)\n",
    "        # exchanging the vectors for those of arbitrary words\n",
    "        thisdata_vectors = [word_vectors[random.choice(list(word_vectors.keys()))] for w in thisdata_vectors]\n",
    "        \n",
    "        ideal_dim, ideal_wt, ideal_bias = ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n",
    "        \n",
    "        df[\"IPred\"] = [iprediction( word_vectors[w], ideal_dim, ideal_wt, ideal_bias) for w in df[\"Row\"]]\n",
    "        \n",
    "        # evaluate, again against the scrambled ratings\n",
    "        res_s = stats.pearsonr(thisdata_gold, df[\"Pred\"])\n",
    "        res_i = stats.pearsonr(thisdata_gold, df[\"IPred\"])\n",
    "        \n",
    "        print(f\"{grandcategory:12s}-{grandfeature:12s} Pred r={res_s.statistic:.3f} p={res_s.pvalue:.3f} IPred ={res_i.statistic:.3f} p={res_i.pvalue:.3f}\")\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_rand_scrambled_r\"] = res_i.statistic\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_rand_scrambled_p\"] = res_i.pvalue               \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "898acfec-2af3-4266-839d-504136a38dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with significant correlations:\n",
      "Fitted dimensions, random words, scrambled ratings: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage with significant correlations:\")\n",
    "sig = sum([r[\"fitted_rand_scrambled_p\"] <= 0.05 for r in results_fitted.values() if r[\"fitted_rand_scrambled_r\"] > 0])\n",
    "print(\"Fitted dimensions, random words, scrambled ratings:\", round(sig / len(results_fitted), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d21747-8e77-4d95-959b-10d6ce39218e",
   "metadata": {},
   "source": [
    "# Seed words as additional input to fitted dimensions\n",
    "\n",
    "What if we give the fitted dimension model the seed words along with the word/ratings pairs? Will that \"disambiguate\" the dimension through the words of a category, so that we cannot fit arbitrary scrambled ratings?\n",
    "\n",
    "While we are at it, what happens if we fit a dimension only with the seed words?\n",
    "\n",
    "To do this, we have to give the seed words made-up ratings. Ratings are z-scores, so the seed words should get ratings either at around -2 or +2, far out on the scale. \n",
    "\n",
    "But does the Grand et al data give us hints which seed words should be at +2 and which at -2? Are the positive seed words always the ones that should have high values on the scale? Let's check first. We see that indeed the positive seeds are always the ones that should have a high value on the scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4658fded-7b6c-41ce-8691-bbce2349a823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cities temperature pseed: hot nseed: cold lowrating: amsterdam (-1.01) highrating: dallas (2.19)\n",
      "professions intelligence pseed: intelligent nseed: stupid lowrating: actor (-0.38) highrating: doctor (1.68)\n",
      "cities intelligence pseed: intelligent nseed: stupid lowrating: amsterdam (0.75) highrating: tokyo (2.26)\n",
      "clothing location pseed: indoor nseed: outdoor lowrating: bathrobe (2.07) highrating: pajamas (2.18)\n",
      "cities arousal pseed: interesting nseed: boring lowrating: amsterdam (1.18) highrating: new-york (1.90)\n",
      "clothing arousal pseed: interesting nseed: boring lowrating: bathrobe (-0.62) highrating: watch (2.47)\n",
      "states size pseed: large nseed: small lowrating: alabama (-0.26) highrating: texas (2.72)\n",
      "sports intelligence pseed: intelligent nseed: stupid lowrating: aerobics (-0.56) highrating: golf (2.03)\n",
      "names age pseed: old nseed: young lowrating: anthony (-0.84) highrating: donald (1.97)\n",
      "clothing wealth pseed: rich nseed: poor lowrating: bathrobe (-0.27) highrating: tuxedo (2.80)\n",
      "weather danger pseed: dangerous nseed: safe lowrating: blizzard (0.91) highrating: tsunami (1.52)\n",
      "professions danger pseed: dangerous nseed: safe lowrating: actor (-0.66) highrating: soldier (2.31)\n",
      "clothing size pseed: large nseed: small lowrating: bathrobe (-0.97) highrating: boots (2.58)\n",
      "animals size pseed: large nseed: small lowrating: alligator (0.59) highrating: whale (2.09)\n",
      "sports wealth pseed: rich nseed: poor lowrating: aerobics (-0.40) highrating: golf (2.81)\n",
      "professions valence pseed: good nseed: bad lowrating: actor (0.04) highrating: doctor (1.31)\n",
      "names wealth pseed: rich nseed: poor lowrating: anthony (-0.41) highrating: donald (2.48)\n",
      "cities cost pseed: expensive nseed: inexpensive lowrating: amsterdam (0.41) highrating: san-francisco (1.87)\n",
      "cities wealth pseed: rich nseed: poor lowrating: amsterdam (-1.01) highrating: dallas (2.19)\n",
      "professions gender pseed: male nseed: female lowrating: actor (0.88) highrating: king (1.44)\n",
      "states religiosity pseed: religious nseed: atheist lowrating: alabama (1.62) highrating: texas (1.72)\n",
      "clothing age pseed: old nseed: young lowrating: bathrobe (0.69) highrating: shawl (1.81)\n",
      "weather wetness pseed: wet nseed: dry lowrating: blizzard (0.62) highrating: tsunami (1.22)\n",
      "professions wealth pseed: rich nseed: poor lowrating: actor (1.16) highrating: king (1.83)\n",
      "myth valence pseed: good nseed: bad lowrating: alien (0.20) highrating: angel (2.12)\n",
      "clothing cost pseed: expensive nseed: inexpensive lowrating: bathrobe (-0.57) highrating: tuxedo (2.57)\n",
      "professions age pseed: old nseed: young lowrating: actor (-0.61) highrating: king (2.05)\n",
      "myth size pseed: large nseed: small lowrating: alien (-0.16) highrating: dragon (1.86)\n",
      "sports danger pseed: dangerous nseed: safe lowrating: aerobics (-1.04) highrating: boxing (2.12)\n",
      "names gender pseed: male nseed: female lowrating: anthony (1.15) highrating: joseph (1.19)\n",
      "cities danger pseed: dangerous nseed: safe lowrating: amsterdam (-0.90) highrating: baghdad (2.41)\n",
      "animals weight pseed: heavy nseed: light lowrating: alligator (0.68) highrating: mammoth (1.82)\n",
      "sports gender pseed: male nseed: female lowrating: aerobics (-1.94) highrating: sumo (1.93)\n",
      "professions location pseed: indoor nseed: outdoor lowrating: actor (-0.32) highrating: librarian (1.08)\n",
      "sports speed pseed: fast nseed: slow lowrating: aerobics (0.09) highrating: racing (2.18)\n",
      "states temperature pseed: hot nseed: cold lowrating: alabama (1.00) highrating: florida (2.06)\n",
      "professions arousal pseed: interesting nseed: boring lowrating: actor (1.17) highrating: president (1.61)\n",
      "cities size pseed: large nseed: small lowrating: amsterdam (-0.59) highrating: beijing (2.23)\n",
      "states wealth pseed: rich nseed: poor lowrating: alabama (-1.75) highrating: new-york (2.56)\n",
      "sports arousal pseed: interesting nseed: boring lowrating: aerobics (-1.08) highrating: football (2.74)\n",
      "animals wetness pseed: wet nseed: dry lowrating: alligator (1.16) highrating: goldfish (1.69)\n",
      "clothing gender pseed: male nseed: female lowrating: bathrobe (0.49) highrating: tuxedo (2.37)\n",
      "weather temperature pseed: hot nseed: cold lowrating: blizzard (-2.20) highrating: heatwave (2.20)\n",
      "cities religiosity pseed: religious nseed: atheist lowrating: amsterdam (-1.68) highrating: jerusalem (3.01)\n",
      "animals intelligence pseed: intelligent nseed: stupid lowrating: alligator (0.11) highrating: dolphin (2.25)\n",
      "states political pseed: democrat nseed: republican lowrating: alabama (-1.32) highrating: california (1.95)\n",
      "names intelligence pseed: intelligent nseed: stupid lowrating: anthony (-0.29) highrating: charles (1.99)\n",
      "myth gender pseed: male nseed: female lowrating: alien (0.05) highrating: minotaur (1.34)\n",
      "animals speed pseed: fast nseed: slow lowrating: alligator (-0.13) highrating: cheetah (2.38)\n",
      "animals gender pseed: male nseed: female lowrating: alligator (1.67) highrating: alligator (1.67)\n",
      "states cost pseed: expensive nseed: inexpensive lowrating: alabama (-1.36) highrating: california (2.51)\n",
      "myth danger pseed: dangerous nseed: safe lowrating: alien (0.13) highrating: devil (1.69)\n",
      "animals danger pseed: dangerous nseed: safe lowrating: alligator (1.87) highrating: tiger (1.93)\n",
      "animals loudness pseed: loud nseed: soft lowrating: alligator (-0.44) highrating: elephant (1.48)\n",
      "states intelligence pseed: intelligent nseed: stupid lowrating: alabama (-1.58) highrating: massachusetts (2.00)\n",
      "sports location pseed: indoor nseed: outdoor lowrating: aerobics (0.97) highrating: boxing (1.66)\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "\n",
    "        df0 = df.sort_values(by = \"Gold\")\n",
    "        lowest = df0.Row[0]\n",
    "        lowestval = df0.Gold[0]\n",
    "        highest = df0.Row.iat[-1]\n",
    "        highestval = df0.Gold.iat[-1]\n",
    "        print(grandcategory, grandfeature, \n",
    "              \"pseed:\", pos_seedwords[0], \"nseed:\", neg_seedwords[0],\n",
    "              f\"lowrating: {lowest} ({lowestval:.2f})\", \n",
    "              f\"highrating: {highest} ({highestval:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aa3555-70cd-4d9a-9fec-d3e3c3e4a20e",
   "metadata": {},
   "source": [
    "We first train fitted dimensions on seeds only. We set the ratings for the seed words to be 0.5 beyond the highest/lowest rating in the dataset, with a bit of jitter added. \n",
    "\n",
    "We use only the dimension and re-scale, as we cannot expect the weight and bias to be useful in this case. \n",
    "\n",
    "We see that these dimensions don't work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff57a3fa-b430-4d0e-8671-837eed6860cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-based versus fitted *seed-based* dimensions\n",
      "cities      -temperature  Pred r=-0.086 p=0.553 IPred =-0.095 p=0.511\n",
      "professions -intelligence Pred r=0.468 p=0.001 IPred =0.564 p=0.000\n",
      "cities      -intelligence Pred r=0.161 p=0.265 IPred =-0.212 p=0.139\n",
      "clothing    -location     Pred r=0.323 p=0.022 IPred =-0.178 p=0.217\n",
      "cities      -arousal      Pred r=0.001 p=0.996 IPred =-0.270 p=0.058\n",
      "clothing    -arousal      Pred r=0.185 p=0.199 IPred =0.169 p=0.241\n",
      "states      -size         Pred r=0.331 p=0.019 IPred =0.102 p=0.480\n",
      "sports      -intelligence Pred r=0.613 p=0.000 IPred =0.384 p=0.006\n",
      "names       -age          Pred r=0.616 p=0.000 IPred =-0.012 p=0.932\n",
      "clothing    -wealth       Pred r=0.369 p=0.008 IPred =0.307 p=0.030\n",
      "weather     -danger       Pred r=0.790 p=0.000 IPred =0.259 p=0.121\n",
      "professions -danger       Pred r=0.446 p=0.001 IPred =-0.143 p=0.327\n",
      "clothing    -size         Pred r=0.097 p=0.503 IPred =0.132 p=0.362\n",
      "animals     -size         Pred r=0.668 p=0.000 IPred =0.041 p=0.820\n",
      "sports      -wealth       Pred r=0.435 p=0.002 IPred =0.300 p=0.034\n",
      "professions -valence      Pred r=0.381 p=0.007 IPred =0.461 p=0.001\n",
      "names       -wealth       Pred r=0.533 p=0.000 IPred =-0.000 p=0.999\n",
      "cities      -cost         Pred r=-0.136 p=0.346 IPred =-0.045 p=0.759\n",
      "cities      -wealth       Pred r=0.128 p=0.377 IPred =-0.144 p=0.317\n",
      "professions -gender       Pred r=0.916 p=0.000 IPred =0.399 p=0.005\n",
      "states      -religiosity  Pred r=-0.063 p=0.666 IPred =-0.266 p=0.062\n",
      "clothing    -age          Pred r=0.561 p=0.000 IPred =-0.122 p=0.398\n",
      "weather     -wetness      Pred r=0.508 p=0.001 IPred =0.156 p=0.355\n",
      "professions -wealth       Pred r=0.533 p=0.000 IPred =0.269 p=0.061\n",
      "myth        -valence      Pred r=0.643 p=0.000 IPred =-0.008 p=0.957\n",
      "clothing    -cost         Pred r=-0.087 p=0.549 IPred =0.322 p=0.023\n",
      "professions -age          Pred r=0.238 p=0.100 IPred =0.292 p=0.041\n",
      "myth        -size         Pred r=0.704 p=0.000 IPred =-0.086 p=0.553\n",
      "sports      -danger       Pred r=0.379 p=0.007 IPred =0.061 p=0.675\n",
      "names       -gender       Pred r=0.940 p=0.000 IPred =0.268 p=0.060\n",
      "cities      -danger       Pred r=0.715 p=0.000 IPred =0.410 p=0.003\n",
      "animals     -weight       Pred r=0.065 p=0.714 IPred =0.078 p=0.661\n",
      "sports      -gender       Pred r=0.854 p=0.000 IPred =0.168 p=0.244\n",
      "professions -location     Pred r=-0.127 p=0.386 IPred =0.161 p=0.269\n",
      "sports      -speed        Pred r=0.029 p=0.843 IPred =-0.041 p=0.779\n",
      "states      -temperature  Pred r=0.611 p=0.000 IPred =0.148 p=0.307\n",
      "professions -arousal      Pred r=0.523 p=0.000 IPred =0.220 p=0.128\n",
      "cities      -size         Pred r=0.162 p=0.260 IPred =0.215 p=0.134\n",
      "states      -wealth       Pred r=0.470 p=0.001 IPred =0.358 p=0.011\n",
      "sports      -arousal      Pred r=0.279 p=0.050 IPred =0.205 p=0.154\n",
      "animals     -wetness      Pred r=0.794 p=0.000 IPred =0.448 p=0.008\n",
      "clothing    -gender       Pred r=0.818 p=0.000 IPred =0.262 p=0.067\n",
      "weather     -temperature  Pred r=0.470 p=0.003 IPred =0.163 p=0.335\n",
      "cities      -religiosity  Pred r=0.459 p=0.001 IPred =-0.365 p=0.009\n",
      "animals     -intelligence Pred r=0.080 p=0.652 IPred =-0.311 p=0.073\n",
      "states      -political    Pred r=0.399 p=0.004 IPred =0.211 p=0.140\n",
      "names       -intelligence Pred r=0.651 p=0.000 IPred =-0.213 p=0.137\n",
      "myth        -gender       Pred r=0.817 p=0.000 IPred =0.003 p=0.981\n",
      "animals     -speed        Pred r=0.358 p=0.037 IPred =-0.090 p=0.612\n",
      "animals     -gender       Pred r=0.700 p=0.000 IPred =0.243 p=0.165\n",
      "states      -cost         Pred r=-0.006 p=0.968 IPred =0.399 p=0.004\n",
      "myth        -danger       Pred r=0.723 p=0.000 IPred =0.058 p=0.687\n",
      "animals     -danger       Pred r=0.599 p=0.000 IPred =0.149 p=0.399\n",
      "animals     -loudness     Pred r=-0.081 p=0.647 IPred =-0.232 p=0.187\n",
      "states      -intelligence Pred r=0.107 p=0.460 IPred =0.102 p=0.482\n",
      "sports      -location     Pred r=0.649 p=0.000 IPred =-0.179 p=0.215\n"
     ]
    }
   ],
   "source": [
    "print(\"Seed-based versus fitted *seed-based* dimensions\")\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "        \n",
    "        # make average seed-based dimension, use for predictions\n",
    "        dimension_vec = average_dim_vector(pos_seedwords, neg_seedwords, word_vectors)\n",
    "        df[\"Pred\"] = [vector_scalar_projection( word_vectors[w], dimension_vec) for w in df[\"Row\"]]\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        lowvalue = df[\"Gold\"].min() - 0.5\n",
    "        highvalue = df[\"Gold\"].max() + 0.5\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        thisdata_vectors = []\n",
    "        thisdata_gold = []\n",
    "        \n",
    "        for seed in pos_seedwords:\n",
    "            thisdata_vectors.append( word_vectors [ seed ])\n",
    "            thisdata_gold.append( highvalue + random.uniform(0.001, 0.005))\n",
    "\n",
    "        for seed in neg_seedwords:\n",
    "            thisdata_vectors.append( word_vectors [ seed ])\n",
    "            thisdata_gold.append( lowvalue - random.uniform(0.001, 0.005))\n",
    "\n",
    "        \n",
    "        ideal_dim, _, _= ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n",
    "        \n",
    "        df[\"IPred\"] = [vector_scalar_projection( word_vectors[w], ideal_dim) for w in df[\"Row\"]]\n",
    "        \n",
    "        # evaluate\n",
    "        res_s = stats.pearsonr(df[\"Gold\"], df[\"Pred\"])\n",
    "        res_i = stats.pearsonr(df[\"Gold\"], df[\"IPred\"])\n",
    "        \n",
    "        print(f\"{grandcategory:12s}-{grandfeature:12s} Pred r={res_s.statistic:.3f} p={res_s.pvalue:.3f} IPred ={res_i.statistic:.3f} p={res_i.pvalue:.3f}\")\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_seed_r\"] = res_i.statistic\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_seed_p\"] = res_i.pvalue               \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2ef501e-5eca-4836-a1b7-17283bb7e6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with significant correlations:\n",
      "Fitted dimensions, seed-based: 0.214\n",
      "For comparison, seed-based: 0.679\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage with significant correlations:\")\n",
    "sig = sum([r[\"fitted_seed_p\"] <= 0.05 for r in results_fitted.values() if r[\"fitted_seed_r\"] > 0])\n",
    "print(\"Fitted dimensions, seed-based:\", round(sig / len(results_fitted), 3))\n",
    "seed_sig = sum([r[\"seed_p\"] <= 0.05 for r in results_fitted.values() if r[\"seed_r\"] > 0])\n",
    "print(\"For comparison, seed-based:\", round(seed_sig / len(results_fitted), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32008d5-ba68-4cd2-9f87-a267c6c827d8",
   "metadata": {},
   "source": [
    "Next we fit dimensions with both seed words and ratings. This works very well: we again get significant correlations in all cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dffa00c-0a84-4446-b85b-0660989124eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-based versus fitted *seed-based* dimensions with ratings\n",
      "cities      -temperature  Pred r=-0.086 p=0.553 IPred =0.985 p=0.000\n",
      "professions -intelligence Pred r=0.468 p=0.001 IPred =0.989 p=0.000\n",
      "cities      -intelligence Pred r=0.161 p=0.265 IPred =0.992 p=0.000\n",
      "clothing    -location     Pred r=0.323 p=0.022 IPred =0.989 p=0.000\n",
      "cities      -arousal      Pred r=0.001 p=0.996 IPred =0.997 p=0.000\n",
      "clothing    -arousal      Pred r=0.185 p=0.199 IPred =0.995 p=0.000\n",
      "states      -size         Pred r=0.331 p=0.019 IPred =0.983 p=0.000\n",
      "sports      -intelligence Pred r=0.613 p=0.000 IPred =0.990 p=0.000\n",
      "names       -age          Pred r=0.616 p=0.000 IPred =0.998 p=0.000\n",
      "clothing    -wealth       Pred r=0.369 p=0.008 IPred =0.993 p=0.000\n",
      "weather     -danger       Pred r=0.790 p=0.000 IPred =0.996 p=0.000\n",
      "professions -danger       Pred r=0.446 p=0.001 IPred =0.990 p=0.000\n",
      "clothing    -size         Pred r=0.097 p=0.503 IPred =0.994 p=0.000\n",
      "animals     -size         Pred r=0.668 p=0.000 IPred =0.994 p=0.000\n",
      "sports      -wealth       Pred r=0.435 p=0.002 IPred =0.992 p=0.000\n",
      "professions -valence      Pred r=0.381 p=0.007 IPred =0.993 p=0.000\n",
      "names       -wealth       Pred r=0.533 p=0.000 IPred =0.999 p=0.000\n",
      "cities      -cost         Pred r=-0.136 p=0.346 IPred =0.989 p=0.000\n",
      "cities      -wealth       Pred r=0.128 p=0.377 IPred =0.993 p=0.000\n",
      "professions -gender       Pred r=0.916 p=0.000 IPred =0.996 p=0.000\n",
      "states      -religiosity  Pred r=-0.063 p=0.666 IPred =0.994 p=0.000\n",
      "clothing    -age          Pred r=0.561 p=0.000 IPred =0.996 p=0.000\n",
      "weather     -wetness      Pred r=0.508 p=0.001 IPred =0.993 p=0.000\n",
      "professions -wealth       Pred r=0.533 p=0.000 IPred =0.992 p=0.000\n",
      "myth        -valence      Pred r=0.643 p=0.000 IPred =0.996 p=0.000\n",
      "clothing    -cost         Pred r=-0.087 p=0.549 IPred =0.995 p=0.000\n",
      "professions -age          Pred r=0.238 p=0.100 IPred =0.992 p=0.000\n",
      "myth        -size         Pred r=0.704 p=0.000 IPred =0.997 p=0.000\n",
      "sports      -danger       Pred r=0.379 p=0.007 IPred =0.990 p=0.000\n",
      "names       -gender       Pred r=0.940 p=0.000 IPred =0.999 p=0.000\n",
      "cities      -danger       Pred r=0.715 p=0.000 IPred =0.993 p=0.000\n",
      "animals     -weight       Pred r=0.065 p=0.714 IPred =0.999 p=0.000\n",
      "sports      -gender       Pred r=0.854 p=0.000 IPred =0.989 p=0.000\n",
      "professions -location     Pred r=-0.127 p=0.386 IPred =0.994 p=0.000\n",
      "sports      -speed        Pred r=0.029 p=0.843 IPred =0.994 p=0.000\n",
      "states      -temperature  Pred r=0.611 p=0.000 IPred =0.981 p=0.000\n",
      "professions -arousal      Pred r=0.523 p=0.000 IPred =0.996 p=0.000\n",
      "cities      -size         Pred r=0.162 p=0.260 IPred =0.993 p=0.000\n",
      "states      -wealth       Pred r=0.470 p=0.001 IPred =0.990 p=0.000\n",
      "sports      -arousal      Pred r=0.279 p=0.050 IPred =0.993 p=0.000\n",
      "animals     -wetness      Pred r=0.794 p=0.000 IPred =0.995 p=0.000\n",
      "clothing    -gender       Pred r=0.818 p=0.000 IPred =0.994 p=0.000\n",
      "weather     -temperature  Pred r=0.470 p=0.003 IPred =0.996 p=0.000\n",
      "cities      -religiosity  Pred r=0.459 p=0.001 IPred =0.987 p=0.000\n",
      "animals     -intelligence Pred r=0.080 p=0.652 IPred =0.995 p=0.000\n",
      "states      -political    Pred r=0.399 p=0.004 IPred =0.989 p=0.000\n",
      "names       -intelligence Pred r=0.651 p=0.000 IPred =0.999 p=0.000\n",
      "myth        -gender       Pred r=0.817 p=0.000 IPred =0.995 p=0.000\n",
      "animals     -speed        Pred r=0.358 p=0.037 IPred =0.993 p=0.000\n",
      "animals     -gender       Pred r=0.700 p=0.000 IPred =0.997 p=0.000\n",
      "states      -cost         Pred r=-0.006 p=0.968 IPred =0.990 p=0.000\n",
      "myth        -danger       Pred r=0.723 p=0.000 IPred =0.993 p=0.000\n",
      "animals     -danger       Pred r=0.599 p=0.000 IPred =0.995 p=0.000\n",
      "animals     -loudness     Pred r=-0.081 p=0.647 IPred =0.998 p=0.000\n",
      "states      -intelligence Pred r=0.107 p=0.460 IPred =0.990 p=0.000\n",
      "sports      -location     Pred r=0.649 p=0.000 IPred =0.996 p=0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Seed-based versus fitted *seed-based* dimensions with ratings\")\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "        \n",
    "        # make average seed-based dimension, use for predictions\n",
    "        dimension_vec = average_dim_vector(pos_seedwords, neg_seedwords, word_vectors)\n",
    "        df[\"Pred\"] = [vector_scalar_projection( word_vectors[w], dimension_vec) for w in df[\"Row\"]]\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        lowvalue = df[\"Gold\"].min() - 0.5\n",
    "        highvalue = df[\"Gold\"].max() + 0.5\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        thisdata_vectors = []\n",
    "        thisdata_gold = []\n",
    "        \n",
    "        for seed in pos_seedwords:\n",
    "            thisdata_vectors.append( word_vectors [ seed ])\n",
    "            thisdata_gold.append( highvalue + random.uniform(0.001, 0.005))\n",
    "\n",
    "        for seed in neg_seedwords:\n",
    "            thisdata_vectors.append( word_vectors [ seed ])\n",
    "            thisdata_gold.append( lowvalue - random.uniform(0.001, 0.005))\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            thisdata_gold.append( row.Gold)\n",
    "        \n",
    "        ideal_dim, ideal_wt, ideal_bias = ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n",
    "        \n",
    "        df[\"IPred\"] = [iprediction( word_vectors[w], ideal_dim, ideal_wt, ideal_bias) for w in df[\"Row\"]]\n",
    "                \n",
    "        # evaluate\n",
    "        res_s = stats.pearsonr(df[\"Gold\"], df[\"Pred\"])\n",
    "        res_i = stats.pearsonr(df[\"Gold\"], df[\"IPred\"])\n",
    "        \n",
    "        print(f\"{grandcategory:12s}-{grandfeature:12s} Pred r={res_s.statistic:.3f} p={res_s.pvalue:.3f} IPred ={res_i.statistic:.3f} p={res_i.pvalue:.3f}\")\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_rseed_r\"] = res_i.statistic\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_rseed_p\"] = res_i.pvalue               \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47e0be0c-a6a1-4246-bf2b-192dc93fae55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with significant correlations:\n",
      "Fitted dimensions, seed-based: 1.0\n",
      "For comparison, seed-based: 0.679\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage with significant correlations:\")\n",
    "sig = sum([r[\"fitted_rseed_p\"] <= 0.05 for r in results_fitted.values() if r[\"fitted_rseed_r\"] > 0])\n",
    "print(\"Fitted dimensions, seed-based:\", round(sig / len(results_fitted), 3))\n",
    "seed_sig = sum([r[\"seed_p\"] <= 0.05 for r in results_fitted.values() if r[\"seed_r\"] > 0])\n",
    "print(\"For comparison, seed-based:\", round(seed_sig / len(results_fitted), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89eeba-918b-474e-94e3-20db6c506fa5",
   "metadata": {},
   "source": [
    "# Does having the seeds helps against under-determined dimensions?\n",
    "\n",
    "Previously we saw that we were able to compute perfect fitted dimensions with scrambled ratings, as long as the words were from a coherent category. Our guess was that this was because there are many ways in which words from a coherent category relate to each other, so that the dimension is under-determined given just the word embeddings. So when we add seed words to the training data, does it get harder to fit dimensions with scrambled ratings?\n",
    "\n",
    "Nope. We still get significant correlations in all cases. Maybe the words just overrule the seeds. We may need a more complex objective function that lets us give more weight to the seeds. \n",
    "\n",
    "So, how well are we predicting the seed words at the end of the procedure? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b428753-796b-44e8-8361-e4fe30419ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrambled ratings, fitted dimensions with seed words\n",
      "cities      -temperature  IPred =0.984 p=0.000\n",
      "professions -intelligence IPred =0.979 p=0.000\n",
      "cities      -intelligence IPred =0.996 p=0.000\n",
      "clothing    -location     IPred =0.996 p=0.000\n",
      "cities      -arousal      IPred =0.996 p=0.000\n",
      "clothing    -arousal      IPred =0.996 p=0.000\n",
      "states      -size         IPred =0.998 p=0.000\n",
      "sports      -intelligence IPred =0.991 p=0.000\n",
      "names       -age          IPred =0.996 p=0.000\n",
      "clothing    -wealth       IPred =0.994 p=0.000\n",
      "weather     -danger       IPred =0.989 p=0.000\n",
      "professions -danger       IPred =0.994 p=0.000\n",
      "clothing    -size         IPred =0.992 p=0.000\n",
      "animals     -size         IPred =0.995 p=0.000\n",
      "sports      -wealth       IPred =0.995 p=0.000\n",
      "professions -valence      IPred =0.991 p=0.000\n",
      "names       -wealth       IPred =0.997 p=0.000\n",
      "cities      -cost         IPred =0.994 p=0.000\n",
      "cities      -wealth       IPred =0.992 p=0.000\n",
      "professions -gender       IPred =0.994 p=0.000\n",
      "states      -religiosity  IPred =0.992 p=0.000\n",
      "clothing    -age          IPred =0.996 p=0.000\n",
      "weather     -wetness      IPred =0.991 p=0.000\n",
      "professions -wealth       IPred =0.981 p=0.000\n",
      "myth        -valence      IPred =0.992 p=0.000\n",
      "clothing    -cost         IPred =0.994 p=0.000\n",
      "professions -age          IPred =0.998 p=0.000\n",
      "myth        -size         IPred =0.993 p=0.000\n",
      "sports      -danger       IPred =0.977 p=0.000\n",
      "names       -gender       IPred =0.998 p=0.000\n",
      "cities      -danger       IPred =0.993 p=0.000\n",
      "animals     -weight       IPred =0.996 p=0.000\n",
      "sports      -gender       IPred =0.991 p=0.000\n",
      "professions -location     IPred =0.994 p=0.000\n",
      "sports      -speed        IPred =0.988 p=0.000\n",
      "states      -temperature  IPred =0.980 p=0.000\n",
      "professions -arousal      IPred =0.979 p=0.000\n",
      "cities      -size         IPred =0.988 p=0.000\n",
      "states      -wealth       IPred =0.993 p=0.000\n",
      "sports      -arousal      IPred =0.996 p=0.000\n",
      "animals     -wetness      IPred =0.997 p=0.000\n",
      "clothing    -gender       IPred =0.993 p=0.000\n",
      "weather     -temperature  IPred =0.988 p=0.000\n",
      "cities      -religiosity  IPred =0.994 p=0.000\n",
      "animals     -intelligence IPred =0.997 p=0.000\n",
      "states      -political    IPred =0.967 p=0.000\n",
      "names       -intelligence IPred =0.997 p=0.000\n",
      "myth        -gender       IPred =0.998 p=0.000\n",
      "animals     -speed        IPred =0.998 p=0.000\n",
      "animals     -gender       IPred =0.998 p=0.000\n",
      "states      -cost         IPred =0.979 p=0.000\n",
      "myth        -danger       IPred =0.990 p=0.000\n",
      "animals     -danger       IPred =0.994 p=0.000\n",
      "animals     -loudness     IPred =0.998 p=0.000\n",
      "states      -intelligence IPred =0.996 p=0.000\n",
      "sports      -location     IPred =0.986 p=0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Scrambled ratings, fitted dimensions with seed words\")\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        thisdata_vectors = []\n",
    "        thisdata_gold = []\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            thisdata_gold.append( row.Gold)\n",
    "      \n",
    "        #SCRAMBLING\n",
    "        random.shuffle(thisdata_gold)\n",
    "        thisdata_gold_noseed = thisdata_gold.copy()\n",
    "        \n",
    "        # adding seed words, with non-scrambled ratings\n",
    "        lowvalue = df[\"Gold\"].min() - 0.5\n",
    "        highvalue = df[\"Gold\"].max() + 0.5\n",
    "        \n",
    "        for seed in pos_seedwords:\n",
    "            thisdata_vectors.append( word_vectors [ seed ])\n",
    "            thisdata_gold.append( highvalue + random.uniform(0.001, 0.005))\n",
    "\n",
    "        for seed in neg_seedwords:\n",
    "            thisdata_vectors.append( word_vectors [ seed ])\n",
    "            thisdata_gold.append( lowvalue - random.uniform(0.001, 0.005))\n",
    "            \n",
    "            \n",
    "        ideal_dim, ideal_wt, ideal_bias = ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n",
    "        \n",
    "        df[\"IPred\"] = [iprediction( word_vectors[w], ideal_dim, ideal_wt, ideal_bias) for w in df[\"Row\"]]\n",
    "        \n",
    "        # evaluate, again against the scrambled ratings\n",
    "        res_i = stats.pearsonr(thisdata_gold_noseed, df[\"IPred\"])\n",
    "        \n",
    "        print(f\"{grandcategory:12s}-{grandfeature:12s} IPred ={res_i.statistic:.3f} p={res_i.pvalue:.3f}\")\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_rseed_scrambled_r\"] = res_i.statistic\n",
    "        results_fitted[(grandcategory, grandfeature)][\"fitted_rseed_scrambled_p\"] = res_i.pvalue\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1118bc88-3d7a-441d-8e2a-8f7b4ac64567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with significant correlations:\n",
      "Fitted dimensions w scrambled ratings: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage with significant correlations:\")\n",
    "sig = sum([r[\"fitted_rseed_scrambled_p\"] <= 0.05 for r in results_fitted.values() if r[\"fitted_rseed_scrambled_r\"] > 0])\n",
    "print(\"Fitted dimensions w scrambled ratings:\", round(sig / len(results_fitted), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582167f9-0d1c-474b-9c9d-189efadfc1b5",
   "metadata": {},
   "source": [
    "# Training and test set\n",
    "\n",
    "When we set aside a test set, and train only on part of the data, we can test how well the dimensions generalize. \n",
    "\n",
    "The original seed dimensions, trained on all ratings, don't generalize. Will fitted dimensions with seeds generalize? \n",
    "\n",
    "## Evaluation measure issues\n",
    "\n",
    "We cannot use Pearson's r anymore because the p values become unreliable with small datasets. Grand et al evaluate using OC_p, pairwise order consistency. Another obvious option is Mean Squared Error MSE, basically squared residuals. If we switch evaluations like that, will the results still tell the same story? We first check for correlation among evaluation measures when training on the whole data, testing for seed-based dimensions, fitted dimensions, and fitted dimensions with seeds. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41f9c839-df2b-4a3b-b2aa-fb4f86f1068b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# pairwise order consistency, normal definition\n",
    "def pairwise_order_consistency(goldvalues, modelvalues):\n",
    "    if len(goldvalues) != len(modelvalues):\n",
    "        raise Exception(\"shouldn't be here\")\n",
    "        \n",
    "    outcomes = [ ]\n",
    "    for i1, i2 in itertools.combinations(range(len(goldvalues)), 2):\n",
    "        goldrel = (goldvalues[i1] > goldvalues[i2])\n",
    "        modelrel = (modelvalues[i1] > modelvalues[i2])\n",
    "        outcomes.append(int(goldrel == modelrel))\n",
    "        \n",
    "    return sum(outcomes) / len(outcomes)\n",
    "\n",
    "# pairwise order consistency only for a subset of the model values \n",
    "def pairwise_order_consistency_wrt(goldvalues, modelvalues, test_indices):\n",
    "    if len(goldvalues) != len(modelvalues):\n",
    "        raise Exception(\"shouldn't be here\")\n",
    "        \n",
    "    outcomes = [ ]\n",
    "    for i1 in test_indices:\n",
    "        for i2 in range(len(goldvalues)):\n",
    "            if i1 == i2: continue\n",
    "            \n",
    "            goldrel = (goldvalues[i1] > goldvalues[i2])\n",
    "            modelrel = (modelvalues[i1] > modelvalues[i2])\n",
    "            outcomes.append(int(goldrel == modelrel))\n",
    "        \n",
    "    return sum(outcomes) / len(outcomes)\n",
    "\n",
    "# mean squared error\n",
    "def mean_squared_error(goldvalues, modelvalues):\n",
    "    if len(goldvalues) != len(modelvalues):\n",
    "        raise Exception(\"shouldn't be here\")\n",
    "    return sum([(g - m)**2 for g, m in zip(goldvalues, modelvalues)]) / len(goldvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb599d56-42a0-4396-93a7-470832a8adfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combined method: fitted dimension with seeds\n",
    "def fitted_dimension_withseeds(thisdata_vectors, thisdata_gold, feature_dim, \n",
    "                               pos_seedwords, neg_seedwords, word_vectors, offset = 0.5, jitter = False):\n",
    "    # adding seed words\n",
    "    \n",
    "    lowvalue = min(thisdata_gold) - offset\n",
    "    highvalue = max(thisdata_gold) + offset\n",
    "        \n",
    "    for seed in pos_seedwords:\n",
    "        thisdata_vectors.append( word_vectors [ seed ])\n",
    "        j = random.uniform(0.001, 0.005) if jitter else 0\n",
    "        thisdata_gold.append( highvalue + j)\n",
    "\n",
    "    for seed in neg_seedwords:\n",
    "        thisdata_vectors.append( word_vectors [ seed ])\n",
    "        j = random.uniform(0.001, 0.005) if jitter else 0\n",
    "        thisdata_gold.append( lowvalue - j)\n",
    "            \n",
    "            \n",
    "    return ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7b473-18b3-4b65-b7fe-64e6437b8c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training on all data, computing more evaluation measures \n",
    "# so we can test for correlation among evaluation measures\n",
    "\n",
    "rvalues_seed = [ ]\n",
    "rvalues_fit = [ ]\n",
    "rvalues_sfit = [ ]\n",
    "ocp_seed = [ ]\n",
    "ocp_fit = [ ]\n",
    "ocp_sfit = [ ]\n",
    "msevalues_seed = [ ]\n",
    "msevalues_fit = [ ]\n",
    "msevalues_sfit = [ ]\n",
    "\n",
    "offset = 0.5\n",
    "jitter = False\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "        \n",
    "        # make average seed-based dimension, use for predictions\n",
    "        dimension_vec = average_dim_vector(pos_seedwords, neg_seedwords, word_vectors)\n",
    "        df[\"Pred\"] = [vector_scalar_projection( word_vectors[w], dimension_vec) for w in df[\"Row\"]]\n",
    "        sweight, sbias = coef_for_seed_dimension(df[\"Gold\"], df[\"Pred\"])\n",
    "        adjusted_spred = sprediction(df[\"Pred\"], sweight, sbias)\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        thisdata_vectors = []\n",
    "        thisdata_gold = []\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            thisdata_gold.append( row.Gold)\n",
    "        \n",
    "        ideal_dim, ideal_wt, ideal_bias = ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n",
    "        \n",
    "        df[\"IPred\"] = [iprediction( word_vectors[w], ideal_dim, ideal_wt, ideal_bias) for w in df[\"Row\"]]\n",
    "        \n",
    "        # make fitted dimension with seeds, use for predictions    \n",
    "        lowvalue = df[\"Gold\"].min() - offset\n",
    "        highvalue = df[\"Gold\"].max() + offset\n",
    "        \n",
    "        for seed in pos_seedwords:\n",
    "            thisdata_vectors.append( word_vectors [ seed ])\n",
    "            j = random.uniform(0.001, 0.005) if jitter else 0\n",
    "            thisdata_gold.append( highvalue + j)\n",
    "\n",
    "        for seed in neg_seedwords:\n",
    "            thisdata_vectors.append( word_vectors [ seed ])\n",
    "            j = random.uniform(0.001, 0.005) if jitter else 0\n",
    "            thisdata_gold.append( lowvalue - j)\n",
    "            \n",
    "            \n",
    "        ideal_dim, ideal_wt, ideal_bias = ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n",
    "        df[\"I2Pred\"] = [iprediction( word_vectors[w], ideal_dim, ideal_wt, ideal_bias) for w in df[\"Row\"]]\n",
    "        \n",
    "        # evaluate\n",
    "        res_s = stats.pearsonr(df[\"Gold\"], df[\"Pred\"])\n",
    "        res_i = stats.pearsonr(df[\"Gold\"], df[\"IPred\"])\n",
    "        res_2 = stats.pearsonr(df[\"Gold\"], df[\"I2Pred\"])\n",
    "        ocp_s = pairwise_order_consistency(df[\"Gold\"], df[\"Pred\"])\n",
    "        ocp_i = pairwise_order_consistency(df[\"Gold\"], df[\"IPred\"])\n",
    "        ocp_2 = pairwise_order_consistency(df[\"Gold\"], df[\"I2Pred\"])\n",
    "        mse_s = mean_squared_error(df[\"Gold\"], adjusted_spred)\n",
    "        mse_i = mean_squared_error(df[\"Gold\"], df[\"IPred\"])\n",
    "        mse_2 = mean_squared_error(df[\"Gold\"], df[\"I2Pred\"])\n",
    "        \n",
    "        rvalues_seed.append(res_s.statistic)\n",
    "        rvalues_fit.append(res_i.statistic)\n",
    "        rvalues_sfit.append(res_2.statistic)\n",
    "        ocp_seed.append(ocp_s)\n",
    "        ocp_fit.append(ocp_i)\n",
    "        ocp_sfit.append(ocp_2)\n",
    "        msevalues_seed.append(mse_s)\n",
    "        msevalues_fit.append(mse_i)\n",
    "        msevalues_sfit.append(mse_2)\n",
    "        \n",
    "        \n",
    "        print(f\"{grandcategory:12s}-{grandfeature:12s} Pred r={res_s.statistic:.2f} p={res_s.pvalue:.2f} ocp={ocp_s:.2f} mse={mse_s:.2f}\",\n",
    "              f\"IPred ={res_i.statistic:.2f} p={res_i.pvalue:.2f} ocp={ocp_i:.2f} mse={mse_i:.2f}\",\n",
    "              f\"ISPred ={res_2.statistic:.2f} p={res_2.pvalue:.2f} ocp={ocp_2:.2f} mse={mse_2:.2f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fdd10ad-6075-4653-9a02-b55c50f1d0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and sd OC_P, seed-based: 0.641 0.108\n",
      "Mean and sd OC_P, fitted: 0.967 0.012\n",
      "Mean and sd OC_P, fit+seed: 0.962 0.015\n",
      "\n",
      "Median, mean and sd MSE, seed-based: 3.812 37839.374 278945.854\n",
      "Median, mean and sd MSE, fitted: 0.059 0.074 0.056\n",
      "Median, mean and sd MSE, fit_seed: 0.068 0.079 0.056\n",
      "Median, mean and sd MSE, seed-based, fixed: 3.493 30.575 57.855\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "# average evaluation ratings\n",
    "print(f\"Mean and sd OC_P, seed-based: {statistics.mean(ocp_seed):.3f} {statistics.stdev(ocp_seed):.3f}\")\n",
    "print(f\"Mean and sd OC_P, fitted: {statistics.mean(ocp_fit):.3f} {statistics.stdev(ocp_fit):.3f}\")\n",
    "print(f\"Mean and sd OC_P, fit+seed: {statistics.mean(ocp_sfit):.3f} {statistics.stdev(ocp_sfit):.3f}\")\n",
    "print()\n",
    "\n",
    "print(f\"Median, mean and sd MSE, seed-based: {statistics.median(msevalues_seed):.3f} {statistics.mean(msevalues_seed):.3f} {statistics.stdev(msevalues_seed):.3f}\")\n",
    "print(f\"Median, mean and sd MSE, fitted: {statistics.median(msevalues_fit):.3f} {statistics.mean(msevalues_fit):.3f} {statistics.stdev(msevalues_fit):.3f}\")\n",
    "print(f\"Median, mean and sd MSE, fit_seed: {statistics.median(msevalues_sfit):.3f} {statistics.mean(msevalues_sfit):.3f} {statistics.stdev(msevalues_sfit):.3f}\")\n",
    " \n",
    "    \n",
    "# Let's do that again and remove extreme outliers among MSE values\n",
    "new_mseseed = [ ]\n",
    "removing_ix = [ ]\n",
    "for i in range(len(msevalues_seed)):\n",
    "    if msevalues_seed[i] > 1000:\n",
    "        removing_ix.append(i)\n",
    "    else:\n",
    "        new_mseseed.append(msevalues_seed[i])\n",
    "        \n",
    "print(f\"Median, mean and sd MSE, seed-based, fixed: {statistics.median(new_mseseed):.3f} {statistics.mean(new_mseseed):.3f} {statistics.stdev(new_mseseed):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c744e7ed-b4b9-4c83-8a03-e45328b00485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Pearson/OC_p, seed-based: 0.972 0.000\n",
      "Correlation Pearson/OC_p, fitted: 0.642 0.000\n",
      "Correlation Pearson/OC_p, fit+seed: 0.487 0.000\n",
      "\n",
      "Correlation Pearson/MSE, seed-based: -0.186 0.170\n",
      "Correlation Pearson/MSE, fitted: -0.398 0.002\n",
      "Correlation Pearson/MSE, fit+seed: -0.138 0.312\n",
      "Correlation Pearson/MSE, seed-based, fixed: -0.720 0.000\n",
      "Number of removed datapoints due to gigantic MSE 3\n"
     ]
    }
   ],
   "source": [
    "# correlation across ratings\n",
    "res = stats.pearsonr(rvalues_seed, ocp_seed)\n",
    "print(f\"Correlation Pearson/OC_p, seed-based: {res.statistic:.3f} {res.pvalue:.3f}\")\n",
    "res = stats.pearsonr(rvalues_fit, ocp_fit)\n",
    "print(f\"Correlation Pearson/OC_p, fitted: {res.statistic:.3f} {res.pvalue:.3f}\")\n",
    "res = stats.pearsonr(rvalues_sfit, ocp_sfit)\n",
    "print(f\"Correlation Pearson/OC_p, fit+seed: {res.statistic:.3f} {res.pvalue:.3f}\")\n",
    "print()\n",
    "\n",
    "res = stats.pearsonr(rvalues_seed, msevalues_seed)\n",
    "print(f\"Correlation Pearson/MSE, seed-based: {res.statistic:.3f} {res.pvalue:.3f}\")\n",
    "res = stats.pearsonr(rvalues_fit, msevalues_fit)\n",
    "print(f\"Correlation Pearson/MSE, fitted: {res.statistic:.3f} {res.pvalue:.3f}\")\n",
    "res = stats.pearsonr(rvalues_sfit, msevalues_sfit)\n",
    "print(f\"Correlation Pearson/MSE, fit+seed: {res.statistic:.3f} {res.pvalue:.3f}\")\n",
    "\n",
    "\n",
    "new_rseed = [x for i, x in enumerate(rvalues_seed) if i not in removing_ix]\n",
    "res = stats.pearsonr(new_rseed, new_mseseed)\n",
    "print(f\"Correlation Pearson/MSE, seed-based, fixed: {res.statistic:.3f} {res.pvalue:.3f}\")\n",
    "\n",
    "print(\"Number of removed datapoints due to gigantic MSE\", len(removing_ix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d7b9a3-c90b-494e-b0cd-d708759bc108",
   "metadata": {},
   "source": [
    "### What do we learn from this?\n",
    "\n",
    "OC_p is highly correlated with Pearson's r values when computed over the whole dataset. With MSE we do get a highly significant correlation for the fitted dimensions. We also get it for the seed-based dimension if we exclude 3 rogue datapoints. But for the fitted+seed dimensions the correlation is not significant, so MSE may be measuring something different.\n",
    "\n",
    "So we go ahead with OCP and MSE. We want to view OC_p as a stand-in for Pearson's r, however, caveat: We're going to use OC_p differently below, as pairwise order consistency of test set compared to training set. \n",
    "\n",
    "In any case: We can evaluate the train/test split using OC_p and MSE instead of R. \n",
    "This lets us avoid the problem of evaluating on a tiny dataset: We can compute OC_P with respect to all predicted values, \n",
    "and MSE is per individual datapoint anyway, so it's not a problem that there aren't many datapoints to compare.\n",
    "\n",
    "So, with these new measures, what do we learn about generalization of fitted dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e23751e0-3df1-4167-b8bc-d5ba86f69d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test split\n",
      "cities - temperature\n",
      "\tSeed OC_p 0.529 (0.03) Fitted OC_p 0.477 (0.08) Fitted-Seed OC_p 0.495 (0.09) \n",
      "\tSeed MSE 143.853 (39.16) Fitted MSE 27.238 (8.72) Fitted-Seed MSE 24.798 (9.13) \n",
      "professions - intelligence\n",
      "\tSeed OC_p 0.619 (0.05) Fitted OC_p 0.674 (0.09) Fitted-Seed OC_p 0.668 (0.08) \n",
      "\tSeed MSE 3.543 (1.34) Fitted MSE 7.126 (3.16) Fitted-Seed MSE 13.969 (7.30) \n",
      "cities - intelligence\n",
      "\tSeed OC_p 0.590 (0.10) Fitted OC_p 0.611 (0.04) Fitted-Seed OC_p 0.601 (0.04) \n",
      "\tSeed MSE 39.146 (27.80) Fitted MSE 13.576 (9.36) Fitted-Seed MSE 12.986 (8.74) \n",
      "clothing - location\n",
      "\tSeed OC_p 0.583 (0.07) Fitted OC_p 0.604 (0.06) Fitted-Seed OC_p 0.579 (0.12) \n",
      "\tSeed MSE 8.363 (4.88) Fitted MSE 12.970 (5.55) Fitted-Seed MSE 21.090 (8.64) \n",
      "cities - arousal\n",
      "\tSeed OC_p 0.516 (0.08) Fitted OC_p 0.578 (0.11) Fitted-Seed OC_p 0.581 (0.11) \n",
      "\tSeed MSE 2135790.901 (672025.07) Fitted MSE 13.399 (7.08) Fitted-Seed MSE 11.887 (6.33) \n",
      "clothing - arousal\n",
      "\tSeed OC_p 0.561 (0.04) Fitted OC_p 0.603 (0.05) Fitted-Seed OC_p 0.648 (0.07) \n",
      "\tSeed MSE 27.399 (15.02) Fitted MSE 16.571 (11.92) Fitted-Seed MSE 13.752 (9.26) \n",
      "states - size\n",
      "\tSeed OC_p 0.576 (0.02) Fitted OC_p 0.528 (0.04) Fitted-Seed OC_p 0.519 (0.07) \n",
      "\tSeed MSE 7.683 (2.69) Fitted MSE 21.272 (11.40) Fitted-Seed MSE 22.751 (9.87) \n",
      "sports - intelligence\n",
      "\tSeed OC_p 0.678 (0.05) Fitted OC_p 0.587 (0.13) Fitted-Seed OC_p 0.606 (0.13) \n",
      "\tSeed MSE 1.623 (0.25) Fitted MSE 9.569 (4.25) Fitted-Seed MSE 9.900 (5.72) \n",
      "names - age\n",
      "\tSeed OC_p 0.731 (0.04) Fitted OC_p 0.574 (0.10) Fitted-Seed OC_p 0.564 (0.12) \n",
      "\tSeed MSE 1.555 (0.36) Fitted MSE 16.146 (11.15) Fitted-Seed MSE 18.162 (11.46) \n",
      "clothing - wealth\n",
      "\tSeed OC_p 0.628 (0.05) Fitted OC_p 0.619 (0.08) Fitted-Seed OC_p 0.604 (0.08) \n",
      "\tSeed MSE 6.743 (3.71) Fitted MSE 8.893 (2.64) Fitted-Seed MSE 14.582 (4.45) \n",
      "weather - danger\n",
      "\tSeed OC_p 0.793 (0.05) Fitted OC_p 0.582 (0.13) Fitted-Seed OC_p 0.597 (0.14) \n",
      "\tSeed MSE 0.614 (0.37) Fitted MSE 15.995 (2.68) Fitted-Seed MSE 16.567 (5.62) \n",
      "professions - danger\n",
      "\tSeed OC_p 0.647 (0.04) Fitted OC_p 0.585 (0.10) Fitted-Seed OC_p 0.607 (0.07) \n",
      "\tSeed MSE 3.847 (1.64) Fitted MSE 13.693 (8.27) Fitted-Seed MSE 13.594 (6.68) \n",
      "clothing - size\n",
      "\tSeed OC_p 0.527 (0.06) Fitted OC_p 0.532 (0.07) Fitted-Seed OC_p 0.538 (0.09) \n",
      "\tSeed MSE 101.884 (34.11) Fitted MSE 21.887 (11.82) Fitted-Seed MSE 22.096 (13.48) \n",
      "animals - size\n",
      "\tSeed OC_p 0.740 (0.04) Fitted OC_p 0.616 (0.12) Fitted-Seed OC_p 0.589 (0.12) \n",
      "\tSeed MSE 1.134 (0.60) Fitted MSE 12.558 (6.47) Fitted-Seed MSE 12.254 (7.23) \n",
      "sports - wealth\n",
      "\tSeed OC_p 0.626 (0.03) Fitted OC_p 0.585 (0.05) Fitted-Seed OC_p 0.583 (0.09) \n",
      "\tSeed MSE 4.143 (1.81) Fitted MSE 10.347 (4.49) Fitted-Seed MSE 11.634 (4.11) \n",
      "professions - valence\n",
      "\tSeed OC_p 0.581 (0.02) Fitted OC_p 0.606 (0.17) Fitted-Seed OC_p 0.603 (0.16) \n",
      "\tSeed MSE 5.524 (2.21) Fitted MSE 8.191 (5.92) Fitted-Seed MSE 18.358 (13.89) \n",
      "names - wealth\n",
      "\tSeed OC_p 0.652 (0.05) Fitted OC_p 0.621 (0.07) Fitted-Seed OC_p 0.627 (0.06) \n",
      "\tSeed MSE 2.253 (1.64) Fitted MSE 7.272 (3.77) Fitted-Seed MSE 8.254 (4.12) \n",
      "cities - cost\n",
      "\tSeed OC_p 0.531 (0.06) Fitted OC_p 0.586 (0.10) Fitted-Seed OC_p 0.561 (0.10) \n",
      "\tSeed MSE 50.669 (21.92) Fitted MSE 12.992 (2.90) Fitted-Seed MSE 14.157 (3.10) \n",
      "cities - wealth\n",
      "\tSeed OC_p 0.547 (0.07) Fitted OC_p 0.496 (0.11) Fitted-Seed OC_p 0.473 (0.15) \n",
      "\tSeed MSE 60.767 (31.45) Fitted MSE 28.688 (8.22) Fitted-Seed MSE 30.582 (7.04) \n",
      "professions - gender\n",
      "\tSeed OC_p 0.839 (0.01) Fitted OC_p 0.652 (0.06) Fitted-Seed OC_p 0.665 (0.09) \n",
      "\tSeed MSE 0.186 (0.09) Fitted MSE 12.702 (7.39) Fitted-Seed MSE 32.860 (17.02) \n",
      "states - religiosity\n",
      "\tSeed OC_p 0.534 (0.03) Fitted OC_p 0.553 (0.15) Fitted-Seed OC_p 0.552 (0.15) \n",
      "\tSeed MSE 289.168 (208.40) Fitted MSE 16.009 (8.64) Fitted-Seed MSE 18.337 (9.44) \n",
      "clothing - age\n",
      "\tSeed OC_p 0.716 (0.04) Fitted OC_p 0.557 (0.11) Fitted-Seed OC_p 0.565 (0.10) \n",
      "\tSeed MSE 1.950 (0.82) Fitted MSE 14.038 (7.27) Fitted-Seed MSE 14.133 (7.68) \n",
      "weather - wetness\n",
      "\tSeed OC_p 0.693 (0.09) Fitted OC_p 0.613 (0.15) Fitted-Seed OC_p 0.647 (0.11) \n",
      "\tSeed MSE 2.796 (1.62) Fitted MSE 14.332 (7.08) Fitted-Seed MSE 24.649 (16.15) \n",
      "professions - wealth\n",
      "\tSeed OC_p 0.679 (0.04) Fitted OC_p 0.662 (0.08) Fitted-Seed OC_p 0.659 (0.13) \n",
      "\tSeed MSE 2.034 (1.09) Fitted MSE 9.833 (3.15) Fitted-Seed MSE 12.005 (1.92) \n",
      "myth - valence\n",
      "\tSeed OC_p 0.737 (0.03) Fitted OC_p 0.564 (0.13) Fitted-Seed OC_p 0.561 (0.10) \n",
      "\tSeed MSE 1.416 (0.52) Fitted MSE 14.687 (3.24) Fitted-Seed MSE 15.378 (1.91) \n",
      "clothing - cost\n",
      "\tSeed OC_p 0.540 (0.06) Fitted OC_p 0.604 (0.11) Fitted-Seed OC_p 0.586 (0.13) \n",
      "\tSeed MSE 119.489 (39.37) Fitted MSE 8.079 (4.54) Fitted-Seed MSE 15.529 (8.01) \n",
      "professions - age\n",
      "\tSeed OC_p 0.570 (0.01) Fitted OC_p 0.593 (0.09) Fitted-Seed OC_p 0.631 (0.06) \n",
      "\tSeed MSE 18.966 (9.22) Fitted MSE 12.511 (8.06) Fitted-Seed MSE 11.099 (8.71) \n",
      "myth - size\n",
      "\tSeed OC_p 0.760 (0.04) Fitted OC_p 0.562 (0.06) Fitted-Seed OC_p 0.572 (0.04) \n",
      "\tSeed MSE 1.038 (0.45) Fitted MSE 14.640 (4.58) Fitted-Seed MSE 12.842 (4.11) \n",
      "sports - danger\n",
      "\tSeed OC_p 0.626 (0.03) Fitted OC_p 0.588 (0.09) Fitted-Seed OC_p 0.593 (0.08) \n",
      "\tSeed MSE 6.624 (3.15) Fitted MSE 9.374 (1.41) Fitted-Seed MSE 10.310 (2.27) \n",
      "names - gender\n",
      "\tSeed OC_p 0.872 (0.02) Fitted OC_p 0.610 (0.11) Fitted-Seed OC_p 0.607 (0.10) \n",
      "\tSeed MSE 0.131 (0.09) Fitted MSE 8.166 (2.66) Fitted-Seed MSE 13.270 (4.25) \n",
      "cities - danger\n",
      "\tSeed OC_p 0.772 (0.03) Fitted OC_p 0.649 (0.12) Fitted-Seed OC_p 0.647 (0.12) \n",
      "\tSeed MSE 0.957 (0.24) Fitted MSE 10.421 (3.62) Fitted-Seed MSE 11.412 (4.96) \n",
      "animals - weight\n",
      "\tSeed OC_p 0.522 (0.11) Fitted OC_p 0.591 (0.13) Fitted-Seed OC_p 0.593 (0.15) \n",
      "\tSeed MSE 244.503 (88.82) Fitted MSE 17.525 (3.63) Fitted-Seed MSE 17.189 (2.84) \n",
      "sports - gender\n",
      "\tSeed OC_p 0.822 (0.04) Fitted OC_p 0.556 (0.11) Fitted-Seed OC_p 0.538 (0.08) \n",
      "\tSeed MSE 0.355 (0.12) Fitted MSE 9.803 (5.35) Fitted-Seed MSE 18.809 (10.16) \n",
      "professions - location\n",
      "\tSeed OC_p 0.551 (0.03) Fitted OC_p 0.589 (0.05) Fitted-Seed OC_p 0.578 (0.10) \n",
      "\tSeed MSE 60.363 (11.26) Fitted MSE 12.725 (5.26) Fitted-Seed MSE 15.396 (5.63) \n",
      "sports - speed\n",
      "\tSeed OC_p 0.524 (0.05) Fitted OC_p 0.665 (0.09) Fitted-Seed OC_p 0.670 (0.08) \n",
      "\tSeed MSE 1208.833 (462.30) Fitted MSE 5.362 (2.80) Fitted-Seed MSE 4.583 (1.79) \n",
      "states - temperature\n",
      "\tSeed OC_p 0.739 (0.05) Fitted OC_p 0.585 (0.11) Fitted-Seed OC_p 0.598 (0.11) \n",
      "\tSeed MSE 1.782 (0.99) Fitted MSE 13.561 (4.59) Fitted-Seed MSE 15.220 (5.65) \n",
      "professions - arousal\n",
      "\tSeed OC_p 0.669 (0.06) Fitted OC_p 0.681 (0.06) Fitted-Seed OC_p 0.674 (0.06) \n",
      "\tSeed MSE 2.463 (0.85) Fitted MSE 10.306 (4.09) Fitted-Seed MSE 10.605 (3.27) \n",
      "cities - size\n",
      "\tSeed OC_p 0.558 (0.04) Fitted OC_p 0.651 (0.10) Fitted-Seed OC_p 0.662 (0.08) \n",
      "\tSeed MSE 38.779 (17.12) Fitted MSE 12.604 (2.13) Fitted-Seed MSE 12.152 (2.38) \n",
      "states - wealth\n",
      "\tSeed OC_p 0.640 (0.07) Fitted OC_p 0.620 (0.12) Fitted-Seed OC_p 0.632 (0.14) \n",
      "\tSeed MSE 3.414 (1.25) Fitted MSE 11.748 (5.85) Fitted-Seed MSE 11.854 (6.15) \n",
      "sports - arousal\n",
      "\tSeed OC_p 0.592 (0.04) Fitted OC_p 0.639 (0.05) Fitted-Seed OC_p 0.629 (0.07) \n",
      "\tSeed MSE 11.747 (4.19) Fitted MSE 9.024 (3.46) Fitted-Seed MSE 8.327 (3.05) \n",
      "animals - wetness\n",
      "\tSeed OC_p 0.760 (0.07) Fitted OC_p 0.632 (0.16) Fitted-Seed OC_p 0.647 (0.18) \n",
      "\tSeed MSE 0.572 (0.23) Fitted MSE 8.819 (5.42) Fitted-Seed MSE 18.590 (14.37) \n",
      "clothing - gender\n",
      "\tSeed OC_p 0.810 (0.03) Fitted OC_p 0.638 (0.07) Fitted-Seed OC_p 0.595 (0.12) \n",
      "\tSeed MSE 0.487 (0.26) Fitted MSE 7.674 (4.77) Fitted-Seed MSE 14.753 (6.28) \n",
      "weather - temperature\n",
      "\tSeed OC_p 0.663 (0.04) Fitted OC_p 0.644 (0.17) Fitted-Seed OC_p 0.621 (0.16) \n",
      "\tSeed MSE 3.496 (1.56) Fitted MSE 13.824 (7.51) Fitted-Seed MSE 17.512 (5.49) \n",
      "cities - religiosity\n",
      "\tSeed OC_p 0.562 (0.12) Fitted OC_p 0.556 (0.08) Fitted-Seed OC_p 0.551 (0.09) \n",
      "\tSeed MSE 3.786 (1.01) Fitted MSE 13.799 (4.96) Fitted-Seed MSE 14.114 (5.28) \n",
      "animals - intelligence\n",
      "\tSeed OC_p 0.551 (0.06) Fitted OC_p 0.513 (0.07) Fitted-Seed OC_p 0.527 (0.08) \n",
      "\tSeed MSE 134.674 (51.99) Fitted MSE 20.330 (4.77) Fitted-Seed MSE 20.159 (5.61) \n",
      "states - political\n",
      "\tSeed OC_p 0.658 (0.04) Fitted OC_p 0.619 (0.07) Fitted-Seed OC_p 0.584 (0.10) \n",
      "\tSeed MSE 5.115 (1.99) Fitted MSE 16.829 (13.74) Fitted-Seed MSE 29.695 (19.25) \n",
      "names - intelligence\n",
      "\tSeed OC_p 0.736 (0.03) Fitted OC_p 0.590 (0.07) Fitted-Seed OC_p 0.589 (0.10) \n",
      "\tSeed MSE 1.298 (0.54) Fitted MSE 15.075 (4.74) Fitted-Seed MSE 16.539 (5.75) \n",
      "myth - gender\n",
      "\tSeed OC_p 0.746 (0.03) Fitted OC_p 0.529 (0.12) Fitted-Seed OC_p 0.564 (0.10) \n",
      "\tSeed MSE 0.519 (0.23) Fitted MSE 18.919 (6.88) Fitted-Seed MSE 19.525 (8.25) \n",
      "animals - speed\n",
      "\tSeed OC_p 0.600 (0.10) Fitted OC_p 0.556 (0.09) Fitted-Seed OC_p 0.587 (0.10) \n",
      "\tSeed MSE 8.314 (5.61) Fitted MSE 14.330 (3.99) Fitted-Seed MSE 11.286 (3.92) \n",
      "animals - gender\n",
      "\tSeed OC_p 0.726 (0.04) Fitted OC_p 0.620 (0.16) Fitted-Seed OC_p 0.626 (0.13) \n",
      "\tSeed MSE 1.062 (0.26) Fitted MSE 13.601 (9.28) Fitted-Seed MSE 20.798 (11.00) \n",
      "states - cost\n",
      "\tSeed OC_p 0.459 (0.02) Fitted OC_p 0.699 (0.08) Fitted-Seed OC_p 0.660 (0.09) \n",
      "\tSeed MSE 32647.413 (25619.52) Fitted MSE 5.724 (1.98) Fitted-Seed MSE 17.378 (5.38) \n",
      "myth - danger\n",
      "\tSeed OC_p 0.763 (0.07) Fitted OC_p 0.583 (0.07) Fitted-Seed OC_p 0.592 (0.05) \n",
      "\tSeed MSE 0.976 (0.44) Fitted MSE 15.866 (3.26) Fitted-Seed MSE 13.069 (2.55) \n",
      "animals - danger\n",
      "\tSeed OC_p 0.682 (0.10) Fitted OC_p 0.553 (0.11) Fitted-Seed OC_p 0.576 (0.14) \n",
      "\tSeed MSE 1.990 (0.80) Fitted MSE 17.607 (11.39) Fitted-Seed MSE 15.106 (12.35) \n",
      "animals - loudness\n",
      "\tSeed OC_p 0.517 (0.03) Fitted OC_p 0.574 (0.13) Fitted-Seed OC_p 0.580 (0.13) \n",
      "\tSeed MSE 141.973 (42.60) Fitted MSE 19.319 (9.93) Fitted-Seed MSE 17.169 (11.72) \n",
      "states - intelligence\n",
      "\tSeed OC_p 0.574 (0.06) Fitted OC_p 0.576 (0.10) Fitted-Seed OC_p 0.580 (0.09) \n",
      "\tSeed MSE 85.199 (54.02) Fitted MSE 18.727 (4.86) Fitted-Seed MSE 17.901 (5.13) \n",
      "sports - location\n",
      "\tSeed OC_p 0.770 (0.02) Fitted OC_p 0.585 (0.06) Fitted-Seed OC_p 0.583 (0.07) \n",
      "\tSeed MSE 1.281 (0.70) Fitted MSE 10.332 (2.99) Fitted-Seed MSE 15.887 (6.17) \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Training and test split\")\n",
    "\n",
    "numfolds = 5\n",
    "offset = 1.0\n",
    "jitter = False\n",
    "\n",
    "all_evals = [ ]\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "        \n",
    "        \n",
    "        # storage for word vectors and gold values for this dataset\n",
    "        all_thisdata_vectors = []\n",
    "        all_thisdata_gold = []\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            all_thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            all_thisdata_gold.append( row.Gold)\n",
    "      \n",
    "        # crossvalidation setup: give indices to datapoints\n",
    "        fold = np.random.randint(numfolds, size = len(all_thisdata_gold))\n",
    "        \n",
    "        # store the evaluatresults from the different test folds\n",
    "        evals = [ ]\n",
    "        \n",
    "        # iterate over folds, evaluate for each of them\n",
    "        for testfold in range(numfolds):\n",
    "            # compute training and test data for this fold\n",
    "            test_indices =  [i for i in range(len(all_thisdata_gold)) if fold[i] == testfold]\n",
    "            train_indices = [i for i in range(len(all_thisdata_gold)) if fold[i] != testfold]\n",
    "        \n",
    "            gold_test =  [ell[\"Gold\"] for _, ell in df.iloc[ test_indices ].iterrows()]\n",
    "            gold_train = [ ell[\"Gold\"] for _, ell in df.iloc[ train_indices ].iterrows()]\n",
    "            words_test =  [ell[\"Row\"] for _, ell in df.iloc[ test_indices].iterrows()]\n",
    "            words_train = [ell[\"Row\"] for _, ell in df.iloc[ train_indices].iterrows()]\n",
    "            vec_test =  [word_vectors[ w ] for w in words_test]\n",
    "            vec_train = [word_vectors[ w ] for w in words_train ]\n",
    "        \n",
    "\n",
    "            # compute seed-based dimension, and its predictions\n",
    "            seed_dim = average_dim_vector(pos_seedwords, neg_seedwords, word_vectors)\n",
    "            p0 = [vector_scalar_projection( word_vectors[w], seed_dim) for w in df[\"Row\"]]\n",
    "            weight, bias = coef_for_seed_dimension(df[\"Gold\"], p0)\n",
    "            df[\"SPred\"] = [sprediction(p, weight, bias) for p in p0]\n",
    "            \n",
    "            \n",
    "            # compute fitted dimension, and its predictions\n",
    "            fitted_dim, fitted_wt, fitted_bias = ideal_dimension(vec_train, gold_train, feature_dim)\n",
    "            df[\"FPred\"] = [ iprediction( word_vectors[ w], fitted_dim, fitted_wt, fitted_bias) for w in df[\"Row\"]]\n",
    "            \n",
    "            \n",
    "            # compute fitted dimension with seeds, and its predictions\n",
    "            fitted_dim, fitted_wt, fitted_bias = fitted_dimension_withseeds(vec_train, gold_train, feature_dim, \n",
    "                                                                            pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                                            offset = offset, jitter = jitter)\n",
    "            df[\"FSPred\"] = [ iprediction( word_vectors[ w], fitted_dim, fitted_wt, fitted_bias) for w in df[\"Row\"]]\n",
    "            \n",
    "            # order consistency pairwise: test values tested for their ordering wrt. all values, training and test\n",
    "            # MSE: evaluate on test only\n",
    "            e = { \"ocp_s\" : pairwise_order_consistency_wrt(df[\"Gold\"], df[\"SPred\"], test_indices),\n",
    "                  \"ocp_f\" : pairwise_order_consistency_wrt(df[\"Gold\"], df[\"FPred\"], test_indices),\n",
    "                  \"ocp_fs\": pairwise_order_consistency_wrt(df[\"Gold\"], df[\"FSPred\"], test_indices),\n",
    "                  \"mse_s\" : mean_squared_error(gold_test, [p for i, p in enumerate(df[\"SPred\"]) if i in test_indices]),\n",
    "                  \"mse_f\" : mean_squared_error(gold_test, [p for i, p in enumerate(df[\"FPred\"]) if i in test_indices]),\n",
    "                  \"mse_fs\": mean_squared_error(gold_test, [p for i, p in enumerate(df[\"FSPred\"]) if i in test_indices])}\n",
    "            \n",
    "            evals.append(e)\n",
    "            all_evals.append(e)\n",
    "        \n",
    "        print(grandcategory, \"-\", grandfeature)\n",
    "        print(\"\\t\", end = \"\")\n",
    "        for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\")]:\n",
    "            ocps = [e[\"ocp_\" + suffix] for e in evals]\n",
    "            print(name, f\"OC_p {statistics.mean(ocps):.3f} ({statistics.stdev(ocps):.2f})\", end = \" \")\n",
    "        print(\"\\n\\t\", end = \"\")\n",
    "        for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\")]:\n",
    "            mses = [e[\"mse_\" + suffix] for e in evals]\n",
    "            print(name, f\"MSE {statistics.mean(mses):.3f} ({statistics.stdev(mses):.2f})\", end = \" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d914caf5-8358-4c61-8388-34981ea567d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed OC_p mean 0.646 (0.11)\n",
      "Fitted OC_p mean 0.595 (0.10)\n",
      "Fitted-Seed OC_p mean 0.596 (0.10)\n",
      "\n",
      "Seed MSE med 1.141 mean 1.281 (0.70)\n",
      "Fitted MSE med 11.315 mean 10.332 (2.99)\n",
      "Fitted-Seed MSE med 13.712 mean 15.887 (6.17)\n"
     ]
    }
   ],
   "source": [
    "for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\")]:\n",
    "    ocps = [e[\"ocp_\" + suffix] for e in all_evals]\n",
    "    print(name, f\"OC_p mean {statistics.mean(ocps):.3f} ({statistics.stdev(ocps):.2f})\")\n",
    "print()\n",
    "\n",
    "for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\")]:\n",
    "    mses = [e[\"mse_\" + suffix] for e in evals]\n",
    "    print(name, f\"MSE med {statistics.median(mses):.3f} mean {statistics.mean(mses):.3f} ({statistics.stdev(mses):.2f})\") \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0998b-178f-4718-8d11-ab2aaf7dccf0",
   "metadata": {},
   "source": [
    "### Results so far\n",
    "\n",
    "Seed-based dimensions show better results than fitted dimensions, both on terms of OC_p and MSE. There is no clear distinction between fitted dimensions and fitted dimensions with seed in terms of OC_p. In terms of MSE, adding the seeds to the fitted dimensions deteriorates performance. \n",
    "\n",
    "But is this the right way of adding seeds to the fitted dimensions? Another way would be to have a loss that considers both fit of ratings and given seed-based dimensions. An argument for trying this is that fitted+seed dimensions are still able to fit scrambled ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8e01d-379f-4e08-a52b-9edef9b6e86b",
   "metadata": {},
   "source": [
    "# Adding seeds to the fitted dimensions, version 2\n",
    "\n",
    "In this formulation, we actually use the seed-based dimensions to \"disambiguate\" what we want the fitted dimension to do. Our loss function now has two parts, one from the human ratings, and one from the seed-based dimensions. (Currently I'm just summing up the losses from the different seed-based dimensions. One could also try to learn weights for them.)\n",
    "\n",
    "Here is the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0e46c1a-b8fb-43d5-8300-01f18117543f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fitted dimension, with seeds too\n",
    "\n",
    "# Weight/bias defined as trainable variables to optimize during backpropagation along with the feature vector\n",
    "#\n",
    "# parameters:\n",
    "# - word vectors list: list of vectors for the words in our category\n",
    "# - gold ratings: gold ratings on the dimension of interest, \n",
    "#    in the same order as the word vectors list\n",
    "# - feature_dim: dimensionality of the vectors\n",
    "# - random seed\n",
    "#\n",
    "# returns: \n",
    "# - computed vector for the ideal dimension\n",
    "# - weight and bias such that vector * idealvec \\approx weight * goldrating + bias\n",
    "#\n",
    "def fitted_dimension_withseeds(word_vectors_list, gold_ratings, seed_dims, feature_dims, alpha = 0.5, random_seed = 123):\n",
    "    torch.manual_seed(random_seed) \n",
    "\n",
    "    # we compute: a vector of same dimensionality as our embeddings,\n",
    "    # and a weight and a bias constant\n",
    "    feature_vector = torch.randn(feature_dim, requires_grad=True) # dtype=torch.float32)\n",
    "    weight_constant = torch.randn(1, requires_grad=True) \n",
    "    bias_constant = torch.randn(1, requires_grad=True)    \n",
    "\n",
    "    \n",
    "    optimizer = optim.Adam([feature_vector, weight_constant, bias_constant], lr=0.01)\n",
    "    # optimizer = optim.SGD([feature_vector, weight_constant, bias_constant], lr=0.001)\n",
    "\n",
    "    # Number of optimization steps\n",
    "    num_steps = 1000\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    criterion2 = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "    # Gradient clipping threshold\n",
    "    max_norm = 1.0  \n",
    "\n",
    "    for step in range(num_steps):\n",
    "        total_loss1 = 0\n",
    "\n",
    "        # for i in range(len(X_train)):\n",
    "        # \tword_embedding = torch.tensor(X_train[i]) \n",
    "        # \tgold_rating = y_train[i]\n",
    "\n",
    "        for i in range(len(word_vectors_list)):\n",
    "            word_embedding = torch.tensor(word_vectors_list[i])\n",
    "            gold_rating = gold_ratings[i]\n",
    "\n",
    "            dot_product = torch.dot(word_embedding, feature_vector)\n",
    "            weighted_gold = gold_rating * weight_constant\n",
    "            loss1 = ((dot_product - weighted_gold - bias_constant) ** 2)\n",
    "\n",
    "            total_loss1 += loss1\n",
    "            \n",
    "        \n",
    "        avg_loss1 = total_loss1 / len(word_vectors_list)\n",
    "        loss2 = sum([criterion2( feature_vector, d, torch.tensor(1.0)) for d in seed_dims]) / len(seed_dims)\n",
    "        total_loss = alpha*avg_loss1 + (1-alpha) * loss2\n",
    "\n",
    "        total_loss.backward()\n",
    "\n",
    "        # Compute the gradient norms and monitor them during training\n",
    "\n",
    "        # feature_vector_grad_norm = torch.norm(feature_vector.grad)\n",
    "        # print(f\"Step {step+1}, Feature Vector Gradient Norm: {feature_vector_grad_norm.item()}\")\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_([feature_vector, weight_constant, bias_constant], max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(total_loss.item())\n",
    "\n",
    "    \n",
    "    return (feature_vector.detach().numpy(), weight_constant.item(), bias_constant.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa17a01-eceb-405f-9ce7-10625db5788e",
   "metadata": {},
   "source": [
    "## Scrambled ratings again\n",
    "\n",
    "We again scramble the ratings but keep the words, so that they are from the same category. With the seed-based dimensions to pull the model in the direction of the intended property, it should be harder for the model to learn dimensions for scrambled ratings -- and indeed it is. \n",
    "\n",
    "Alpha is the parameter for how to combine the two loss functions, where alpha is the contribution of the human ratings, and (1-alpha) the contribution from the seed dimensions. I am not really sure on what scale the losses from the human ratings are, so it's hard to say what alpha means. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "961f3500-6027-42e3-91f8-dfd5241d2741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrambled ratings, fitted dimensions with seed words, new formulation\n",
      "cities      -temperature  IPred r=0.864 p=0.000\n",
      "professions -intelligence IPred r=0.313 p=0.029\n",
      "cities      -intelligence IPred r=0.163 p=0.257\n",
      "clothing    -location     IPred r=0.562 p=0.000\n",
      "cities      -arousal      IPred r=0.343 p=0.015\n",
      "clothing    -arousal      IPred r=0.551 p=0.000\n",
      "states      -size         IPred r=0.004 p=0.978\n",
      "sports      -intelligence IPred r=0.274 p=0.054\n",
      "names       -age          IPred r=0.866 p=0.000\n",
      "clothing    -wealth       IPred r=0.634 p=0.000\n",
      "weather     -danger       IPred r=0.312 p=0.060\n",
      "professions -danger       IPred r=0.422 p=0.003\n",
      "clothing    -size         IPred r=0.661 p=0.000\n",
      "animals     -size         IPred r=-0.173 p=0.327\n",
      "sports      -wealth       IPred r=0.022 p=0.880\n",
      "professions -valence      IPred r=-0.131 p=0.368\n",
      "names       -wealth       IPred r=0.240 p=0.093\n",
      "cities      -cost         IPred r=0.670 p=0.000\n",
      "cities      -wealth       IPred r=0.706 p=0.000\n",
      "professions -gender       IPred r=0.172 p=0.237\n",
      "states      -religiosity  IPred r=-0.029 p=0.840\n",
      "clothing    -age          IPred r=0.839 p=0.000\n",
      "weather     -wetness      IPred r=0.809 p=0.000\n",
      "professions -wealth       IPred r=0.368 p=0.009\n",
      "myth        -valence      IPred r=0.695 p=0.000\n",
      "clothing    -cost         IPred r=-0.013 p=0.928\n",
      "professions -age          IPred r=0.800 p=0.000\n",
      "myth        -size         IPred r=0.894 p=0.000\n",
      "sports      -danger       IPred r=0.501 p=0.000\n",
      "names       -gender       IPred r=0.653 p=0.000\n",
      "cities      -danger       IPred r=0.163 p=0.257\n",
      "animals     -weight       IPred r=0.287 p=0.099\n",
      "sports      -gender       IPred r=0.759 p=0.000\n",
      "professions -location     IPred r=0.358 p=0.012\n",
      "sports      -speed        IPred r=-0.027 p=0.852\n",
      "states      -temperature  IPred r=0.897 p=0.000\n",
      "professions -arousal      IPred r=-0.028 p=0.846\n",
      "cities      -size         IPred r=0.410 p=0.003\n",
      "states      -wealth       IPred r=0.463 p=0.001\n",
      "sports      -arousal      IPred r=0.218 p=0.129\n",
      "animals     -wetness      IPred r=0.018 p=0.917\n",
      "clothing    -gender       IPred r=0.318 p=0.024\n",
      "weather     -temperature  IPred r=0.622 p=0.000\n",
      "cities      -religiosity  IPred r=-0.059 p=0.682\n",
      "animals     -intelligence IPred r=0.397 p=0.020\n",
      "states      -political    IPred r=0.301 p=0.034\n",
      "names       -intelligence IPred r=0.574 p=0.000\n",
      "myth        -gender       IPred r=0.077 p=0.593\n",
      "animals     -speed        IPred r=-0.186 p=0.292\n",
      "animals     -gender       IPred r=-0.065 p=0.714\n",
      "states      -cost         IPred r=0.465 p=0.001\n",
      "myth        -danger       IPred r=0.334 p=0.018\n",
      "animals     -danger       IPred r=0.691 p=0.000\n",
      "animals     -loudness     IPred r=0.519 p=0.002\n",
      "states      -intelligence IPred r=0.180 p=0.212\n",
      "sports      -location     IPred r=0.585 p=0.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Scrambled ratings, fitted dimensions with seed words, new formulation\")\n",
    "\n",
    "alpha = 0.03\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "\n",
    "        \n",
    "        # make ideal dimension, use for predictions\n",
    "        thisdata_vectors = []\n",
    "        thisdata_gold = []\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            thisdata_gold.append( row.Gold)\n",
    "      \n",
    "        #SCRAMBLING\n",
    "        random.shuffle(thisdata_gold)\n",
    "\n",
    "        diffvectors = [ ]\n",
    "    \n",
    "        for negword in neg_seedwords:\n",
    "            for posword in pos_seedwords:\n",
    "                diffvectors.append(torch.from_numpy(word_vectors[posword] - word_vectors[negword]))\n",
    "            \n",
    "        ideal_dim, ideal_wt, ideal_bias = fitted_dimension_withseeds(thisdata_vectors, thisdata_gold, diffvectors, feature_dim, alpha = alpha)\n",
    "        \n",
    "        df[\"IPred\"] = [iprediction( word_vectors[w], ideal_dim, ideal_wt, ideal_bias) for w in df[\"Row\"]]\n",
    "        \n",
    "        # evaluate, again against the scrambled ratings\n",
    "        res_i = stats.pearsonr(thisdata_gold, df[\"IPred\"])\n",
    "        \n",
    "        print(f\"{grandcategory:12s}-{grandfeature:12s} IPred r={res_i.statistic:.3f} p={res_i.pvalue:.3f}\")\n",
    "        \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe60b4-3bd0-4f19-8dcd-68a13f16f08f",
   "metadata": {},
   "source": [
    "## So, how about a training and test split?\n",
    "\n",
    "With the combined loss, do we do better at predicting results for the test data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26725a-7bf5-49d2-9e3f-2a4ccd32e76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "311fbad5-62a5-45fb-8feb-45a4f54a2ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test split, two-loss formulation for fitted dimensions\n",
      "cities - temperature\n",
      "\tSeed OC_p 0.523 (0.05) Fitted OC_p 0.507 (0.08) Fitted-Seed OC_p 0.645 (0.05) \n",
      "\tSeed MSE 119.793 (62.04) Fitted MSE 24.528 (7.56) Fitted-Seed MSE 956.412 (315.99) \n",
      "professions - intelligence\n",
      "\tSeed OC_p 0.630 (0.04) Fitted OC_p 0.654 (0.04) Fitted-Seed OC_p 0.361 (0.04) \n",
      "\tSeed MSE 3.236 (1.73) Fitted MSE 8.965 (5.01) Fitted-Seed MSE 1522530.221 (722445.99) \n",
      "cities - intelligence\n",
      "\tSeed OC_p 0.581 (0.05) Fitted OC_p 0.569 (0.09) Fitted-Seed OC_p 0.533 (0.06) \n",
      "\tSeed MSE 34.913 (23.60) Fitted MSE 11.133 (4.65) Fitted-Seed MSE 1139667.756 (351579.68) \n",
      "clothing - location\n",
      "\tSeed OC_p 0.601 (0.06) Fitted OC_p 0.554 (0.08) Fitted-Seed OC_p 0.508 (0.07) \n",
      "\tSeed MSE 7.964 (4.10) Fitted MSE 12.845 (5.89) Fitted-Seed MSE 98.463 (68.91) \n",
      "cities - arousal\n",
      "\tSeed OC_p 0.525 (0.05) Fitted OC_p 0.585 (0.06) Fitted-Seed OC_p 0.583 (0.05) \n",
      "\tSeed MSE 2076351.291 (809620.70) Fitted MSE 13.715 (6.49) Fitted-Seed MSE 1080.614 (397.45) \n",
      "clothing - arousal\n",
      "\tSeed OC_p 0.561 (0.05) Fitted OC_p 0.574 (0.10) Fitted-Seed OC_p 0.342 (0.02) \n",
      "\tSeed MSE 27.431 (8.72) Fitted MSE 21.229 (8.05) Fitted-Seed MSE 2207.818 (1420.49) \n",
      "states - size\n",
      "\tSeed OC_p 0.556 (0.07) Fitted OC_p 0.549 (0.08) Fitted-Seed OC_p 0.399 (0.08) \n",
      "\tSeed MSE 8.236 (2.37) Fitted MSE 12.913 (5.84) Fitted-Seed MSE 6184.181 (2242.37) \n",
      "sports - intelligence\n",
      "\tSeed OC_p 0.701 (0.05) Fitted OC_p 0.649 (0.05) Fitted-Seed OC_p 0.465 (0.06) \n",
      "\tSeed MSE 1.409 (0.70) Fitted MSE 9.113 (4.63) Fitted-Seed MSE 37111.842 (10065.36) \n",
      "names - age\n",
      "\tSeed OC_p 0.709 (0.05) Fitted OC_p 0.596 (0.14) Fitted-Seed OC_p 0.420 (0.06) \n",
      "\tSeed MSE 2.089 (1.48) Fitted MSE 14.272 (3.50) Fitted-Seed MSE 2969.284 (662.68) \n",
      "clothing - wealth\n",
      "\tSeed OC_p 0.620 (0.05) Fitted OC_p 0.611 (0.08) Fitted-Seed OC_p 0.576 (0.05) \n",
      "\tSeed MSE 5.898 (4.36) Fitted MSE 9.915 (3.07) Fitted-Seed MSE 146534.293 (71380.58) \n",
      "weather - danger\n",
      "\tSeed OC_p 0.799 (0.02) Fitted OC_p 0.541 (0.16) Fitted-Seed OC_p 0.236 (0.02) \n",
      "\tSeed MSE 0.580 (0.21) Fitted MSE 17.002 (3.59) Fitted-Seed MSE 822.106 (497.37) \n",
      "professions - danger\n",
      "\tSeed OC_p 0.650 (0.04) Fitted OC_p 0.567 (0.06) Fitted-Seed OC_p 0.466 (0.07) \n",
      "\tSeed MSE 3.654 (1.70) Fitted MSE 16.917 (5.57) Fitted-Seed MSE 184.139 (39.16) \n",
      "clothing - size\n",
      "\tSeed OC_p 0.541 (0.07) Fitted OC_p 0.545 (0.05) Fitted-Seed OC_p 0.477 (0.06) \n",
      "\tSeed MSE 102.278 (33.71) Fitted MSE 30.524 (16.86) Fitted-Seed MSE 2993.513 (898.45) \n",
      "animals - size\n",
      "\tSeed OC_p 0.738 (0.03) Fitted OC_p 0.604 (0.09) Fitted-Seed OC_p 0.318 (0.07) \n",
      "\tSeed MSE 1.329 (0.83) Fitted MSE 16.615 (11.40) Fitted-Seed MSE 6090.795 (3396.85) \n",
      "sports - wealth\n",
      "\tSeed OC_p 0.625 (0.07) Fitted OC_p 0.600 (0.11) Fitted-Seed OC_p 0.482 (0.09) \n",
      "\tSeed MSE 3.965 (1.39) Fitted MSE 10.664 (1.73) Fitted-Seed MSE 7397.422 (910.47) \n",
      "professions - valence\n",
      "\tSeed OC_p 0.575 (0.04) Fitted OC_p 0.648 (0.09) Fitted-Seed OC_p 0.580 (0.03) \n",
      "\tSeed MSE 5.813 (1.23) Fitted MSE 7.395 (1.62) Fitted-Seed MSE 274.511 (71.03) \n",
      "names - wealth\n",
      "\tSeed OC_p 0.662 (0.06) Fitted OC_p 0.637 (0.05) Fitted-Seed OC_p 0.503 (0.08) \n",
      "\tSeed MSE 2.216 (0.91) Fitted MSE 8.357 (5.25) Fitted-Seed MSE 113224.621 (23320.68) \n",
      "cities - cost\n",
      "\tSeed OC_p 0.529 (0.09) Fitted OC_p 0.581 (0.08) Fitted-Seed OC_p 0.543 (0.06) \n",
      "\tSeed MSE 60.706 (36.81) Fitted MSE 14.719 (5.38) Fitted-Seed MSE 1727.578 (367.76) \n",
      "cities - wealth\n",
      "\tSeed OC_p 0.543 (0.05) Fitted OC_p 0.497 (0.08) Fitted-Seed OC_p 0.495 (0.06) \n",
      "\tSeed MSE 67.342 (38.23) Fitted MSE 27.084 (9.26) Fitted-Seed MSE 98527.193 (37517.27) \n",
      "professions - gender\n",
      "\tSeed OC_p 0.842 (0.03) Fitted OC_p 0.665 (0.07) Fitted-Seed OC_p 0.779 (0.02) \n",
      "\tSeed MSE 0.176 (0.08) Fitted MSE 10.578 (6.83) Fitted-Seed MSE 212.328 (159.78) \n",
      "states - religiosity\n",
      "\tSeed OC_p 0.540 (0.05) Fitted OC_p 0.514 (0.11) Fitted-Seed OC_p 0.395 (0.05) \n",
      "\tSeed MSE 235.327 (138.28) Fitted MSE 16.558 (8.74) Fitted-Seed MSE 58.465 (8.37) \n",
      "clothing - age\n",
      "\tSeed OC_p 0.709 (0.02) Fitted OC_p 0.621 (0.13) Fitted-Seed OC_p 0.487 (0.06) \n",
      "\tSeed MSE 2.039 (0.84) Fitted MSE 13.182 (8.37) Fitted-Seed MSE 1518.824 (619.53) \n",
      "weather - wetness\n",
      "\tSeed OC_p 0.681 (0.04) Fitted OC_p 0.671 (0.14) Fitted-Seed OC_p 0.692 (0.06) \n",
      "\tSeed MSE 2.834 (1.57) Fitted MSE 10.704 (6.59) Fitted-Seed MSE 3102.636 (1576.39) \n",
      "professions - wealth\n",
      "\tSeed OC_p 0.661 (0.06) Fitted OC_p 0.677 (0.02) Fitted-Seed OC_p 0.698 (0.03) \n",
      "\tSeed MSE 2.349 (0.69) Fitted MSE 10.363 (6.39) Fitted-Seed MSE 246717.463 (117031.89) \n",
      "myth - valence\n",
      "\tSeed OC_p 0.735 (0.02) Fitted OC_p 0.533 (0.10) Fitted-Seed OC_p 0.582 (0.06) \n",
      "\tSeed MSE 1.527 (0.81) Fitted MSE 14.982 (6.70) Fitted-Seed MSE 172.385 (74.64) \n",
      "clothing - cost\n",
      "\tSeed OC_p 0.524 (0.04) Fitted OC_p 0.590 (0.14) Fitted-Seed OC_p 0.488 (0.06) \n",
      "\tSeed MSE 130.021 (48.37) Fitted MSE 10.127 (5.69) Fitted-Seed MSE 857.387 (155.42) \n",
      "professions - age\n",
      "\tSeed OC_p 0.563 (0.05) Fitted OC_p 0.628 (0.12) Fitted-Seed OC_p 0.370 (0.03) \n",
      "\tSeed MSE 14.942 (5.99) Fitted MSE 13.193 (5.93) Fitted-Seed MSE 2878.880 (1156.08) \n",
      "myth - size\n",
      "\tSeed OC_p 0.748 (0.05) Fitted OC_p 0.554 (0.12) Fitted-Seed OC_p 0.338 (0.05) \n",
      "\tSeed MSE 1.017 (0.22) Fitted MSE 14.834 (3.79) Fitted-Seed MSE 4134.658 (1798.24) \n",
      "sports - danger\n",
      "\tSeed OC_p 0.639 (0.04) Fitted OC_p 0.576 (0.09) Fitted-Seed OC_p 0.523 (0.06) \n",
      "\tSeed MSE 6.881 (3.76) Fitted MSE 9.482 (5.65) Fitted-Seed MSE 11.807 (4.71) \n",
      "names - gender\n",
      "\tSeed OC_p 0.875 (0.01) Fitted OC_p 0.574 (0.13) Fitted-Seed OC_p 0.819 (0.01) \n",
      "\tSeed MSE 0.126 (0.05) Fitted MSE 10.689 (2.44) Fitted-Seed MSE 270.189 (186.23) \n",
      "cities - danger\n",
      "\tSeed OC_p 0.770 (0.05) Fitted OC_p 0.612 (0.11) Fitted-Seed OC_p 0.274 (0.04) \n",
      "\tSeed MSE 0.935 (0.27) Fitted MSE 15.393 (7.36) Fitted-Seed MSE 472.891 (135.24) \n",
      "animals - weight\n",
      "\tSeed OC_p 0.506 (0.07) Fitted OC_p 0.671 (0.09) Fitted-Seed OC_p 0.479 (0.11) \n",
      "\tSeed MSE 200.519 (127.07) Fitted MSE 11.430 (8.25) Fitted-Seed MSE 113719.128 (61705.06) \n",
      "sports - gender\n",
      "\tSeed OC_p 0.820 (0.05) Fitted OC_p 0.608 (0.10) Fitted-Seed OC_p 0.717 (0.04) \n",
      "\tSeed MSE 0.356 (0.21) Fitted MSE 11.976 (5.12) Fitted-Seed MSE 5.364 (1.34) \n",
      "professions - location\n",
      "\tSeed OC_p 0.555 (0.05) Fitted OC_p 0.554 (0.11) Fitted-Seed OC_p 0.484 (0.08) \n",
      "\tSeed MSE 59.838 (25.37) Fitted MSE 13.666 (4.80) Fitted-Seed MSE 130.287 (25.61) \n",
      "sports - speed\n",
      "\tSeed OC_p 0.514 (0.03) Fitted OC_p 0.641 (0.06) Fitted-Seed OC_p 0.510 (0.05) \n",
      "\tSeed MSE 1210.091 (753.04) Fitted MSE 8.322 (3.64) Fitted-Seed MSE 383.147 (125.34) \n",
      "states - temperature\n",
      "\tSeed OC_p 0.724 (0.07) Fitted OC_p 0.587 (0.10) Fitted-Seed OC_p 0.442 (0.06) \n",
      "\tSeed MSE 1.726 (0.76) Fitted MSE 15.831 (7.31) Fitted-Seed MSE 1168.665 (757.10) \n",
      "professions - arousal\n",
      "\tSeed OC_p 0.660 (0.05) Fitted OC_p 0.686 (0.07) Fitted-Seed OC_p 0.338 (0.04) \n",
      "\tSeed MSE 2.399 (1.04) Fitted MSE 12.297 (6.35) Fitted-Seed MSE 1701.602 (1098.88) \n",
      "cities - size\n",
      "\tSeed OC_p 0.564 (0.05) Fitted OC_p 0.586 (0.08) Fitted-Seed OC_p 0.443 (0.05) \n",
      "\tSeed MSE 32.255 (22.42) Fitted MSE 11.060 (3.50) Fitted-Seed MSE 3559.254 (1869.35) \n",
      "states - wealth\n",
      "\tSeed OC_p 0.632 (0.08) Fitted OC_p 0.597 (0.06) Fitted-Seed OC_p 0.639 (0.09) \n",
      "\tSeed MSE 3.852 (1.94) Fitted MSE 9.687 (2.99) Fitted-Seed MSE 311078.310 (121379.35) \n",
      "sports - arousal\n",
      "\tSeed OC_p 0.599 (0.07) Fitted OC_p 0.610 (0.15) Fitted-Seed OC_p 0.490 (0.03) \n",
      "\tSeed MSE 11.644 (3.83) Fitted MSE 9.983 (6.45) Fitted-Seed MSE 78.186 (22.72) \n",
      "animals - wetness\n",
      "\tSeed OC_p 0.766 (0.05) Fitted OC_p 0.666 (0.19) Fitted-Seed OC_p 0.691 (0.07) \n",
      "\tSeed MSE 0.552 (0.23) Fitted MSE 10.268 (7.16) Fitted-Seed MSE 1077.187 (450.37) \n",
      "clothing - gender\n",
      "\tSeed OC_p 0.809 (0.01) Fitted OC_p 0.629 (0.07) Fitted-Seed OC_p 0.702 (0.02) \n",
      "\tSeed MSE 0.520 (0.26) Fitted MSE 9.193 (3.88) Fitted-Seed MSE 1024.841 (216.11) \n",
      "weather - temperature\n",
      "\tSeed OC_p 0.658 (0.05) Fitted OC_p 0.578 (0.13) Fitted-Seed OC_p 0.322 (0.07) \n",
      "\tSeed MSE 3.427 (0.55) Fitted MSE 13.145 (4.17) Fitted-Seed MSE 1621.253 (689.39) \n",
      "cities - religiosity\n",
      "\tSeed OC_p 0.618 (0.13) Fitted OC_p 0.553 (0.07) Fitted-Seed OC_p 0.515 (0.09) \n",
      "\tSeed MSE 4.173 (1.98) Fitted MSE 17.707 (17.26) Fitted-Seed MSE 106.597 (48.46) \n",
      "animals - intelligence\n",
      "\tSeed OC_p 0.540 (0.10) Fitted OC_p 0.539 (0.24) Fitted-Seed OC_p 0.475 (0.11) \n",
      "\tSeed MSE 149.678 (46.38) Fitted MSE 17.481 (10.97) Fitted-Seed MSE 1286342.440 (680247.52) \n",
      "states - political\n",
      "\tSeed OC_p 0.647 (0.03) Fitted OC_p 0.602 (0.10) Fitted-Seed OC_p 0.655 (0.01) \n",
      "\tSeed MSE 5.402 (1.73) Fitted MSE 12.698 (6.29) Fitted-Seed MSE 47.901 (9.66) \n",
      "names - intelligence\n",
      "\tSeed OC_p 0.738 (0.04) Fitted OC_p 0.610 (0.03) Fitted-Seed OC_p 0.471 (0.04) \n",
      "\tSeed MSE 1.414 (0.71) Fitted MSE 11.470 (2.38) Fitted-Seed MSE 493714.699 (183156.24) \n",
      "myth - gender\n",
      "\tSeed OC_p 0.743 (0.02) Fitted OC_p 0.554 (0.10) Fitted-Seed OC_p 0.670 (0.05) \n",
      "\tSeed MSE 0.487 (0.08) Fitted MSE 19.507 (8.56) Fitted-Seed MSE 124.920 (65.69) \n",
      "animals - speed\n",
      "\tSeed OC_p 0.624 (0.05) Fitted OC_p 0.562 (0.09) Fitted-Seed OC_p 0.523 (0.05) \n",
      "\tSeed MSE 6.556 (2.13) Fitted MSE 16.421 (12.72) Fitted-Seed MSE 9250.877 (1898.77) \n",
      "animals - gender\n",
      "\tSeed OC_p 0.733 (0.03) Fitted OC_p 0.663 (0.13) Fitted-Seed OC_p 0.620 (0.09) \n",
      "\tSeed MSE 1.077 (0.84) Fitted MSE 14.034 (10.08) Fitted-Seed MSE 119.056 (89.31) \n",
      "states - cost\n",
      "\tSeed OC_p 0.462 (0.06) Fitted OC_p 0.702 (0.05) Fitted-Seed OC_p 0.384 (0.07) \n",
      "\tSeed MSE 29079.620 (18267.43) Fitted MSE 5.786 (2.42) Fitted-Seed MSE 1039.724 (133.60) \n",
      "myth - danger\n",
      "\tSeed OC_p 0.781 (0.04) Fitted OC_p 0.571 (0.14) Fitted-Seed OC_p 0.267 (0.03) \n",
      "\tSeed MSE 0.810 (0.37) Fitted MSE 16.774 (6.01) Fitted-Seed MSE 227.001 (94.04) \n",
      "animals - danger\n",
      "\tSeed OC_p 0.713 (0.08) Fitted OC_p 0.601 (0.07) Fitted-Seed OC_p 0.327 (0.10) \n",
      "\tSeed MSE 1.778 (0.97) Fitted MSE 12.542 (8.45) Fitted-Seed MSE 190.664 (74.18) \n",
      "animals - loudness\n",
      "\tSeed OC_p 0.527 (0.08) Fitted OC_p 0.582 (0.12) Fitted-Seed OC_p 0.494 (0.04) \n",
      "\tSeed MSE 156.814 (81.47) Fitted MSE 19.266 (10.44) Fitted-Seed MSE 33612.219 (5963.07) \n",
      "states - intelligence\n",
      "\tSeed OC_p 0.588 (0.04) Fitted OC_p 0.573 (0.10) Fitted-Seed OC_p 0.462 (0.05) \n",
      "\tSeed MSE 78.882 (43.53) Fitted MSE 19.273 (7.66) Fitted-Seed MSE 516229.106 (275108.24) \n",
      "sports - location\n",
      "\tSeed OC_p 0.771 (0.01) Fitted OC_p 0.627 (0.12) Fitted-Seed OC_p 0.582 (0.05) \n",
      "\tSeed MSE 1.418 (0.75) Fitted MSE 10.173 (5.82) Fitted-Seed MSE 6.286 (2.27) \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Training and test split, two-loss formulation for fitted dimensions\")\n",
    "\n",
    "numfolds = 5\n",
    "alpha = 0.1\n",
    "\n",
    "all_evals = [ ]\n",
    "\n",
    "for filename in os.listdir(grandratings_dir):\n",
    "    if filename.endswith(\"csv\"):\n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "        \n",
    "        \n",
    "        # storage for word vectors and gold values for this dataset\n",
    "        all_thisdata_vectors = []\n",
    "        all_thisdata_gold = []\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            all_thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            all_thisdata_gold.append( row.Gold)\n",
    "      \n",
    "        # crossvalidation setup: give indices to datapoints\n",
    "        fold = np.random.randint(numfolds, size = len(all_thisdata_gold))\n",
    "        \n",
    "        # store the evaluatresults from the different test folds\n",
    "        evals = [ ]\n",
    "        \n",
    "        # iterate over folds, evaluate for each of them\n",
    "        for testfold in range(numfolds):\n",
    "            # compute training and test data for this fold\n",
    "            test_indices =  [i for i in range(len(all_thisdata_gold)) if fold[i] == testfold]\n",
    "            train_indices = [i for i in range(len(all_thisdata_gold)) if fold[i] != testfold]\n",
    "        \n",
    "            gold_test =  [ell[\"Gold\"] for _, ell in df.iloc[ test_indices ].iterrows()]\n",
    "            gold_train = [ ell[\"Gold\"] for _, ell in df.iloc[ train_indices ].iterrows()]\n",
    "            words_test =  [ell[\"Row\"] for _, ell in df.iloc[ test_indices].iterrows()]\n",
    "            words_train = [ell[\"Row\"] for _, ell in df.iloc[ train_indices].iterrows()]\n",
    "            vec_test =  [word_vectors[ w ] for w in words_test]\n",
    "            vec_train = [word_vectors[ w ] for w in words_train ]\n",
    "        \n",
    "\n",
    "            # compute seed-based dimension, and its predictions\n",
    "            seed_dim = average_dim_vector(pos_seedwords, neg_seedwords, word_vectors)\n",
    "            p0 = [vector_scalar_projection( word_vectors[w], seed_dim) for w in df[\"Row\"]]\n",
    "            weight, bias = coef_for_seed_dimension(df[\"Gold\"], p0)\n",
    "            df[\"SPred\"] = [sprediction(p, weight, bias) for p in p0]\n",
    "            \n",
    "            \n",
    "            # compute fitted dimension, and its predictions\n",
    "            fitted_dim, fitted_wt, fitted_bias = ideal_dimension(vec_train, gold_train, feature_dim)\n",
    "            df[\"FPred\"] = [ iprediction( word_vectors[ w], fitted_dim, fitted_wt, fitted_bias) for w in df[\"Row\"]]\n",
    "            \n",
    "            \n",
    "            # compute fitted dimension with seeds, and its predictions\n",
    "            diffvectors = [ ]\n",
    "    \n",
    "            for negword in neg_seedwords:\n",
    "                for posword in pos_seedwords:\n",
    "                    diffvectors.append(word_vectors[posword] - word_vectors[negword])\n",
    "                    \n",
    "            dimvec = torch.from_numpy(np.mean(diffvectors, axis = 0))\n",
    "            \n",
    "            fitted_dim, fitted_wt, fitted_bias = fitted_dimension_withseeds(thisdata_vectors, thisdata_gold, [dimvec], \n",
    "                                                                            feature_dim, alpha = alpha)\n",
    "        \n",
    "            \n",
    "            df[\"FSPred\"] = [ iprediction( word_vectors[ w], fitted_dim, fitted_wt, fitted_bias) for w in df[\"Row\"]]\n",
    "            \n",
    "            # order consistency pairwise: test values tested for their ordering wrt. all values, training and test\n",
    "            # MSE: evaluate on test only\n",
    "            e = { \"ocp_s\" : pairwise_order_consistency_wrt(df[\"Gold\"], df[\"SPred\"], test_indices),\n",
    "                  \"ocp_f\" : pairwise_order_consistency_wrt(df[\"Gold\"], df[\"FPred\"], test_indices),\n",
    "                  \"ocp_fs\": pairwise_order_consistency_wrt(df[\"Gold\"], df[\"FSPred\"], test_indices),\n",
    "                  \"mse_s\" : mean_squared_error(gold_test, [p for i, p in enumerate(df[\"SPred\"]) if i in test_indices]),\n",
    "                  \"mse_f\" : mean_squared_error(gold_test, [p for i, p in enumerate(df[\"FPred\"]) if i in test_indices]),\n",
    "                  \"mse_fs\": mean_squared_error(gold_test, [p for i, p in enumerate(df[\"FSPred\"]) if i in test_indices])}\n",
    "            \n",
    "            evals.append(e)\n",
    "            all_evals.append(e)\n",
    "        \n",
    "        print(grandcategory, \"-\", grandfeature)\n",
    "        print(\"\\t\", end = \"\")\n",
    "        for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\")]:\n",
    "            ocps = [e[\"ocp_\" + suffix] for e in evals]\n",
    "            print(name, f\"OC_p {statistics.mean(ocps):.3f} ({statistics.stdev(ocps):.2f})\", end = \" \")\n",
    "        print(\"\\n\\t\", end = \"\")\n",
    "        for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\")]:\n",
    "            mses = [e[\"mse_\" + suffix] for e in evals]\n",
    "            print(name, f\"MSE {statistics.mean(mses):.3f} ({statistics.stdev(mses):.2f})\", end = \" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a53772f9-dfc5-488b-9f34-f247e177bfc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed OC_p mean 0.647 (0.11)\n",
      "Fitted OC_p mean 0.597 (0.10)\n",
      "Fitted-Seed OC_p mean 0.501 (0.14)\n",
      "\n",
      "Seed MSE med 1.327 mean 1.418 (0.75)\n",
      "Fitted MSE med 12.054 mean 10.173 (5.82)\n",
      "Fitted-Seed MSE med 6.178 mean 6.286 (2.27)\n"
     ]
    }
   ],
   "source": [
    "for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\")]:\n",
    "    ocps = [e[\"ocp_\" + suffix] for e in all_evals]\n",
    "    print(name, f\"OC_p mean {statistics.mean(ocps):.3f} ({statistics.stdev(ocps):.2f})\")\n",
    "print()\n",
    "\n",
    "for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\")]:\n",
    "    mses = [e[\"mse_\" + suffix] for e in evals]\n",
    "    print(name, f\"MSE med {statistics.median(mses):.3f} mean {statistics.mean(mses):.3f} ({statistics.stdev(mses):.2f})\") \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4f302-74bc-45b3-acf5-942092c49b70",
   "metadata": {},
   "source": [
    "# Where are we now\n",
    "\n",
    "So far I have not found a formulation based on fitted dimensions that outperforms seed-based dimensions on unseen data for the Grand datasets. I still think our current best hypothesis is that words of the same category have too many properties in common, so that the direction of the fitted dimension is underdetermined, and the model can overfit to the given ratings. And I still think that using seeds whiler computing fitted dimensions is our best option to \"tell\" the model which property we mean. \n",
    "\n",
    "Things I've tried so far:\n",
    "\n",
    "* Throwing the seeds in with the category words, but with extreme ratings. I've used numbers that are 0.5 to 1 units out from the most extreme ratings, in terms of z-scores. \n",
    "\n",
    "* Making a two-part loss function, where one part is about having a high cosine similarity to given seed-based dimensions, and the other part is about matching human ratings on category words. But I'm not sure I've been doing it right, I don't have much epxerience with pytorch. Setting the mixing parameter alpha to zero should give all weight to the seed dimensions, and should get me numbers that are basically the same as with a seed-based dimension -- but it doesn't, it's lower. So what was I doing wrong?\n",
    "\n",
    "* If we add high match with given seed-based dimensions to the loss functions, could we in principle also learn weights for the different seed-based dimensions, so that it would learn to give high weight to the ones that match with the human ratings, and low weight to the ones that are pointing in the wrong direction?\n",
    "\n",
    "I'm making a new notebook with just the definitions needed to further explore the train/test problem. I'll also make a development set so that we don't always test on all the Grand data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d39b0f-03ab-4a73-90b0-64d0f0862e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
