{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015a79ab-a28a-4a74-96d3-ad41699f2169",
   "metadata": {},
   "source": [
    "# Evaluating on the Grand et al data\n",
    "\n",
    "All models, evaluated on all data except for the development set used in grand_hyper.\n",
    "\n",
    "# Reading in the data.\n",
    "\n",
    "## GLoVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35f7a6d-3eed-45de-bbb7-d4c9790e6b07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import math\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363ee37f-f5e9-4c9a-a2ad-fd28f48e6628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glove_path = \"glove/glove.42B.300d.zip\"\n",
    "glove_file = \"glove.42B.300d.txt\"\n",
    "\n",
    "feature_dim = 300\n",
    "\n",
    "word_vectors = { }\n",
    "\n",
    "with zipfile.ZipFile(glove_path) as azip:\n",
    "    with azip.open(glove_file) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0].decode()\n",
    "            vector = np.array(values[1:], dtype=np.float32)\n",
    "            word_vectors[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea41ce4-5425-4be4-8bac-67e4f6aa78f1",
   "metadata": {},
   "source": [
    "## Grand features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b92738d-e5bf-49e2-b87a-20abef82f71d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kee252/Library/Python/3.9/lib/python/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "grandratings_dir = \"Grand_etal_csv/\"\n",
    "grandfeatures_path = \"/Users/kee252/Data/grand_directions_in_space/features.xlsx\"\n",
    "\n",
    "grandfeatures_df = pd.read_excel(grandfeatures_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73215317-a38a-40ad-82c9-5b0416177931",
   "metadata": {},
   "source": [
    "## Function for reading a specific Grand dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c0badd-c2d8-4d7d-a0c2-92ae021fbeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading in Grand data\n",
    "def read_grand_data(filename, grandratings_dir, grandfeatures_df):\n",
    "    # extract category and feature\n",
    "    grandcategory, grandfeature = filename[:-4].split(\"_\")\n",
    "        \n",
    "    # read human ratings, make gold column\n",
    "    df = pd.read_csv(grandratings_dir + filename)\n",
    "    nspeakers = len(df.columns) -1\n",
    "    df[\"Average\"] = [row.iloc[1:26].sum() / nspeakers for _, row in df.iterrows()]\n",
    "    # z-scores of average ratings\n",
    "    df[\"Gold\"] = (df[\"Average\"] - df[\"Average\"].mean()) / df[\"Average\"].std()\n",
    "        \n",
    "    # obtain seed words from excel file\n",
    "    relevant_row = grandfeatures_df[grandfeatures_df.Dimension == grandfeature]\n",
    "    seedwords = relevant_row.iloc[:, 1:].values.flatten().tolist()\n",
    "    pos_seedwords = seedwords[:3]\n",
    "    neg_seedwords = seedwords[3:]\n",
    "    \n",
    "    return (grandcategory, grandfeature, pos_seedwords, neg_seedwords, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d5a18-e4a9-4c0d-816c-968856027a70",
   "metadata": {},
   "source": [
    "# Function for running crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca1d397-1001-4784-8e47-7ae86d180bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_dim\n",
    "import compute_dim\n",
    "import statistics\n",
    "\n",
    "def crossvalidation(filenames, method, word_vectors, grandratings_dir, grandfeatures_df, random_seed = 123, verbose = False):\n",
    "    \n",
    "    all_evals = [ ]\n",
    "    \n",
    "    for filename in filenames:\n",
    "            grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, \n",
    "                                                                                            grandratings_dir, \n",
    "                                                                                            grandfeatures_df)\n",
    "\n",
    "\n",
    "            # storage for word vectors and gold values for this dataset\n",
    "            all_thisdata_vectors = []\n",
    "            all_thisdata_gold = []\n",
    "\n",
    "            # collect word vectors and gold ratings\n",
    "            for row in df.itertuples():\n",
    "                # row.Row is the word. look it up in word_vectors\n",
    "                all_thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "                # gold rating: use z-scored average\n",
    "                all_thisdata_gold.append( row.Gold)\n",
    "\n",
    "            # crossvalidation setup: give indices to datapoints\n",
    "            fold = np.random.randint(method[\"numfolds\"], size = len(all_thisdata_gold))\n",
    "\n",
    "            # store the evaluation results from the different test folds\n",
    "            evals = [ ]\n",
    "\n",
    "            # iterate over folds, evaluate for each of them\n",
    "            for testfold in range(method[\"numfolds\"]):\n",
    "                # compute training and test data for this fold\n",
    "                test_indices =  [i for i in range(len(all_thisdata_gold)) if fold[i] == testfold]\n",
    "                train_indices = [i for i in range(len(all_thisdata_gold)) if fold[i] != testfold]\n",
    "\n",
    "                gold_test =  [ell[\"Gold\"] for _, ell in df.iloc[ test_indices ].iterrows()]\n",
    "                gold_train = [ ell[\"Gold\"] for _, ell in df.iloc[ train_indices ].iterrows()]\n",
    "                words_test =  [ell[\"Row\"] for _, ell in df.iloc[ test_indices].iterrows()]\n",
    "                words_train = [ell[\"Row\"] for _, ell in df.iloc[ train_indices].iterrows()]\n",
    "                vec_test =  [word_vectors[ w ] for w in words_test]\n",
    "                vec_train = [word_vectors[ w ] for w in words_train ]\n",
    "\n",
    "\n",
    "                # compute seed-based dimension, and its predictions\n",
    "                if method[\"method\"] == \"seedbased\":\n",
    "                    dimension = compute_dim.dimension_seedbased(pos_seedwords, neg_seedwords, word_vectors)\n",
    "                    df[\"Pred\"] = compute_dim.predict_coord_fromtrain(vec_train, gold_train, dimension, all_thisdata_vectors)\n",
    "\n",
    "                elif method[\"method\"] == \"fitted\":\n",
    "                    dimension, weight, bias = compute_dim.dimension_fitted_fromratings(vec_train, gold_train, \n",
    "                                                                                       method[\"feature_dim\"],\n",
    "                                                                                       random_seed = random_seed)\n",
    "                    df[\"Pred\"] = compute_dim.predict_coord_fromline(all_thisdata_vectors, dimension, weight, bias)\n",
    "\n",
    "                elif method[\"method\"] == \"fitted_seedwords\":\n",
    "                    dimension, weight, bias = compute_dim.dimension_fitted_fromratings_seedwords(vec_train, gold_train, \n",
    "                                                                    method[\"feature_dim\"], \n",
    "                                                                    pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                                    offset = method[\"offset\"], jitter = method[\"jitter\"],\n",
    "                                                                    random_seed = random_seed)\n",
    "                    df[\"Pred\"] = compute_dim.predict_coord_fromline(all_thisdata_vectors, dimension, weight, bias)\n",
    "\n",
    "                elif method[\"method\"] == \"fitted_seeddims\":\n",
    "                    dimension, weight, bias = compute_dim.dimension_fitted_fromratings_seeddims(vec_train, gold_train, \n",
    "                                                                    method[\"feature_dim\"], \n",
    "                                                                    pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                                    do_average = method[\"do_average\"], \n",
    "                                                                    alpha = method[\"alpha\"],\n",
    "                                                                    random_seed = random_seed)\n",
    "                    df[\"Pred\"] = compute_dim.predict_coord_fromline(all_thisdata_vectors, dimension, weight, bias)\n",
    "\n",
    "                elif method[\"method\"] == \"combined\":\n",
    "                    dimension, weight, bias = compute_dim.dimension_fitted_fromratings_combined(vec_train, gold_train,\n",
    "                                                                    method[\"feature_dim\"],\n",
    "                                                                    pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                                    offset = method[\"offset\"], jitter = method[\"jitter\"],\n",
    "                                                                    do_average = method[\"do_average\"], \n",
    "                                                                    alpha = method[\"alpha\"],\n",
    "                                                                    random_seed = random_seed)\n",
    "                    df[\"Pred\"] = compute_dim.predict_coord_fromline(all_thisdata_vectors, dimension, weight, bias)\n",
    "\n",
    "                else:\n",
    "                    raise Exception(\"shouldn't be here\")\n",
    "\n",
    "                # order consistency pairwise: test values tested for their ordering wrt. all values, training and test\n",
    "                # MSE: evaluate on test only\n",
    "                e = { \"ocp\" : eval_dim.pairwise_order_consistency_wrt(df[\"Gold\"], df[\"Pred\"], test_indices),\n",
    "                      \"mse\" : eval_dim.mean_squared_error(gold_test, [p for i, p in enumerate(df[\"Pred\"]) if i in test_indices]),\n",
    "                      \"feature\" : grandfeature,\n",
    "                      \"category\" : grandcategory}\n",
    "\n",
    "                all_evals.append(e)\n",
    "\n",
    "    if verbose:\n",
    "        ocps = [e[\"ocp\"] for e in all_evals if e[\"ocp\"] is not None]\n",
    "        mses = [e[\"mse\"] for e in all_evals if e[\"mse\"] is not None]\n",
    "\n",
    "        print(\"\\n\\nOverall\", method[\"method\"], \n",
    "              f\"OC_p {statistics.mean(ocps):.3f} ({statistics.stdev(ocps):.2f})\", \n",
    "              f\"MSE mean {statistics.mean(mses):.3f} ({statistics.stdev(mses):.2f}) median {statistics.median(mses):.3f}\")\n",
    "        \n",
    "    return all_evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f081d8-a75b-466f-8d77-a1b277b06fcf",
   "metadata": {},
   "source": [
    "# Functions for aggregating results\n",
    "\n",
    "Same as for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a089795d-2ef3-453a-b5a6-c5b816f59f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "# given a list of results dictionaries, \n",
    "# group them by the given dictionary keys\n",
    "def eval_aggregate_by(evals, keylabels):\n",
    "    bydataset_eval = defaultdict(list)\n",
    "    \n",
    "    for e in evals:\n",
    "        key = tuple([str(e[k]) for k in keylabels])\n",
    "        bydataset_eval[ key ].append(e)\n",
    "        \n",
    "    return bydataset_eval\n",
    "\n",
    "\n",
    "# given a list of results dictionaries,\n",
    "# compute mean, median and standard deviation over values for a particular key\n",
    "def eval_summary_by(evals, keylabel):\n",
    "    vals = [e[keylabel] for e in evals if e[keylabel] is not None]\n",
    "    \n",
    "    return (statistics.mean(vals), statistics.median(vals), statistics.stdev(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006fa38-f176-460d-a634-7600a4867d8d",
   "metadata": {},
   "source": [
    "# The data that is not in the development set\n",
    "\n",
    "We set aside 6 category/feature pairs for development. We use the rest for testing through crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d94451d-a3c9-45f7-b507-ec9b1b443d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cities', 'temperature'],\n",
       " ['professions', 'intelligence'],\n",
       " ['clothing', 'location'],\n",
       " ['cities', 'arousal'],\n",
       " ['clothing', 'arousal'],\n",
       " ['states', 'size'],\n",
       " ['sports', 'intelligence'],\n",
       " ['clothing', 'wealth'],\n",
       " ['weather', 'danger'],\n",
       " ['professions', 'danger'],\n",
       " ['clothing', 'size'],\n",
       " ['animals', 'size'],\n",
       " ['sports', 'wealth'],\n",
       " ['professions', 'valence'],\n",
       " ['names', 'wealth'],\n",
       " ['cities', 'cost'],\n",
       " ['cities', 'wealth'],\n",
       " ['professions', 'gender'],\n",
       " ['states', 'religiosity'],\n",
       " ['clothing', 'age'],\n",
       " ['weather', 'wetness'],\n",
       " ['professions', 'wealth'],\n",
       " ['myth', 'valence'],\n",
       " ['clothing', 'cost'],\n",
       " ['professions', 'age'],\n",
       " ['myth', 'size'],\n",
       " ['sports', 'danger'],\n",
       " ['names', 'gender'],\n",
       " ['sports', 'gender'],\n",
       " ['professions', 'location'],\n",
       " ['sports', 'speed'],\n",
       " ['states', 'temperature'],\n",
       " ['professions', 'arousal'],\n",
       " ['cities', 'size'],\n",
       " ['states', 'wealth'],\n",
       " ['sports', 'arousal'],\n",
       " ['clothing', 'gender'],\n",
       " ['weather', 'temperature'],\n",
       " ['cities', 'religiosity'],\n",
       " ['animals', 'intelligence'],\n",
       " ['names', 'intelligence'],\n",
       " ['myth', 'gender'],\n",
       " ['animals', 'speed'],\n",
       " ['animals', 'gender'],\n",
       " ['states', 'cost'],\n",
       " ['myth', 'danger'],\n",
       " ['animals', 'danger'],\n",
       " ['animals', 'loudness'],\n",
       " ['states', 'intelligence'],\n",
       " ['sports', 'location']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [f for f in os.listdir(grandratings_dir) if f.endswith(\"csv\")]\n",
    "\n",
    "import random\n",
    "random.seed(789)\n",
    "devset = random.sample(filenames, 6)\n",
    "traintestset = [f for f in filenames if f not in devset]\n",
    "[ filename[:-4].split(\"_\") for filename in traintestset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f9fa2-87c0-4f5f-a6f4-7d5e03a18bc5",
   "metadata": {},
   "source": [
    "# Running the actual evaluation\n",
    "\n",
    "## Seed-based dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095318ba-fcf6-479f-8407-11b45d2efcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numfolds = 5\n",
    "num_randseeds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f50fae-6667-4571-8157-44d9751a7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = { \"method\": \"seedbased\",\n",
    "          \"numfolds\" : numfolds}\n",
    "\n",
    "results = crossvalidation(traintestset, method, word_vectors, grandratings_dir, grandfeatures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17cbff0b-8a9a-49c8-b221-f2159e63d391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed-based method: OC_P mean 0.635 (0.12)MSE median 226.407\n"
     ]
    }
   ],
   "source": [
    "ocp_mean, _, ocp_sd = eval_summary_by(results, \"ocp\")\n",
    "mse_mean, mse_med, mse_sd = eval_summary_by(results, \"mse\")\n",
    "\n",
    "print(\"Seed-based method:\",\n",
    "      f\"OC_P mean {ocp_mean:.3f} ({ocp_sd:.2f})\",\n",
    "      f\"MSE median {mse_med:.3f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2ba5d-b19d-4103-bc20-f7af7d1988cf",
   "metadata": {},
   "source": [
    "## Fitted dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3da9ad-95b3-464b-9b24-027ed30926a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5421174858513682 91.0626807798399\n",
      "0.5219122305305846 234.07023055288454\n",
      "0.5694117891829683 38.33066970437781\n"
     ]
    }
   ],
   "source": [
    "method = {\"method\": \"fitted\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "\n",
    "results = [ ]\n",
    "\n",
    "for rval in randoms:\n",
    "    theseresults = crossvalidation(traintestset, method, word_vectors, grandratings_dir, grandfeatures_df, random_seed = rval)\n",
    "    \n",
    "    ocp_mean, _, _ = eval_summary_by(theseresults, \"ocp\")\n",
    "    _, mse_med, _ = eval_summary_by(theseresults, \"mse\")\n",
    "    \n",
    "    print(ocp_mean, mse_med)\n",
    "\n",
    "    results += theseresults\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f9bd52-d60c-424a-a9e6-099740e480e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted method: OC_P mean 0.544 (0.03)MSE median 114.021 (100.04)\n"
     ]
    }
   ],
   "source": [
    "results_bycond = eval_aggregate_by(results,[\"category\", \"feature\"])\n",
    "\n",
    "ocps = [eval_summary_by(cond_results, \"ocp\")[0] for cond_results in results_bycond.values()]\n",
    "mses = [eval_summary_by(cond_results, \"mse\")[1] for cond_results in results_bycond.values()]\n",
    "    \n",
    "ocp_mean = statistics.mean(ocps)\n",
    "ocp_sd = statistics.stdev(ocps)\n",
    "msemed_mean= statistics.mean(mses)\n",
    "msemed_sd = statistics.stdev(mses)\n",
    "\n",
    "print(\"Fitted method:\",\n",
    "      f\"OC_P mean {ocp_mean:.3f} ({ocp_sd:.2f})\",\n",
    "      f\"MSE median {msemed_mean:.3f} ({msemed_sd:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee5550-895f-46f3-8246-12884df35008",
   "metadata": {},
   "source": [
    "# Fitted dimensions with seed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc644bc-4589-4718-bb64-64390f6dbb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5311938588842575 291.70447837975917\n",
      "0.5291527131751409 185.7156647626582\n",
      "0.545760398712621 111.50139446948805\n"
     ]
    }
   ],
   "source": [
    "method = { \"method\": \"fitted_seedwords\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"offset\" : 2.0,\n",
    "          \"jitter\" : True,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "results = [ ]\n",
    "\n",
    "for rval in randoms:\n",
    "    theseresults = crossvalidation(traintestset, method, word_vectors, grandratings_dir, grandfeatures_df, random_seed = rval)\n",
    "    \n",
    "    ocp_mean, _, _ = eval_summary_by(theseresults, \"ocp\")\n",
    "    _, mse_med, _ = eval_summary_by(theseresults, \"mse\")\n",
    "    \n",
    "    print(ocp_mean, mse_med)\n",
    "\n",
    "    results += theseresults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4743ab0-6757-4b3e-8dcf-554ba1308482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted, with seed words, offset 2.0 jitter True OC_P mean 0.535 (0.03) MSE median 229.438 (261.97)\n"
     ]
    }
   ],
   "source": [
    "results_bycond = eval_aggregate_by(results,[\"category\", \"feature\"])\n",
    "\n",
    "ocps = [eval_summary_by(cond_results, \"ocp\")[0] for cond_results in results_bycond.values()]\n",
    "mses = [eval_summary_by(cond_results, \"mse\")[1] for cond_results in results_bycond.values()]\n",
    "    \n",
    "ocp_mean = statistics.mean(ocps)\n",
    "ocp_sd = statistics.stdev(ocps)\n",
    "msemed_mean= statistics.mean(mses)\n",
    "msemed_sd = statistics.stdev(mses)\n",
    "\n",
    "print(\"Fitted, with seed words,\", \n",
    "      \"offset\", method[\"offset\"], \"jitter\", method[\"jitter\"],\n",
    "      f\"OC_P mean {ocp_mean:.3f} ({ocp_sd:.2f})\",\n",
    "      f\"MSE median {msemed_mean:.3f} ({msemed_sd:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65fe8f0-c6bc-4047-b46a-8f65673e39d3",
   "metadata": {},
   "source": [
    "# Fitted dimensions with seed dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8187ba15-1d44-402e-82d4-43a675326171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6529228362960654 5.701850589982518\n",
      "0.6541907368516412 6.940450263703243\n",
      "0.6362253492701136 10.110086721618455\n"
     ]
    }
   ],
   "source": [
    "method = { \"method\": \"fitted_seeddims\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"alpha\" : 0.02,\n",
    "          \"do_average\" : True,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(num_randseeds)]\n",
    "results = [ ]\n",
    "\n",
    "for rval in randoms:\n",
    "    theseresults = crossvalidation(traintestset, method, word_vectors, grandratings_dir, grandfeatures_df, random_seed = rval)\n",
    "\n",
    "    ocp_mean, _, _ = eval_summary_by(theseresults, \"ocp\")\n",
    "    _, mse_med, _ = eval_summary_by(theseresults, \"mse\")\n",
    "    \n",
    "    print(ocp_mean, mse_med)\n",
    "\n",
    "    results += theseresults\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16140e7c-9517-46c9-b35d-a1f6ec78b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted, with seed dim.s, alpha 0.02 avg True OC_P mean 0.648 (0.11) MSE median 64.431 (138.39)\n"
     ]
    }
   ],
   "source": [
    "results_bycond = eval_aggregate_by(results,[\"category\", \"feature\"])\n",
    "\n",
    "ocps = [eval_summary_by(cond_results, \"ocp\")[0] for cond_results in results_bycond.values()]\n",
    "mses = [eval_summary_by(cond_results, \"mse\")[1] for cond_results in results_bycond.values()]\n",
    "    \n",
    "ocp_mean = statistics.mean(ocps)\n",
    "ocp_sd = statistics.stdev(ocps)\n",
    "msemed_mean= statistics.mean(mses)\n",
    "msemed_sd = statistics.stdev(mses)\n",
    "\n",
    "print(\"Fitted, with seed dim.s,\", \n",
    "      \"alpha\", method[\"alpha\"], \"avg\", method[\"do_average\"],\n",
    "      f\"OC_P mean {ocp_mean:.3f} ({ocp_sd:.2f})\",\n",
    "      f\"MSE median {msemed_mean:.3f} ({msemed_sd:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d6643-386b-4602-8578-1fd9e250c17f",
   "metadata": {},
   "source": [
    "# Fitted dimensions with seeds as words and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "351efed8-4d5b-470e-9ddc-1ca2a49275d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7928723629760392 0.6837275364436712\n",
      "0.7927436748503687 0.6409548804488194\n",
      "0.7854006256738303 0.7083679941557908\n"
     ]
    }
   ],
   "source": [
    "method = {\"method\": \"combined\",\n",
    "          \"numfolds\" : numfolds,\n",
    "          \"alpha\" : 0.05,\n",
    "          \"do_average\" : True,\n",
    "          \"offset\" : 2,\n",
    "          \"jitter\" : True,\n",
    "          \"feature_dim\" : feature_dim}\n",
    "\n",
    "\n",
    "random.seed(5)\n",
    "randoms = [random.randrange(0,100) for _ in range(3)]\n",
    "results = [ ]\n",
    "\n",
    "for rval in randoms:\n",
    "    theseresults = crossvalidation(traintestset, method, word_vectors, grandratings_dir, grandfeatures_df, random_seed = rval)\n",
    "    \n",
    "    ocp_mean, _, _ = eval_summary_by(theseresults, \"ocp\")\n",
    "    _, mse_med, _ = eval_summary_by(theseresults, \"mse\")\n",
    "    \n",
    "    print(ocp_mean, mse_med)\n",
    "\n",
    "    results += theseresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27b4e0a9-8914-4f13-9b32-0cd2a2ec0afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted, with seed dim.s, alpha 0.05 avg True offset 2 jitter True OC_P mean 0.790 (0.05) MSE median 0.754 (0.32)\n"
     ]
    }
   ],
   "source": [
    "results_bycond = eval_aggregate_by(results,[\"category\", \"feature\"])\n",
    "\n",
    "ocps = [eval_summary_by(cond_results, \"ocp\")[0] for cond_results in results_bycond.values()]\n",
    "mses = [eval_summary_by(cond_results, \"mse\")[1] for cond_results in results_bycond.values()]\n",
    "    \n",
    "ocp_mean = statistics.mean(ocps)\n",
    "ocp_sd = statistics.stdev(ocps)\n",
    "msemed_mean= statistics.mean(mses)\n",
    "msemed_sd = statistics.stdev(mses)\n",
    "\n",
    "print(\"Fitted, with seed dim.s,\", \n",
    "      \"alpha\", method[\"alpha\"], \"avg\", method[\"do_average\"],\n",
    "      \"offset\", method[\"offset\"], \"jitter\", method[\"jitter\"],\n",
    "      f\"OC_P mean {ocp_mean:.3f} ({ocp_sd:.2f})\",\n",
    "      f\"MSE median {msemed_mean:.3f} ({msemed_sd:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb8f14-be66-4b1e-9970-29c823e696c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
