{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58271ad2-41e9-4630-ba98-6bec20f70e6a",
   "metadata": {},
   "source": [
    "# Zooming in on particular Grand datasets \n",
    "\n",
    "We use GLoVE vectors, they have worked best so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469b5f0-7b5b-416e-93b3-36f163a91e4f",
   "metadata": {},
   "source": [
    "# Global data, set to run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d7398-c24b-4b27-a99e-0ac26f774b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"../glove/glove.42B.300d.zip\"\n",
    "glove_file = \"glove.42B.300d.txt\"\n",
    "\n",
    "grandratings_dir = \"../data/Grandetal-data/\"\n",
    "grandfeatures_path = \"../data/Grandetal-data/features.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce3629-a6e3-42fe-b05c-65fe7e14b46e",
   "metadata": {},
   "source": [
    "# The Grand category and feature to be illustrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bbbd1f-1110-4cd1-b17b-da442bde807d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grand_category = \"clothing\"\n",
    "grand_feature = \"wealth\"\n",
    "\n",
    "randomseed = 3\n",
    "how_many_pieces = 3\n",
    "testfold = 0\n",
    "\n",
    "# grand_category = \"animals\"\n",
    "# grand_feature = \"size\"\n",
    "\n",
    "# randomseed = 3\n",
    "# how_many_pieces = 3\n",
    "# testfold = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c91c2-dfe8-4d0e-bfd1-3f03fb6620bc",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a180621-c55c-4bbb-b25c-f282098baeb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import math\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6c328-3bd3-44c0-a9ee-bfd43a9fa796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GLoVE vectors\n",
    "\n",
    "\n",
    "feature_dim = 300\n",
    "\n",
    "word_vectors = { }\n",
    "\n",
    "with zipfile.ZipFile(glove_path) as azip:\n",
    "    with azip.open(glove_file) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0].decode()\n",
    "            vector = np.array(values[1:], dtype=np.float32)\n",
    "            word_vectors[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6956aa-d676-4c11-897a-94e1bfc48aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grandfeatures_df = pd.read_excel(grandfeatures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47ac0e-9502-404b-b0cd-faecc6fd9a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = grandratings_dir + grand_category + \"_\" + grand_feature + \".csv\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "nspeakers = len(df.columns) -1\n",
    "df[\"Average\"] = [row.iloc[1:26].sum() / nspeakers for _, row in df.iterrows()]\n",
    "# z-scores of average ratings\n",
    "df[\"Gold\"] = (df[\"Average\"] - df[\"Average\"].mean()) / df[\"Average\"].std()\n",
    "\n",
    "# obtain seed words from excel file\n",
    "relevant_row = grandfeatures_df[grandfeatures_df.Dimension == grand_feature]\n",
    "seedwords = relevant_row.iloc[:, 1:].values.flatten().tolist()\n",
    "pos_seedwords = seedwords[:3]\n",
    "neg_seedwords = seedwords[3:]\n",
    "\n",
    "print(df.sort_values(by=\"Gold\")[[\"Row\", \"Gold\"]].head())\n",
    "print(df.sort_values(by=\"Gold\")[[\"Row\", \"Gold\"]].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34a3f3-cf0b-40ca-afe3-80fa9f1bb84b",
   "metadata": {},
   "source": [
    "# Train/test split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da58c2-88a3-465c-b4db-fcfc69f9ddf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# split into training and test\n",
    "\n",
    "rng = np.random.default_rng(seed = randomseed)\n",
    "fold = rng.integers(low = 0, high = how_many_pieces, size = len(df.Gold))\n",
    "\n",
    "test_indices =  [i for i in range(len(df.Gold)) if fold[i] == testfold]\n",
    "print(\"Test datapoints\")\n",
    "for _, ell in df.iloc[ test_indices].iterrows():\n",
    "    print(\"\\t\", ell[\"Row\"], ell[\"Gold\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e07cf-298f-4fa6-bd27-47ee82ae89a0",
   "metadata": {},
   "source": [
    "# Obtaining predictions\n",
    "\n",
    "Train on train, predict on all, store results in the dataframe for seed-based and fit+s models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc59d9e-1b14-46ad-951b-4a804fe9f9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# obtaining predictions for each datapoint\n",
    "import eval_dim\n",
    "import compute_dim\n",
    "import statistics\n",
    "\n",
    "# compute training and test data.\n",
    "# we got test indices above\n",
    "train_indices = [i for i in range(len(df.Gold)) if fold[i] != testfold]\n",
    "all_thisdata_vectors = [word_vectors[ row.Row ] for row in df.itertuples() ]\n",
    "gold_train = [ ell[\"Gold\"] for _, ell in df.iloc[ train_indices ].iterrows()]\n",
    "words_test =  [ell[\"Row\"] for _, ell in df.iloc[ test_indices].iterrows()]\n",
    "words_train = [ell[\"Row\"] for _, ell in df.iloc[ train_indices].iterrows()]\n",
    "vec_test =  [word_vectors[ w ] for w in words_test]\n",
    "vec_train = [word_vectors[ w ] for w in words_train ]\n",
    "\n",
    "random_seed = 123\n",
    "hyper_offset = 1.0\n",
    "hyper_jitter = False\n",
    "hyper_average = True\n",
    "hyper_alpha_s = 0.05\n",
    "\n",
    "# seed-based dimension\n",
    "seed_dimension = compute_dim.dimension_seedbased(pos_seedwords, neg_seedwords, word_vectors)\n",
    "# df[\"Seed\"] = compute_dim.predict_coord_fromtrain(vec_train, gold_train, dimension, all_thisdata_vectors)\n",
    "df[\"Seed\"] = compute_dim.predict_coord_fromtrain(all_thisdata_vectors, df.Gold, seed_dimension, all_thisdata_vectors)\n",
    "\n",
    "# df[\"Seed\"] = compute_dim.predict_scalarproj(all_thisdata_vectors, dimension)\n",
    "\n",
    "# fit+s dimension\n",
    "fit_dimension, fit_weight, fit_bias = compute_dim.dimension_fitted_fromratings_combined(vec_train, gold_train,\n",
    "                                                                    300,\n",
    "                                                                    pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                                    offset = hyper_offset, \n",
    "                                                                    alpha = hyper_alpha_s,\n",
    "                                                                    random_seed = random_seed)\n",
    "df[\"Fit+s\"] = compute_dim.predict_coord_fromline(all_thisdata_vectors, fit_dimension, fit_weight, fit_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e9ecf-55ad-49f5-81cd-4fa8fd35a147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testdf = df.iloc[ test_indices].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f274e02e-a43d-47e7-b29f-2d102df574ae",
   "metadata": {},
   "source": [
    "# Ranking the datapoints, in comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd7fef-cff2-45bd-842d-8e8d1c45f740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rankings of the datapoints\n",
    "gold_wordrank = list(testdf.sort_values(by = \"Gold\").Row)\n",
    "seed_wordrank = list(testdf.sort_values(by = \"Seed\").Row)\n",
    "fits_wordrank = list(testdf.sort_values(by = \"Fit+s\").Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa6b3f-b4c3-4e23-a450-8bcb0826740f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Rankings: Gold, Seed, Fit+s\\n\")\n",
    "for i, word in enumerate(gold_wordrank):\n",
    "    print(word,  \"&\", seed_wordrank[i], \"&\", fits_wordrank[i], '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa7bc7-acf5-48a3-98ab-f18c70ec01ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort by square error\n",
    "print(\"Datapoints, sorted by square error\")\n",
    "for column in [\"Seed\", \"Fit+s\"]:\n",
    "    sqerr = (testdf.Gold - testdf[column])**2\n",
    "\n",
    "    print(column)\n",
    "    for se, word in sorted(zip(sqerr, testdf.Row)):\n",
    "        print(word, se)\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82023e8d-68ef-4cce-84dc-e61aa8a63793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort datapoints by error in rank\n",
    "print(\"Datapoints, by error in rank\")\n",
    "for column in [\"Seed\", \"Fit+s\"]:\n",
    "    print(column, \"\\n\")\n",
    "    goldrank  = testdf.Gold.rank()\n",
    "    modelrank = testdf[column].rank()\n",
    "    sqdiff = (goldrank - modelrank)**2\n",
    "    for sd, word in sorted(zip(sqdiff, testdf.Row)):\n",
    "        print(word, sd)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33a2bd-78c5-478a-abc9-ba43ec4c15dc",
   "metadata": {},
   "source": [
    "# Plotting test vectors and interpretable dimensions in a 2-d image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802feaa-7b3f-4640-b2ed-366d2c570c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# projection of a vector along a direction,\n",
    "# where we want the actual vector, not its length\n",
    "# (vec * direction1) * direction1\n",
    "def vector_projection(vec, direction):\n",
    "    dir_veclen = math.sqrt(np.dot(direction, direction))\n",
    "    direction1 = direction / dir_veclen\n",
    "    return np.dot(vec, direction1) * direction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac80f64-6613-4b0a-bf91-20a69575e7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "# Code for projecting embeddings down to 2-d\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "###\n",
    "# function that produces a visualization of a given list of words.\n",
    "# parameters\n",
    "# - words: list of words to visualize\n",
    "# - seeds_pos, seeds_neg: seedwords, which will also be visualized\n",
    "# - space: dictionary mapping words to numpy arrays that are embeddings\n",
    "# - lines: information about lines to add to the picture. This is a Python dictionary;\n",
    "#   - key 'wordpairs': list of pairs of words: add lines between those words\n",
    "#   - key 'dims': list of vectors that represent averaged interpretable dimensions.\n",
    "#     For each dimension, project two words onto it, and draw a line through those two points\n",
    "#   - key 'pointpairs': list of pairs of vectors: project into 2d space and draw a line through them\n",
    "#   - key \"colors\": list of colors for the lines, one per line, first for word pairs lines,\n",
    "#          then dims lines, then pointpairs lines\n",
    "def visualize(words, seeds_pos, seeds_neg, space, lines, omitwords = []):\n",
    "    # make the scatter plot\n",
    "    allwords, twodim, pca_obj = plot_points(words, seeds_pos, seeds_neg, space, omitwords = omitwords)\n",
    "    \n",
    "    lineindex = 0\n",
    "    \n",
    "    # for every pair of words for which we want to draw\n",
    "    # an individual-wordpair line: draw the line\n",
    "    if \"wordpairs\" in lines:\n",
    "        for word1, word2 in lines[\"wordpairs\"]:\n",
    "            i1 = allwords.index(word1)\n",
    "            point1 = twodim[i1]\n",
    "            i2 = allwords.index(word2)\n",
    "            point2 = twodim[i2]\n",
    "        \n",
    "            if \"colors\" in lines:\n",
    "                plt.axline(point1, point2, c=lines[\"colors\"][lineindex])\n",
    "            else:\n",
    "                plt.axline(point1, point2)\n",
    "                \n",
    "            lineindex += 1\n",
    "        \n",
    "    # for every vector that is an averaged dimension:\n",
    "    # project two words onto this vector to get two points, \n",
    "    # then draw a line through those two points.\n",
    "    if \"dims\" in lines:\n",
    "        for avgvector in lines[\"dims\"]:\n",
    "            # project the first two words onto the average vector\n",
    "            # where we need the actual vector, not just its length\n",
    "            proj1 = vector_projection(space[ words[0] ], avgvector)\n",
    "            proj2 = vector_projection(space[ words[1] ], avgvector)\n",
    "        \n",
    "            # make them into an array to feed into pca\n",
    "            x = np.array( [ proj1, proj2])\n",
    "        \n",
    "            # downproject to two dimensions\n",
    "            points = pca_obj.transform(x)[:,:2]\n",
    "        \n",
    "            # and plot the line\n",
    "            if \"colors\" in lines:\n",
    "                plt.axline( points[0], points[1], c=lines[\"colors\"][lineindex])\n",
    "            else:\n",
    "                plt.axline( points[0], points[1])\n",
    "                \n",
    "            lineindex += 1\n",
    "            \n",
    "    if \"pointpairs\" in lines: \n",
    "        for vec1, vec2 in lines[\"pointpairs\"]:\n",
    "            # downproject the two points\n",
    "            x = np.array( [vec1, vec2 ])\n",
    "            points = pca_obj.transform(x)[:, :2]\n",
    "            \n",
    "            # and plot\n",
    "            if \"colors\" in lines:\n",
    "                plt.axline( points[0], points[1], c = lines[\"colors\"][lineindex])\n",
    "            else:\n",
    "                plt.axline(points[0], points[1])\n",
    "                \n",
    "            lineindex += 1\n",
    "                \n",
    "    plt.show()\n",
    "        \n",
    "    \n",
    "def plot_points(words, seeds_pos, seeds_neg, space, omitwords = [ ]):\n",
    "    allwords = words + seeds_pos + seeds_neg\n",
    "    \n",
    "    # put all the word vectors into one matrix\n",
    "    word_vectors = np.array([space[w] for w in allwords])\n",
    "    \n",
    "    # use dimensionality reduction: \n",
    "    # Principal Component Analysis, PCA\n",
    "    # keep the two first dimensions\n",
    "    pca_obj = PCA()\n",
    "    twodim = pca_obj.fit_transform(word_vectors)[:,:2]\n",
    "\n",
    "    # set up the canvas\n",
    "    plt.figure(figsize=(6,6))\n",
    "    \n",
    "    # plot colors: blue for concept words, \n",
    "    # green for positive seeds, red for negative seeds\n",
    "    plotcolors = [ ]\n",
    "    for w in allwords:\n",
    "        if w in seeds_pos: plotcolors.append(\"g\")\n",
    "        elif w in seeds_neg: plotcolors.append(\"r\")\n",
    "        else: plotcolors.append(\"b\")\n",
    "    \n",
    "    # add a scatter plot of the two-D embeddings\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', \n",
    "                c=plotcolors)\n",
    "\n",
    "    # add each of the words to the plot, a bit above and to the right\n",
    "    # of the 2-D dot it goes with\n",
    "    for word, (x,y) in zip(allwords, twodim):\n",
    "        if word not in omitwords:\n",
    "            plt.text(x+0.05, y+0.05, word)\n",
    "\n",
    "    return (allwords, twodim, pca_obj)\n",
    "    # now show the canvas\n",
    "    # plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44efe3e9-026e-4463-bcee-4f7bdca046fe",
   "metadata": {},
   "source": [
    "### Seed-based dimension only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd309d5-afaa-45c6-8ce0-cada5b3a9677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(list(testdf[\"Row\"]), [], [], word_vectors,  \n",
    "          {\"dims\" : [seed_dimension]}, omitwords = [\"sweatshirt\", \"belt\", \"hat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14222c3a-296f-4d1d-8129-be3133e94392",
   "metadata": {},
   "source": [
    "### Seed-based and fitted dimension\n",
    "\n",
    "blue: seed based\n",
    "\n",
    "red: fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d67056-0457-4dee-8c6a-a602a6c9b7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(list(testdf[\"Row\"]), [], [], word_vectors,  \n",
    "          {\"dims\" : [seed_dimension], \n",
    "           \"pointpairs\" : [ (np.zeros(feature_dim), fit_dimension)],\n",
    "          \"colors\" : [\"b\", \"r\"]}, \n",
    "          omitwords = [\"sweatshirt\", \"belt\", \"hat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d82e3bd-2bcc-4ffd-ae67-723ce674b9db",
   "metadata": {},
   "source": [
    "# Illustrating residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df98090a-6e41-4758-9b52-fd0999de7ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testdf.sort_values(by=\"Gold\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac7419d-3617-4d48-b5c8-d2734b5d7ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "offset= []\n",
    "nextoffset = 0\n",
    "for  _, ell in df.iloc[ test_indices].iterrows():\n",
    "    offset.append(nextoffset)\n",
    "    nextoffset += 2 * len(ell[\"Row\"]) + 2\n",
    "    \n",
    "testdf[\"Offset\"] = offset\n",
    "    \n",
    "testdf.plot(kind = \"scatter\", y= [\"Gold\", \"Seed\", \"Fit+s\"], x = [\"Offset\", \"Offset\", \"Offset\"], \n",
    "            c = [0, 0.7, 0.3]*len(testdf.Gold), colormap = \"rainbow\", ylabel = \"Rating\", xlabel = \"\", xticks = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca5633-768b-49ad-bca5-17661266b8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
