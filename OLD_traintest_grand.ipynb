{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40497638-f6f6-4424-a7aa-4a43efda34b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bf61834-8f0f-4580-88da-f4f85292ff7d",
   "metadata": {},
   "source": [
    "# Reading the GLoVE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd7b586-6498-44fb-8810-5cbe92e383ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import math\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dae5cc5-4986-48ed-bcdf-4329a1906e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glove_path = \"glove/glove.42B.300d.zip\"\n",
    "glove_file = \"glove.42B.300d.txt\"\n",
    "\n",
    "feature_dim = 300\n",
    "\n",
    "word_vectors = { }\n",
    "\n",
    "with zipfile.ZipFile(glove_path) as azip:\n",
    "    with azip.open(glove_file) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0].decode()\n",
    "            vector = np.array(values[1:], dtype=np.float32)\n",
    "            word_vectors[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07f037-d314-409b-b0f8-c5d060d5e721",
   "metadata": {},
   "source": [
    "# Read Grand features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f56398ff-3d19-4544-bc82-06a60e6d8737",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kee252/Library/Python/3.9/lib/python/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "grandratings_dir = \"Grand_etal_csv/\"\n",
    "grandfeatures_path = \"/Users/kee252/Data/grand_directions_in_space/features.xlsx\"\n",
    "\n",
    "grandfeatures_df = pd.read_excel(grandfeatures_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634312f-f738-462a-9d5d-b8bf0ba5dbcc",
   "metadata": {},
   "source": [
    "# Functions: Seed-based dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9dda4e6-e1b5-4f55-9624-ac46ad1cec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging over seed pair vectors\n",
    "def average_dim_vector(seeds_pos, seeds_neg, space):\n",
    "    diffvectors = [ ]\n",
    "    \n",
    "    for negword in seeds_neg:\n",
    "        for posword in seeds_pos:\n",
    "            diffvectors.append(space[posword] - space[negword])\n",
    "\n",
    "    # average\n",
    "    dimvec = np.mean(diffvectors, axis = 0)\n",
    "    return dimvec\n",
    "\n",
    "# scalar projection of a vector along a given direction:\n",
    "# length of the projection vector\n",
    "# (vec * direction) / ||direction||\n",
    "def vector_scalar_projection(vec, direction):\n",
    "    dir_veclen = math.sqrt(np.dot(direction, direction))\n",
    "    return np.dot(vec, direction) / dir_veclen\n",
    "\n",
    "# projection of a vector along a direction,\n",
    "# where we want the actual vector, not its length\n",
    "# (vec * direction1) * direction1\n",
    "def vector_projection(vec, direction):\n",
    "    dir_veclen = math.sqrt(np.dot(direction, direction))\n",
    "    direction1 = direction / dir_veclen\n",
    "    return np.dot(vec, direction1) * direction1\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# fitted dimensions come with a weight and bias for prediction. \n",
    "# we can compute those also for seed-based dimensions\n",
    "# to make predictions on the same order of magnitude as the original ratings.\n",
    "# We need that in order to do a Mean Squared Error (MSE) evaluation.\n",
    "# \n",
    "# This function uses linear regression to compute weight and bias. formula:\n",
    "#\n",
    "# model_rating ~ weight * gold_rating + bias\n",
    "#\n",
    "# formulated this way round to match the formulation in the objective function\n",
    "# of the fitted dimensions model\n",
    "def coef_for_seed_dimension(gold_ratings, model_ratings):\n",
    "    result = stats.linregress(gold_ratings, model_ratings)\n",
    "    \n",
    "    return (result.slope, result.intercept)\n",
    "\n",
    "# given a scalar projection on a seed-based dimension,\n",
    "# along with weight and bias computed by\n",
    "# coef_for_seed_dimension,\n",
    "# compute a predicted rating.\n",
    "def sprediction(sprojection, weight, bias):\n",
    "    return (sprojection - bias) / weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098e7cf-7de6-4239-b3d5-cd0e333f7867",
   "metadata": {},
   "source": [
    "# Functions: Fitted dimensions\n",
    "\n",
    "## Original fitted dimension formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d931eb-80a5-474e-bdb7-24850d5c88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing a fitted dimension based on a list of word vectors and matching list of gold ratings.\n",
    "# feature_dim is dimensionality of the vectors. \n",
    "# This fits a dimension using an objective function based on the Jameel and Schockaert idea\n",
    "def ideal_dimension(word_vectors_list, gold_ratings, feature_dim, random_seed = 123):\n",
    "    torch.manual_seed(random_seed) \n",
    "\n",
    "    # we compute: a vector of same dimensionality as our embeddings,\n",
    "    # and a weight and a bias constant\n",
    "    feature_vector = torch.randn(feature_dim, requires_grad=True) # dtype=torch.float32)\n",
    "    weight_constant = torch.randn(1, requires_grad=True) \n",
    "    bias_constant = torch.randn(1, requires_grad=True)    \n",
    "\n",
    "    \n",
    "    optimizer = optim.Adam([feature_vector, weight_constant, bias_constant], lr=0.01)\n",
    "    # optimizer = optim.SGD([feature_vector, weight_constant, bias_constant], lr=0.001)\n",
    "\n",
    "    # Number of optimization steps\n",
    "    num_steps = 1000\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    # Gradient clipping threshold\n",
    "    max_norm = 1.0  \n",
    "\n",
    "    for step in range(num_steps):\n",
    "        total_loss = 0\n",
    "\n",
    "        # for i in range(len(X_train)):\n",
    "        # \tword_embedding = torch.tensor(X_train[i]) \n",
    "        # \tgold_rating = y_train[i]\n",
    "\n",
    "        for i in range(len(word_vectors_list)):\n",
    "            word_embedding = torch.tensor(word_vectors_list[i])\n",
    "            gold_rating = gold_ratings[i]\n",
    "\n",
    "            dot_product = torch.dot(word_embedding, feature_vector)\n",
    "            weighted_gold = gold_rating * weight_constant\n",
    "            loss = ((dot_product - weighted_gold - bias_constant) ** 2)\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "        # Average loss over all words in X_train or in the whole human dic (2,801 annotated single words in total)\n",
    "        # avg_loss = total_loss / len(X_train)\n",
    "        avg_loss = total_loss / len(word_vectors_list)\n",
    "\n",
    "        avg_loss.backward()\n",
    "\n",
    "        # Compute the gradient norms and monitor them during training\n",
    "\n",
    "        # feature_vector_grad_norm = torch.norm(feature_vector.grad)\n",
    "        # print(f\"Step {step+1}, Feature Vector Gradient Norm: {feature_vector_grad_norm.item()}\")\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_([feature_vector, weight_constant, bias_constant], max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(avg_loss.item())\n",
    "    \n",
    "    return (feature_vector.detach().numpy(), weight_constant.item(), bias_constant.item())\n",
    "\n",
    "# we have defined our loss to shoot for\n",
    "# (vec * direction) \\approx weight* goldrating + bias\n",
    "# hence the predicted rating is\n",
    "# predictedrating = ((vec * direction) - bias ) / weight\n",
    "def iprediction(vec, direction, weight, bias):\n",
    "    return (np.dot(vec, direction) - bias) / weight\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5463e-a4a1-45ed-98d7-35262f43fe77",
   "metadata": {},
   "source": [
    "## Fitted dimension with seeds as additional words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb599d56-42a0-4396-93a7-470832a8adfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combined method: fitted dimension with seeds\n",
    "# thisdata_vectors: vectors for category words\n",
    "# thisdata_gold: gold ratings for category words\n",
    "# feature_dim: dimensionality\n",
    "# pos_seedwords: list of positive seedwords\n",
    "# neg_seedwords: list of negative seedwords\n",
    "# word_vectors: mapping word-> vector\n",
    "# offset: synthetic rating for seed words should be this far beyond\n",
    "#   the rating of the most positive/most negative word\n",
    "# jitter: if true: add a bit of random variation to seed word ratings\n",
    "def fitted_dimension_withseedwords(thisdata_vectors, thisdata_gold, feature_dim, \n",
    "                                   pos_seedwords, neg_seedwords, word_vectors, offset = 0.5, jitter = False):\n",
    "    # adding seed words\n",
    "    \n",
    "    lowvalue = min(thisdata_gold) - offset\n",
    "    highvalue = max(thisdata_gold) + offset\n",
    "        \n",
    "    for seed in pos_seedwords:\n",
    "        thisdata_vectors.append( word_vectors [ seed ])\n",
    "        j = random.uniform(0.001, 0.005) if jitter else 0\n",
    "        thisdata_gold.append( highvalue + j)\n",
    "\n",
    "    for seed in neg_seedwords:\n",
    "        thisdata_vectors.append( word_vectors [ seed ])\n",
    "        j = random.uniform(0.001, 0.005) if jitter else 0\n",
    "        thisdata_gold.append( lowvalue - j)\n",
    "            \n",
    "            \n",
    "    return ideal_dimension(thisdata_vectors, thisdata_gold, feature_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a21d26e-1fe7-44ba-b4e0-4274a40fbfae",
   "metadata": {},
   "source": [
    "## Fitted dimensions with combined loss function: similarity to seed dimensions and match with human ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4514a7f-7299-4a22-84e8-5518d269b877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fitted dimension, with seeds too\n",
    "\n",
    "# Weight/bias defined as trainable variables to optimize during backpropagation along with the feature vector\n",
    "#\n",
    "# parameters:\n",
    "# - word vectors list: list of vectors for the words in our category\n",
    "# - gold ratings: gold ratings on the dimension of interest, \n",
    "#    in the same order as the word vectors list\n",
    "# - feature_dim: dimensionality of the vectors\n",
    "# - random seed\n",
    "#\n",
    "# returns: \n",
    "# - computed vector for the ideal dimension\n",
    "# - weight and bias such that vector * idealvec \\approx weight * goldrating + bias\n",
    "#\n",
    "def fitted_dimension_withseeddims(word_vectors_list, gold_ratings, seed_dims, feature_dims, alpha = 0.5, random_seed = 123):\n",
    "    torch.manual_seed(random_seed) \n",
    "\n",
    "    # we compute: a vector of same dimensionality as our embeddings,\n",
    "    # and a weight and a bias constant\n",
    "    feature_vector = torch.randn(feature_dim, requires_grad=True) # dtype=torch.float32)\n",
    "    weight_constant = torch.randn(1, requires_grad=True) \n",
    "    bias_constant = torch.randn(1, requires_grad=True)    \n",
    "\n",
    "    \n",
    "    optimizer = optim.Adam([feature_vector, weight_constant, bias_constant], lr=0.01)\n",
    "    # optimizer = optim.SGD([feature_vector, weight_constant, bias_constant], lr=0.001)\n",
    "\n",
    "    # Number of optimization steps\n",
    "    num_steps = 1000\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    criterion2 = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "    # Gradient clipping threshold\n",
    "    max_norm = 1.0  \n",
    "\n",
    "    for step in range(num_steps):\n",
    "        total_loss1 = 0\n",
    "\n",
    "        # for i in range(len(X_train)):\n",
    "        # \tword_embedding = torch.tensor(X_train[i]) \n",
    "        # \tgold_rating = y_train[i]\n",
    "\n",
    "        for i in range(len(word_vectors_list)):\n",
    "            word_embedding = torch.tensor(word_vectors_list[i])\n",
    "            gold_rating = gold_ratings[i]\n",
    "\n",
    "            dot_product = torch.dot(word_embedding, feature_vector)\n",
    "            weighted_gold = gold_rating * weight_constant\n",
    "            loss1 = ((dot_product - weighted_gold - bias_constant) ** 2)\n",
    "\n",
    "            total_loss1 += loss1\n",
    "            \n",
    "        \n",
    "        avg_loss1 = total_loss1 / len(word_vectors_list)\n",
    "        loss2 = sum([criterion2( feature_vector, d, torch.tensor(1.0)) for d in seed_dims]) / len(seed_dims)\n",
    "        total_loss = alpha*avg_loss1 + (1-alpha) * loss2\n",
    "\n",
    "        total_loss.backward()\n",
    "\n",
    "        # Compute the gradient norms and monitor them during training\n",
    "\n",
    "        # feature_vector_grad_norm = torch.norm(feature_vector.grad)\n",
    "        # print(f\"Step {step+1}, Feature Vector Gradient Norm: {feature_vector_grad_norm.item()}\")\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_([feature_vector, weight_constant, bias_constant], max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(total_loss.item())\n",
    "\n",
    "    \n",
    "    return (feature_vector.detach().numpy(), weight_constant.item(), bias_constant.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8216d9-2d9d-43c0-989e-a173a3e4be84",
   "metadata": {},
   "source": [
    "# Function for reading in a specific Grand dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f45bb6e-da17-4581-91b2-41d3721ce40d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading in Grand data\n",
    "def read_grand_data(filename, grandratings_dir, grandfeatures_df):\n",
    "    # extract category and feature\n",
    "    grandcategory, grandfeature = filename[:-4].split(\"_\")\n",
    "        \n",
    "    # read human ratings, make gold column\n",
    "    df = pd.read_csv(grandratings_dir + filename)\n",
    "    df[\"Average\"] = [row.iloc[1:26].sum() / 25 for _, row in df.iterrows()]\n",
    "    # z-scores of average ratings\n",
    "    df[\"Gold\"] = (df[\"Average\"] - df[\"Average\"].mean()) / df[\"Average\"].std()\n",
    "        \n",
    "    # obtain seed words from excel file\n",
    "    relevant_row = grandfeatures_df[grandfeatures_df.Dimension == grandfeature]\n",
    "    seedwords = relevant_row.iloc[:, 1:].values.flatten().tolist()\n",
    "    pos_seedwords = seedwords[:3]\n",
    "    neg_seedwords = seedwords[3:]\n",
    "    \n",
    "    return (grandcategory, grandfeature, pos_seedwords, neg_seedwords, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e6d9b-907f-496d-9ccc-7703e1d7cf3e",
   "metadata": {},
   "source": [
    "# Evaluation measures: OC_p, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead8c3fe-34e0-4bd6-8144-263eedbc8d62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# pairwise order consistency, normal definition\n",
    "def pairwise_order_consistency(goldvalues, modelvalues):\n",
    "    if len(goldvalues) != len(modelvalues):\n",
    "        raise Exception(\"shouldn't be here\")\n",
    "        \n",
    "    outcomes = [ ]\n",
    "    for i1, i2 in itertools.combinations(range(len(goldvalues)), 2):\n",
    "        goldrel = (goldvalues[i1] > goldvalues[i2])\n",
    "        modelrel = (modelvalues[i1] > modelvalues[i2])\n",
    "        outcomes.append(int(goldrel == modelrel))\n",
    "        \n",
    "    return sum(outcomes) / len(outcomes)\n",
    "\n",
    "# pairwise order consistency only for a subset of the model values \n",
    "def pairwise_order_consistency_wrt(goldvalues, modelvalues, test_indices):\n",
    "    if len(goldvalues) != len(modelvalues):\n",
    "        raise Exception(\"shouldn't be here\")\n",
    "        \n",
    "    outcomes = [ ]\n",
    "    for i1 in test_indices:\n",
    "        for i2 in range(len(goldvalues)):\n",
    "            if i1 == i2: continue\n",
    "            \n",
    "            goldrel = (goldvalues[i1] > goldvalues[i2])\n",
    "            modelrel = (modelvalues[i1] > modelvalues[i2])\n",
    "            outcomes.append(int(goldrel == modelrel))\n",
    "        \n",
    "    return sum(outcomes) / len(outcomes)\n",
    "\n",
    "# mean squared error\n",
    "def mean_squared_error(goldvalues, modelvalues):\n",
    "    if len(goldvalues) != len(modelvalues):\n",
    "        raise Exception(\"shouldn't be here\")\n",
    "    return sum([(g - m)**2 for g, m in zip(goldvalues, modelvalues)]) / len(goldvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f83f4-de33-4e1b-a0e4-e04650488db0",
   "metadata": {},
   "source": [
    "# Making a development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a6fe6d-20d2-43e2-8428-c46b1f6944be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cities', 'danger'],\n",
       " ['states', 'political'],\n",
       " ['animals', 'wetness'],\n",
       " ['cities', 'intelligence'],\n",
       " ['animals', 'weight'],\n",
       " ['names', 'age']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [f for f in os.listdir(grandratings_dir) if f.endswith(\"csv\")]\n",
    "[ filename[:-4].split(\"_\") for filename in filenames]\n",
    "\n",
    "import random\n",
    "random.seed(789)\n",
    "devset = random.sample(filenames, 6)\n",
    "[ filename[:-4].split(\"_\") for filename in devset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a139eaec-fdec-4520-b210-04c91c32632a",
   "metadata": {},
   "source": [
    "# Running an evaluation with crossvalidation on the development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e23751e0-3df1-4167-b8bc-d5ba86f69d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test split\n",
      "cities - danger\n",
      "\tSeed OC_p 0.770 (0.03) Fitted OC_p 0.651 (0.04) Fitted-Seed OC_p 0.658 (0.04) Fitted-SeedD OC_p 0.826 (0.04) \n",
      "\tSeed MSE 0.975 (0.38) Fitted MSE 12.674 (5.61) Fitted-Seed MSE 11.837 (3.38) Fitted-SeedD MSE 0.594 (0.20) \n",
      "states - political\n",
      "\tSeed OC_p 0.663 (0.06) Fitted OC_p 0.604 (0.06) Fitted-Seed OC_p 0.591 (0.08) Fitted-SeedD OC_p 0.768 (0.03) \n",
      "\tSeed MSE 4.877 (2.78) Fitted MSE 14.012 (9.66) Fitted-Seed MSE 22.456 (9.13) Fitted-SeedD MSE 0.945 (0.12) \n",
      "animals - wetness\n",
      "\tSeed OC_p 0.755 (0.05) Fitted OC_p 0.635 (0.14) Fitted-Seed OC_p 0.633 (0.14) Fitted-SeedD OC_p 0.774 (0.11) \n",
      "\tSeed MSE 0.569 (0.26) Fitted MSE 9.231 (7.49) Fitted-Seed MSE 23.144 (18.38) Fitted-SeedD MSE 0.691 (0.32) \n",
      "cities - intelligence\n",
      "\tSeed OC_p 0.584 (0.06) Fitted OC_p 0.586 (0.06) Fitted-Seed OC_p 0.606 (0.10) Fitted-SeedD OC_p 0.802 (0.05) \n",
      "\tSeed MSE 35.250 (22.71) Fitted MSE 10.895 (4.53) Fitted-Seed MSE 10.555 (4.67) Fitted-SeedD MSE 0.716 (0.35) \n",
      "animals - weight\n",
      "\tSeed OC_p 0.511 (0.04) Fitted OC_p 0.642 (0.05) Fitted-Seed OC_p 0.629 (0.05) Fitted-SeedD OC_p 0.857 (0.03) \n",
      "\tSeed MSE 207.393 (114.23) Fitted MSE 14.677 (8.95) Fitted-Seed MSE 13.329 (4.90) Fitted-SeedD MSE 0.287 (0.16) \n",
      "names - age\n",
      "\tSeed OC_p 0.722 (0.02) Fitted OC_p 0.621 (0.09) Fitted-Seed OC_p 0.622 (0.09) Fitted-SeedD OC_p 0.854 (0.02) \n",
      "\tSeed MSE 1.499 (0.49) Fitted MSE 14.792 (4.35) Fitted-Seed MSE 16.658 (3.29) Fitted-SeedD MSE 0.391 (0.16) \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "print(\"Training and test split\")\n",
    "\n",
    "numfolds = 5\n",
    "offset = 1.0\n",
    "alpha = 0.1\n",
    "jitter = False\n",
    "\n",
    "all_evals = [ ]\n",
    "\n",
    "for filename in devset: \n",
    "        grandcategory, grandfeature, pos_seedwords, neg_seedwords, df = read_grand_data(filename, grandratings_dir, grandfeatures_df)\n",
    "        \n",
    "        \n",
    "        # storage for word vectors and gold values for this dataset\n",
    "        all_thisdata_vectors = []\n",
    "        all_thisdata_gold = []\n",
    "\n",
    "        for row in df.itertuples():\n",
    "            # row.Row is the word. look it up in word_vectors\n",
    "            all_thisdata_vectors.append( word_vectors[ row.Row ])\n",
    "            # gold rating: use z-scored average\n",
    "            all_thisdata_gold.append( row.Gold)\n",
    "      \n",
    "        # crossvalidation setup: give indices to datapoints\n",
    "        fold = np.random.randint(numfolds, size = len(all_thisdata_gold))\n",
    "        \n",
    "        # store the evaluation results from the different test folds\n",
    "        evals = [ ]\n",
    "        \n",
    "        # iterate over folds, evaluate for each of them\n",
    "        for testfold in range(numfolds):\n",
    "            # compute training and test data for this fold\n",
    "            test_indices =  [i for i in range(len(all_thisdata_gold)) if fold[i] == testfold]\n",
    "            train_indices = [i for i in range(len(all_thisdata_gold)) if fold[i] != testfold]\n",
    "        \n",
    "            gold_test =  [ell[\"Gold\"] for _, ell in df.iloc[ test_indices ].iterrows()]\n",
    "            gold_train = [ ell[\"Gold\"] for _, ell in df.iloc[ train_indices ].iterrows()]\n",
    "            words_test =  [ell[\"Row\"] for _, ell in df.iloc[ test_indices].iterrows()]\n",
    "            words_train = [ell[\"Row\"] for _, ell in df.iloc[ train_indices].iterrows()]\n",
    "            vec_test =  [word_vectors[ w ] for w in words_test]\n",
    "            vec_train = [word_vectors[ w ] for w in words_train ]\n",
    "        \n",
    "\n",
    "            # compute seed-based dimension, and its predictions\n",
    "            seed_dim = average_dim_vector(pos_seedwords, neg_seedwords, word_vectors)\n",
    "            # prediction: first scalar projection, then compute weight and bias,\n",
    "            # and use them to make predictions\n",
    "            p0 = [vector_scalar_projection( word_vectors[w], seed_dim) for w in df[\"Row\"]]\n",
    "            weight, bias = coef_for_seed_dimension(df[\"Gold\"], p0)\n",
    "            df[\"SPred\"] = [sprediction(p, weight, bias) for p in p0]\n",
    "            \n",
    "            \n",
    "            # compute fitted dimension, and its predictions\n",
    "            fitted_dim, fitted_wt, fitted_bias = ideal_dimension(vec_train, gold_train, feature_dim)\n",
    "            df[\"FPred\"] = [ iprediction( word_vectors[ w], fitted_dim, fitted_wt, fitted_bias) for w in df[\"Row\"]]\n",
    "            \n",
    "            \n",
    "            # compute fitted dimension with seeds, and its predictions\n",
    "            fitted_dim, fitted_wt, fitted_bias = fitted_dimension_withseedwords(vec_train, gold_train, feature_dim, \n",
    "                                                                                pos_seedwords, neg_seedwords, word_vectors,\n",
    "                                                                                offset = offset, jitter = jitter)\n",
    "            df[\"FSPred\"] = [ iprediction( word_vectors[ w], fitted_dim, fitted_wt, fitted_bias) for w in df[\"Row\"]]\n",
    "            \n",
    "            # compute fitted dimension with seed dimensions, and its predictions\n",
    "            diffvectors = [ ]\n",
    "    \n",
    "            for negword in neg_seedwords:\n",
    "                for posword in pos_seedwords:\n",
    "                    diffvectors.append(word_vectors[posword] - word_vectors[negword])\n",
    "                    \n",
    "            dimvec = torch.from_numpy(np.mean(diffvectors, axis = 0))\n",
    "            \n",
    "            fitted_dim, fitted_wt, fitted_bias = fitted_dimension_withseeddims(vec_train, gold_train, [dimvec], \n",
    "                                                                               feature_dim, alpha = alpha)\n",
    "        \n",
    "            \n",
    "            df[\"FS2Pred\"] = [ iprediction( word_vectors[ w], fitted_dim, fitted_wt, fitted_bias) for w in df[\"Row\"]]\n",
    "            \n",
    "            # order consistency pairwise: test values tested for their ordering wrt. all values, training and test\n",
    "            # MSE: evaluate on test only\n",
    "            e = { \"ocp_s\" : pairwise_order_consistency_wrt(df[\"Gold\"], df[\"SPred\"], test_indices),\n",
    "                  \"ocp_f\" : pairwise_order_consistency_wrt(df[\"Gold\"], df[\"FPred\"], test_indices),\n",
    "                  \"ocp_fs\": pairwise_order_consistency_wrt(df[\"Gold\"], df[\"FSPred\"], test_indices),\n",
    "                  \"ocp_fs2\": pairwise_order_consistency_wrt(df[\"Gold\"], df[\"FS2Pred\"], test_indices),\n",
    "                  \"mse_s\" : mean_squared_error(gold_test, [p for i, p in enumerate(df[\"SPred\"]) if i in test_indices]),\n",
    "                  \"mse_f\" : mean_squared_error(gold_test, [p for i, p in enumerate(df[\"FPred\"]) if i in test_indices]),\n",
    "                  \"mse_fs\": mean_squared_error(gold_test, [p for i, p in enumerate(df[\"FSPred\"]) if i in test_indices]),\n",
    "                  \"mse_fs2\": mean_squared_error(gold_test, [p for i, p in enumerate(df[\"FS2Pred\"]) if i in test_indices])}\n",
    "            \n",
    "            evals.append(e)\n",
    "            all_evals.append(e)\n",
    "        \n",
    "        print(grandcategory, \"-\", grandfeature)\n",
    "        print(\"\\t\", end = \"\")\n",
    "        for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\"), (\"fs2\", \"Fitted-SeedD\")]:\n",
    "            ocps = [e[\"ocp_\" + suffix] for e in evals]\n",
    "            print(name, f\"OC_p {statistics.mean(ocps):.3f} ({statistics.stdev(ocps):.2f})\", end = \" \")\n",
    "        print(\"\\n\\t\", end = \"\")\n",
    "        for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\"), (\"fs2\", \"Fitted-SeedD\")]:\n",
    "            mses = [e[\"mse_\" + suffix] for e in evals]\n",
    "            print(name, f\"MSE {statistics.mean(mses):.3f} ({statistics.stdev(mses):.2f})\", end = \" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "750af420-9b42-471f-a5c2-3d56adb0d559",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed OC_p mean 0.667 (0.10)\n",
      "Fitted OC_p mean 0.623 (0.08)\n",
      "Fitted-Seed OC_p mean 0.623 (0.08)\n",
      "Fitted-SeedD OC_p mean 0.813 (0.06)\n",
      "\n",
      "Seed MSE med 1.318 mean 1.499 (0.49)\n",
      "Fitted MSE med 13.149 mean 14.792 (4.35)\n",
      "Fitted-Seed MSE med 16.654 mean 16.658 (3.29)\n",
      "Fitted-SeedD MSE med 0.361 mean 0.391 (0.16)\n"
     ]
    }
   ],
   "source": [
    "for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\"), (\"fs2\", \"Fitted-SeedD\")]:\n",
    "    ocps = [e[\"ocp_\" + suffix] for e in all_evals]\n",
    "    print(name, f\"OC_p mean {statistics.mean(ocps):.3f} ({statistics.stdev(ocps):.2f})\")\n",
    "print()\n",
    "\n",
    "for suffix, name in [(\"s\", \"Seed\"), (\"f\", \"Fitted\"), (\"fs\", \"Fitted-Seed\"), (\"fs2\", \"Fitted-SeedD\")]:\n",
    "    mses = [e[\"mse_\" + suffix] for e in evals]\n",
    "    print(name, f\"MSE med {statistics.median(mses):.3f} mean {statistics.mean(mses):.3f} ({statistics.stdev(mses):.2f})\") \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccab8bb-b9a0-460c-835f-ff115524d7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
